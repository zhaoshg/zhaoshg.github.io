<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[分布式系统的事务处理]]></title>
      <url>%2F20170505%2Ftransaction_distributed_system%2F</url>
      <content type="text"><![CDATA[分布式事务及应用场景当我们在生产线上用一台服务器来提供数据服务的时候，我会遇到如下的两个问题： 一台服务器的性能不足以提供足够的能力服务于所有的网络请求。 我们总是害怕我们的这台服务器停机，造成服务不可用或是数据丢失。 于是我们不得不对我们的服务器进行扩展，加入更多的机器来分担性能上的问题，以及来解决单点故障问题。通常，我们会通过两种手段来扩展我们的数据服务： 数据分区：就是把数据分块放在不同的服务器上（如：uid % 16，一致性哈希等）。 数据镜像：让所有的服务器都有相同的数据，提供相当的服务。 $y^i$ 对于第一种情况，我们无法解决数据丢失的问题，单台服务器出问题时，会有部分数据丢失。所以，数据服务的高可用性只能通过第二种方法来完成——数据的冗余存储（一般工业界认为比较安全的备份数应该是3份，如：Hadoop和Dynamo）。 但是，加入更多的机器，会让我们的数据服务变得很复杂，尤其是跨服务器的事务处理，也就是跨服务器的数据一致性。这个是一个很难的问题。 让我们用最经典的Use Case：“A帐号向B帐号汇钱”来说明一下，熟悉RDBMS事务的都知道从帐号A到帐号B需要6个操作： 从A帐号中把余额读出来。 对A帐号做减法操作。 把结果写回A帐号中。 从B帐号中把余额读出来。 对B帐号做加法操作。 把结果写回B帐号中。 为了数据的一致性，这6件事，要么都成功做完，要么都不成功，而且这个操作的过程中，对A、B帐号的其它访问必需锁死，所谓锁死就是要排除其它的读写操作，不然会有脏数据的问题，这就是事务。那么，我们在加入了更多的机器后，这个事情会变得复杂起来： 在数据分区的方案中：如果A帐号和B帐号的数据不在同一台服务器上怎么办？我们需要一个跨机器的事务处理。也就是说，如果A的扣钱成功了，但B的加钱不成功，我们还要把A的操作给回滚回去。这在跨机器的情况下，就变得比较复杂了。 在数据镜像的方案中：A帐号和B帐号间的汇款是可以在一台机器上完成的，但是别忘了我们有多台机器存在A帐号和B帐号的副本。如果对A帐号的汇钱有两个并发操作（要汇给B和C），这两个操作发生在不同的两台服务器上怎么办？也就是说，在数据镜像中，在不同的服务器上对同一个数据的写操作怎么保证其一致性，保证数据不冲突？ 同时，我们还要考虑性能的因素，如果不考虑性能的话，事务得到保证并不困难，系统慢一点就行了。除了考虑性能外，我们还要考虑可用性，也就是说，一台机器没了，数据不丢失，服务可由别的机器继续提供。 于是，我们需要重点考虑下面的这么几个情况： 容灾：数据不丢、结点的Failover 数据的一致性：事务处理 性能：吞吐量 、 响应时间 前面说过，要解决数据不丢，只能通过数据冗余的方法，就算是数据分区，每个区也需要进行数据冗余处理。这就是数据副本：当出现某个节点的数据丢失时可以从副本读到，数据副本是分布式系统解决数据丢失异常的唯一手段。所以，在这篇文章中，简单起见，我们只讨论在数据冗余情况下考虑数据的一致性和性能的问题。简单说来： 要想让数据有高可用性，就得写多份数据。 写多份的问题会导致数据一致性的问题。 数据一致性的问题又会引发性能问题 这就是软件开发，按下了葫芦起了瓢。 一致性模型说起数据一致性来说，简单说有三种类型（当然，如果细分的话，还有很多一致性模型，如：顺序一致性，FIFO一致性，会话一致性，单读一致性，单写一致性，但为了本文的简单易读，我只说下面三种）： Weak 弱一致性：当你写入一个新值后，读操作在数据副本上可能读出来，也可能读不出来。比如：某些cache系统，网络游戏其它玩家的数据和你没什么关系，VOIP这样的系统，或是百度搜索引擎（呵呵）。 Eventually 最终一致性：当你写入一个新值后，有可能读不出来，但在某个时间窗口之后保证最终能读出来。比如：DNS，电子邮件、Amazon S3，Google搜索引擎这样的系统。 Strong 强一致性：新的数据一旦写入，在任意副本任意时刻都能读到新值。比如：文件系统，RDBMS，Azure Table都是强一致性的。 从这三种一致型的模型上来说，我们可以看到，Weak和Eventually一般来说是异步冗余的，而Strong一般来说是同步冗余的，异步的通常意味着更好的性能，但也意味着更复杂的状态控制。同步意味着简单，但也意味着性能下降。 好，让我们由浅入深，一步一步地来看有哪些技术： Master-Slave首先是Master-Slave结构，对于这种加构，Slave一般是Master的备份。在这样的系统中，一般是如下设计的： 读写请求都由Master负责。 写请求写到Master上后，由Master同步到Slave上。 从Master同步到Slave上，你可以使用异步，也可以使用同步，可以使用Master来push，也可以使用Slave来pull。 通常来说是Slave来周期性的pull，所以，是最终一致性。这个设计的问题是，如果Master在pull周期内垮掉了，那么会导致这个时间片内的数据丢失。如果你不想让数据丢掉，Slave只能成为Read-Only的方式等Master恢复。 当然，如果你可以容忍数据丢掉的话，你可以马上让Slave代替Master工作（对于只负责计算的结点来说，没有数据一致性和数据丢失的问题，Master-Slave的方式就可以解决单点问题了） 当然，Master Slave也可以是强一致性的， 比如：当我们写Master的时候，Master负责先写自己，等成功后，再写Slave，两者都成功后返回成功，整个过程是同步的，如果写Slave失败了，那么两种方法，一种是标记Slave不可用报错并继续服务（等Slave恢复后同步Master的数据，可以有多个Slave，这样少一个，还有备份，就像前面说的写三份那样），另一种是回滚自己并返回写失败。（注：一般不先写Slave，因为如果写Master自己失败后，还要回滚Slave，此时如果回滚Slave失败，就得手工订正数据了）你可以看到，如果Master-Slave需要做成强一致性有多复杂。 Master-MasterMaster-Master，又叫Multi-master，是指一个系统存在两个或多个Master，每个Master都提供read-write服务。这个模型是Master-Slave的加强版，数据间同步一般是通过Master间的异步完成，所以是最终一致性。 Master-Master的好处是，一台Master挂了，别的Master可以正常做读写服务，他和Master-Slave一样，当数据没有被复制到别的Master上时，数据会丢失。很多数据库都支持Master-Master的Replication的机制。 另外，如果多个Master对同一个数据进行修改的时候，这个模型的恶梦就出现了——对数据间的冲突合并，这并不是一件容易的事情。看看Dynamo的Vector Clock的设计（记录数据的版本号和修改者）就知道这个事并不那么简单，而且Dynamo对数据冲突这个事是交给用户自己搞的。就像我们的SVN源码冲突一样，对于同一行代码的冲突，只能交给开发者自己来处理。（在本文后后面会讨论一下Dynamo的Vector Clock） Two/Three Phase Commit这个协议的缩写又叫2PC，中文叫两阶段提交。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。 两阶段提交的算法如下： 第一阶段：协调者会问所有的参与者结点，是否可以执行提交操作。 各个参与者开始事务执行的准备工作：如：为资源上锁，预留资源，写undo/redo log…… 参与者响应协调者，如果事务的准备工作成功，则回应“可以提交”，否则回应“拒绝提交”。 第二阶段：如果所有的参与者都回应“可以提交”，那么，协调者向所有的参与者发送“正式提交”的命令。参与者完成正式提交，并释放所有资源，然后回应“完成”，协调者收集各结点的“完成”回应后结束这个Global Transaction。如果有一个参与者回应“拒绝提交”，那么，协调者向所有的参与者发送“回滚操作”，并释放所有资源，然后回应“回滚完成”，协调者收集各结点的“回滚”回应后，取消这个Global Transaction。 我们可以看到，2PC说白了就是第一阶段做Vote，第二阶段做决定的一个算法，也可以看到2PC这个事是强一致性的算法。在前面我们讨论过Master-Slave的强一致性策略，和2PC有点相似，只不过2PC更为保守一些——先尝试再提交。2PC用的是比较多的，在一些系统设计中，会串联一系列的调用，比如：A -&gt; B -&gt; C -&gt; D，每一步都会分配一些资源或改写一些数据。比如我们B2C网上购物的下单操作在后台会有一系列的流程需要做。如果我们一步一步地做，就会出现这样的问题，如果某一步做不下去了，那么前面每一次所分配的资源需要做反向操作把他们都回收掉，所以，操作起来比较复杂。现在很多处理流程（Workflow）都会借鉴2PC这个算法，使用 try -&gt; confirm的流程来确保整个流程的能够成功完成。 举个通俗的例子，西方教堂结婚的时候，都有这样的桥段： 牧师分别问新郎和新娘：你是否愿意……不管生老病死……（询问阶段） 当新郎和新娘都回答愿意后（锁定一生的资源），牧师就会说：我宣布你们……（事务提交） 这是多么经典的一个两阶段提交的事务处理。 另外，我们也可以看到其中的一些问题，A）其中一个是同步阻塞操作，这个事情必然会非常大地影响性能。B）另一个主要的问题是在TimeOut上，比如， 如果第一阶段中，参与者没有收到询问请求，或是参与者的回应没有到达协调者。那么，需要协调者做超时处理，一旦超时，可以当作失败，也可以重试。 如果第二阶段中，正式提交发出后，如果有的参与者没有收到，或是参与者提交/回滚后的确认信息没有返回，一旦参与者的回应超时，要么重试，要么把那个参与者标记为问题结点剔除整个集群，这样可以保证服务结点都是数据一致性的。 糟糕的情况是，第二阶段中，如果参与者收不到协调者的commit/fallback指令，参与者将处于“状态未知”阶段，参与者完全不知道要怎么办，比如：如果所有的参与者完成第一阶段的回复后（可能全部yes，可能全部no，可能部分yes部分no），如果协调者在这个时候挂掉了。那么所有的结点完全不知道怎么办（问别的参与者都不行）。为了一致性，要么死等协调者，要么重发第一阶段的yes/no命令。 两段提交最大的问题就是第 3 项，如果第一阶段完成后，参与者在第二阶没有收到决策，那么数据结点会进入“不知所措”的状态，这个状态会block住整个事务。也就是说，协调者Coordinator对于事务的完成非常重要，Coordinator的可用性是个关键。 因些，我们引入三段提交，三段提交在Wikipedia上的描述如下，他把二段提交的第一个段break成了两段：询问，然后再锁资源。最后真正提交。三段提交的示意图如下： 三段提交的核心理念是：在询问的时候并不锁定资源，除非所有人都同意了，才开始锁资源。 理论上来说，如果第一阶段所有的结点返回成功，那么有理由相信成功提交的概率很大。这样一来，可以降低参与者Cohorts的状态未知的概率。也就是说，一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了。这一点很重要。 下面我们来看一下3PC的状态迁移图：（注意图中的虚线，那些F,T是Failuer或Timeout，其中的：状态含义是 q – Query，a – Abort，w – Wait，p – PreCommit，c – Commit） 从上图的状态变化图我们可以从虚线（那些F,T是Failuer或Timeout）看到——如果结点处在P状态（PreCommit）的时候发生了F/T的问题，三段提交比两段提交的好处是，三段提交可以继续直接把状态变成C状态（Commit），而两段提交则不知所措。 其实，三段提交是一个很复杂的事情，实现起来相当难，而且也有一些问题。 看到这里，我相信你有很多很多的问题，你一定在思考2PC/3PC中各种各样的失败场景，你会发现Timeout是个非常难处理的事情，因为网络上的Timeout在很多时候让你无所事从，你也不知道对方是做了还是没有做。于是你好好的一个状态机就因为Timeout成了个摆设。 一个网络服务会有三种状态： Success Failure Timeout 第三个绝对是恶梦，尤其在你需要维护状态的时候。 Two Generals Problem（两将军问题）Two Generals Problem 两将军问题是这么一个思维性实验问题：有两支军队，它们分别有一位将军领导，现在准备攻击一座修筑了防御工事的城市。这两支军队都驻扎在那座城市的附近，分占一座山头。一道山谷把两座山分隔开来，并且两位将军唯一的通信方式就是派各自的信使来往于山谷两边。不幸的是，这个山谷已经被那座城市的保卫者占领，并且存在一种可能，那就是任何被派出的信使通过山谷是会被捕。 请注意，虽然两位将军已经就攻击那座城市达成共识，但在他们各自占领山头阵地之前，并没有就进攻时间达成共识。两位将军必须让自己的军队同时进攻城市才能取得成功。因此，他们必须互相沟通，以确定一个时间来攻击，并同意就在那时攻击。如果只有一个将军进行攻击，那么这将是一个灾难性的失败。 这个思维实验就包括考虑他们如何去做这件事情。下面是我们的思考： 第一位将军先发送一段消息“让我们在上午9点开始进攻”。然而，一旦信使被派遣，他是否通过了山谷，第一位将军就不得而知了。任何一点的不确定性都会使得第一位将军攻击犹豫，因为如果第二位将军不能在同一时刻发动攻击，那座城市的驻军就会击退他的军队的进攻，导致他的军对被摧毁。 知道了这一点，第二位将军就需要发送一个确认回条：“我收到您的邮件，并会在9点的攻击。”但是，如果带着确认消息的信使被抓怎么办？所以第二位将军会犹豫自己的确认消息是否能到达。 于是，似乎我们还要让第一位将军再发送一条确认消息——“我收到了你的确认”。然而，如果这位信使被抓怎么办呢？ 这样一来，是不是我们还要第二位将军发送一个“确认收到你的确认”的信息。 靠，于是你会发现，这事情很快就发展成为不管发送多少个确认消息，都没有办法来保证两位将军有足够的自信自己的信使没有被敌军捕获。 这个问题是无解的。 两个将军问题和它的无解证明首先由E.A.Akkoyunlu,K.Ekanadham和R.V.Huber于1975年在《一些限制与折衷的网络通信设计》一文中发表，就在这篇文章的第73页中一段描述两个黑帮之间的通信中被阐明。 1978年，在Jim Gray的《数据库操作系统注意事项》一书中（从第465页开始）被命名为两个将军悖论。作为两个将军问题的定义和无解性的证明的来源，这一参考被广泛提及。 这个实验意在阐明：试图通过建立在一个不可靠的连接上的交流来协调一项行动的隐患和设计上的巨大挑战。 从工程上来说，一个解决两个将军问题的实际方法是使用一个能够承受通信信道不可靠性的方案，并不试图去消除这个不可靠性，但要将不可靠性削减到一个可以接受的程度。比如，第一位将军排出了100位信使并预计他们都被捕的可能性很小。在这种情况下，不管第二位将军是否会攻击或者受到任何消息，第一位将军都会进行攻击。另外，第一位将军可以发送一个消息流，而第二位将军可以对其中的每一条消息发送一个确认消息，这样如果每条消息都被接收到，两位将军会感觉更好。然而我们可以从证明中看出，他们俩都不能肯定这个攻击是可以协调的。他们没有算法可用（比如，收到4条以上的消息就攻击）能够确保防止仅有一方攻击。再者，第一位将军还可以为每条消息编号，说这是1号，2号……直到n号。这种方法能让第二位将军知道通信信道到底有多可靠，并且返回合适的数量的消息来确保最后一条消息被接收到。如果信道是可靠的话，只要一条消息就行了，其余的就帮不上什么忙了。最后一条和第一条消息丢失的概率是相等的。 两将军问题可以扩展成更变态的拜占庭将军问题 (Byzantine Generals Problem)，其故事背景是这样的：拜占庭位于现在土耳其的伊斯坦布尔，是东罗马帝国的首都。由于当时拜占庭罗马帝国国土辽阔，为了防御目的，因此每个军队都分隔很远，将军与将军之间只能靠信差传消息。 在战争的时候，拜占庭军队内所有将军必需达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，军队可能有叛徒和敌军间谍，这些叛徒将军们会扰乱或左右决策的过程。这时候，在已知有成员谋反的情况下，其余忠诚的将军在不受叛徒的影响下如何达成一致的协议，这就是拜占庭将军问题。 Paxos算法Wikipedia上的各种Paxos算法)的描述非常详细，大家可以去围观一下。 Paxos 算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个「一致性算法」以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。从20世纪80年代起对于一致性算法的研究就没有停止过。 Notes：Paxos算法是莱斯利·兰伯特（Leslie Lamport，就是 LaTeX 中的”La”，此人现在在微软研究院）于1990年提出的一种基于消息传递的一致性算法。由于算法难以理解起初并没有引起人们的重视，使Lamport在八年后1998年重新发表到ACM Transactions on Computer Systems上（The Part-Time Parliament）。即便如此paxos算法还是没有得到重视，2001年Lamport 觉得同行无法接受他的幽默感，于是用容易接受的方法重新表述了一遍（Paxos Made Simple）。可见Lamport对Paxos算法情有独钟。近几年Paxos算法的普遍使用也证明它在分布式一致性算法中的重要地位。2006年Google的三篇论文初现“云”的端倪，其中的Chubby Lock服务使用Paxos作为Chubby Cell中的一致性算法，Paxos的人气从此一路狂飙。（Lamport 本人在 他的blog 中描写了他用9年时间发表这个算法的前前后后） 注：Amazon的AWS中，所有的云服务都基于一个ALF（Async Lock Framework）的框架实现的，这个ALF用的就是Paxos算法。我在Amazon的时候，看内部的分享视频时，设计者在内部的Principle Talk里说他参考了ZooKeeper的方法，但他用了另一种比ZooKeeper更易读的方式实现了这个算法。 简单说来，Paxos的目的是让整个集群的结点对某个值的变更达成一致。Paxos算法基本上来说是个民主选举的算法——大多数的决定会成个整个集群的统一决定。任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以Paxos算法需要集群中的结点是单数）。 这个算法有两个阶段（假设这个有三个结点：A，B，C）： 第一阶段：Prepare阶段A把申请修改的请求Prepare Request发给所有的结点A，B，C。注意，Paxos算法会有一个Sequence Number（你可以认为是一个提案号，这个数不断递增，而且是唯一的，也就是说A和B不可能有相同的提案号），这个提案号会和修改请求一同发出，任何结点在“Prepare阶段”时都会拒绝其值小于当前提案号的请求。所以，结点A在向所有结点申请修改请求的时候，需要带一个提案号，越新的提案，这个提案号就越是是最大的。如果接收结点收到的提案号n大于其它结点发过来的提案号，这个结点会回应Yes（本结点上最新的被批准提案号），并保证不接收其它&lt;n的提案。这样一来，结点上在Prepare阶段里总是会对最新的提案做承诺。优化：在上述 prepare 过程中，如果任何一个结点发现存在一个更高编号的提案，则需要通知 提案人，提醒其中断这次提案。 第二阶段：Accept阶段如果提案者A收到了超过半数的结点返回的Yes，然后他就会向所有的结点发布Accept Request（同样，需要带上提案号n），如果没有超过半数的话，那就返回失败。当结点们收到了Accept Request后，如果对于接收的结点来说，n是最大的了，那么，它就会修改这个值，如果发现自己有一个更大的提案号，那么，结点就会拒绝修改。 我们可以看以，这似乎就是一个“两段提交”的优化。其实，2PC/3PC都是分布式一致性算法的残次版本，Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。 我们还可以看到：对于同一个值的在不同结点的修改提案就算是在接收方被乱序收到也是没有问题的。 关于一些实例，你可以看一下Wikipedia中文中的“Paxos样例”一节，我在这里就不再多说了。对于Paxos算法中的一些异常示例，大家可以自己推导一下。你会发现基本上来说只要保证有半数以上的结点存活，就没有什么问题。 多说一下，自从Lamport在1998年发表Paxos算法后，对Paxos的各种改进工作就从未停止，其中动作最大的莫过于2005年发表的Fast Paxos。无论何种改进，其重点依然是在消息延迟与性能、吞吐量之间作出各种权衡。为了容易地从概念上区分二者，称前者Classic Paxos，改进后的后者为Fast Paxos。 总结下图来自：Google App Engine的co-founder Ryan Barrett在2009年的google i/o上的演讲《Transaction Across DataCenter》（视频： http://www.youtube.com/watch?v=srOgpXECblk） 前面，我们说过，要想让数据有高可用性，就需要冗余数据写多份。写多份的问题会带来一致性的问题，而一致性的问题又会带来性能问题。从上图我们可以看到，我们基本上来说不可以让所有的项都绿起来，这就是著名的CAP理论：一致性，可用性，分区容忍性，你只可能要其中的两个。 NWR模型最后我还想提一下Amazon Dynamo的NWR模型。这个NWR模型把CAP的选择权交给了用户，让用户自己的选择你的CAP中的哪两个。 所谓NWR模型。N代表N个备份，W代表要写入至少W份才认为成功，R表示至少读取R个备份。配置的时候要求W+R &gt; N。 因为W+R &gt; N， 所以 R &gt; N-W 这个是什么意思呢？就是读取的份数一定要比总备份数减去确保写成功的倍数的差值要大。 也就是说，每次读取，都至少读取到一个最新的版本。从而不会读到一份旧数据。当我们需要高可写的环境的时候，我们可以配置W = 1 如果N=3 那么R = 3。 这个时候只要写任何节点成功就认为成功，但是读的时候必须从所有的节点都读出数据。如果我们要求读的高效率，我们可以配置 W=N R=1。这个时候任何一个节点读成功就认为成功，但是写的时候必须写所有三个节点成功才认为成功。 NWR模型的一些设置会造成脏数据的问题，因为这很明显不是像Paxos一样是一个强一致的东西，所以，可能每次的读写操作都不在同一个结点上，于是会出现一些结点上的数据并不是最新版本，但却进行了最新的操作。 所以，Amazon Dynamo引了数据版本的设计。也就是说，如果你读出来数据的版本是v1，当你计算完成后要回填数据后，却发现数据的版本号已经被人更新成了v2，那么服务器就会拒绝你。版本这个事就像“乐观锁”一样。 但是，对于分布式和NWR模型来说，版本也会有恶梦的时候——就是版本冲的问题，比如：我们设置了N=3 W=1，如果A结点上接受了一个值，版本由v1 -&gt; v2，但还没有来得及同步到结点B上（异步的，应该W=1，写一份就算成功），B结点上还是v1版本，此时，B结点接到写请求，按道理来说，他需要拒绝掉，但是他一方面并不知道别的结点已经被更新到v2，另一方面他也无法拒绝，因为W=1，所以写一分就成功了。于是，出现了严重的版本冲突。 Amazon的Dynamo把版本冲突这个问题巧妙地回避掉了——版本冲这个事交给用户自己来处理。 于是，Dynamo引入了Vector Clock（矢量钟？!）这个设计。这个设计让每个结点各自记录自己的版本信息，也就是说，对于同一个数据，需要记录两个事：1）谁更新的我，2）我的版本号是什么。 下面，我们来看一个操作序列： 一个写请求，第一次被节点A处理了。节点A会增加一个版本信息(A，1)。我们把这个时候的数据记做D1(A，1)。 然后另外一个对同样key的请求还是被A处理了于是有D2(A，2)。这个时候，D2是可以覆盖D1的，不会有冲突产生。 现在我们假设D2传播到了所有节点(B和C)，B和C收到的数据不是从客户产生的，而是别人复制给他们的，所以他们不产生新的版本信息，所以现在B和C所持有的数据还是D2(A，2)。于是A，B，C上的数据及其版本号都是一样的。 如果我们有一个新的写请求到了B结点上，于是B结点生成数据D3(A,2; B,1)，意思是：数据D全局版本号为3，A升了两新，B升了一次。这不就是所谓的代码版本的log么？ 如果D3没有传播到C的时候又一个请求被C处理了，于是，以C结点上的数据是D4(A,2; C,1)。 好，最精彩的事情来了：如果这个时候来了一个读请求，我们要记得，我们的W=1 那么R=N=3，所以R会从所有三个节点上读，此时，他会读到三个版本： A结点：D2(A,2) B结点：D3(A,2; B,1); C结点：D4(A,2; C,1) 这个时候可以判断出，D2已经是旧版本（已经包含在D3/D4中），可以舍弃。 但是D3和D4是明显的版本冲突。于是，交给调用方自己去做版本冲突处理。就像源代码版本管理一样。 很明显，上述的Dynamo的配置用的是CAP里的A和P。 我非常推大家都去看看这篇论文：《Dynamo：Amazon’s Highly Available Key-Value Store》，如果英文痛苦，你可以看看译文（译者不详）。 本文转载自：酷 壳]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[10种排序算法]]></title>
      <url>%2F20170502%2F10_algorithm_of_sort%2F</url>
      <content type="text"><![CDATA[排序算法有很多，所以在特定情景中使用哪一种算法很重要。为了选择合适的算法，可以按照建议的顺序考虑以下标准： 执行时间 存储空间 编程工作 对于数据量较小的情形，①、②差别不大，主要考虑③；而对于数据量大的，①为首要。 主要排序法有： 冒泡（Bubble）排序——相邻交换 选择排序——每次最小/大排在相应的位置 插入排序——将下一个插入已排好的序列中 壳（Shell）排序——缩小增量 归并排序 快速排序 堆排序 拓扑排序 锦标赛排序 基数排序 冒泡（Bubble）排序12345678910111213141516171819202122232425/** * 冒泡排序 * 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 * 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 * 针对所有的元素重复以上的步骤，除了最后一个。 * 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 * @param numbers 需要排序的整型数组 */ public static void bubbleSort(int[] numbers) &#123; int temp = 0; int size = numbers.length; for(int i = 0 ; i &lt; size-1; i ++) &#123; for(int j = 0 ;j &lt; size-1-i ; j++) &#123; if(numbers[j] &gt; numbers[j+1]) //交换两数位置 &#123; temp = numbers[j]; numbers[j] = numbers[j+1]; numbers[j+1] = temp; &#125; &#125; &#125; &#125; 效率 O（n²）,适用于排序小列表。 选择排序基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 1234567891011121314151617181920212223242526272829/** * 选择排序算法 * 在未排序序列中找到最小元素，存放到排序序列的起始位置 * 再从剩余未排序元素中继续寻找最小元素，然后放到排序序列末尾。 * 以此类推，直到所有元素均排序完毕。 * @param numbers */ public static void selectSort(int[] numbers) &#123; int size = numbers.length; //数组长度 int temp = 0 ; //中间变量 for(int i = 0 ; i &lt; size ; i++) &#123; int k = i; //待确定的位置 //选择出应该在第i个位置的数 for(int j = size -1 ; j &gt; i ; j--) &#123; if(numbers[j] &lt; numbers[k]) &#123; k = j; &#125; &#125; //交换两个数 temp = numbers[i]; numbers[i] = numbers[k]; numbers[k] = temp; &#125; &#125; 效率O（n²），适用于排序小的列表。 插入排序基本思想：每步将一个待排序的记录，按其顺序码大小插入到前面已经排序的字序列的合适位置（从后向前找到合适位置后），直到全部插入排序完为止。 12345678910111213141516171819202122232425262728/** * 插入排序 * * 从第一个元素开始，该元素可以认为已经被排序 * 取出下一个元素，在已经排序的元素序列中从后向前扫描 * 如果该元素（已排序）大于新元素，将该元素移到下一位置 * 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 * 将新元素插入到该位置中 * 重复步骤2 * @param numbers 待排序数组 */ public static void insertSort(int[] numbers) &#123; int size = numbers.length; int temp = 0 ; int j = 0; for(int i = 0 ; i &lt; size ; i++) &#123; temp = numbers[i]; //假如temp比前面的值小，则将前面的值后移 for(j = i ; j &gt; 0 &amp;&amp; temp &lt; numbers[j-1] ; j --) &#123; numbers[j] = numbers[j-1]; &#125; numbers[j] = temp; &#125; &#125; 最佳效率O（n）；最糟效率O（n²）与冒泡、选择相同，适用于排序小列表 若列表基本有序，则插入排序比冒泡、选择更有效率。 壳（Shell）排序——缩小增量排序基本思想：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。 操作方法： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 12345678910111213141516171819202122232425262728293031323334353637/**希尔排序的原理:根据需求，如果你想要结果从大到小排列，它会首先将数组进行分组，然后将较大值移到前面，较小值 * 移到后面，最后将整个数组进行插入排序，这样比起一开始就用插入排序减少了数据交换和移动的次数，可以说希尔排序是加强 * 版的插入排序 * 拿数组5, 2, 8, 9, 1, 3，4来说，数组长度为7，当increment为3时，数组分为两个序列 * 5，2，8和9，1，3，4，第一次排序，9和5比较，1和2比较，3和8比较，4和比其下标值小increment的数组值相比较 * 此例子是按照从大到小排列，所以大的会排在前面，第一次排序后数组为9, 2, 8, 5, 1, 3，4 * 第一次后increment的值变为3/2=1,此时对数组进行插入排序， *实现数组从大到小排 */ public static void shellSort(int[] data) &#123; int j = 0; int temp = 0; //每次将步长缩短为原来的一半 for (int increment = data.length / 2; increment &gt; 0; increment /= 2) &#123; for (int i = increment; i &lt; data.length; i++) &#123; temp = data[i]; for (j = i; j &gt;= increment; j -= increment) &#123; if(temp &gt; data[j - increment])//如想从小到大排只需修改这里 &#123; data[j] = data[j - increment]; &#125; else &#123; break; &#125; &#125; data[j] = temp; &#125; &#125; &#125; 适用于排序小列表。效率估计 O（nlog2^n）~O（n^1.5） ，取决于增量值的最初大小。建议使用质数作为增量值，因为如果增量值是2的幂，则在下一个通道中会再次比较相同的元素。 壳（Shell）排序改进了插入排序，减少了比较的次数。是不稳定的排序，因为排序过程中元素可能会前后跳跃。 归并排序基本思想： 归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 合并方法： 设r[i…n]由两个有序子表r[i…m]和r[m+1…n]组成，两个子表长度分别为n-i +1、n-m。 j=m+1；k=i；i=i; //置两个子表的起始下标及辅助数组的起始下标 若i&gt;m 或j&gt;n，转⑷ //其中一个子表已合并完，比较选取结束 //选取r[i]和r[j]较小的存入辅助数组rf如果r[i]&lt;r[j]，rf[k]=r[i]； i++； k++； 转⑵否则，rf[k]=r[j]； j++； k++； 转⑵ //将尚未处理完的子表中元素存入rf如果i&lt;=m，将r[i…m]存入rf[k…n] //前一子表非空如果j&lt;=n , 将r[j…n] 存入rf[k…n] //后一子表非空 合并结束。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 归并排序 * 简介:将两个（或两个以上）有序表合并成一个新的有序表 即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列 * 时间复杂度为O(nlogn) * 稳定排序方式 * @param nums 待排序数组 * @return 输出有序数组 */ public static int[] sort(int[] nums, int low, int high) &#123; int mid = (low + high) / 2; if (low &lt; high) &#123; // 左边 sort(nums, low, mid); // 右边 sort(nums, mid + 1, high); // 左右归并 merge(nums, low, mid, high); &#125; return nums; &#125; /** * 将数组中low到high位置的数进行排序 * @param nums 待排序数组 * @param low 待排的开始位置 * @param mid 待排中间位置 * @param high 待排结束位置 */ public static void merge(int[] nums, int low, int mid, int high) &#123; int[] temp = new int[high - low + 1]; int i = low;// 左指针 int j = mid + 1;// 右指针 int k = 0; // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (nums[i] &lt; nums[j]) &#123; temp[k++] = nums[i++]; &#125; else &#123; temp[k++] = nums[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = nums[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = nums[j++]; &#125; // 把新数组中的数覆盖nums数组 for (int k2 = 0; k2 &lt; temp.length; k2++) &#123; nums[k2 + low] = temp[k2]; &#125; &#125; 效率O（nlogn），归并的最佳、平均和最糟用例效率之间没有差异。适用于排序大列表，基于分治法。 快速排序基本思想：选择一个基准元素,通常选择第一个元素或者最后一个元素,通过一趟扫描，将待排序列分成两部分,一部分比基准元素小,一部分大于等于基准元素,此时基准元素在其排好序后的正确位置,然后再用同样的方法递归地排序划分的两部分。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 归并排序 * 简介:将两个（或两个以上）有序表合并成一个新的有序表 即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列 * 时间复杂度为O(nlogn) * 稳定排序方式 * @param nums 待排序数组 * @return 输出有序数组 */ public static int[] sort(int[] nums, int low, int high) &#123; int mid = (low + high) / 2; if (low &lt; high) &#123; // 左边 sort(nums, low, mid); // 右边 sort(nums, mid + 1, high); // 左右归并 merge(nums, low, mid, high); &#125; return nums; &#125; /** * 将数组中low到high位置的数进行排序 * @param nums 待排序数组 * @param low 待排的开始位置 * @param mid 待排中间位置 * @param high 待排结束位置 */ public static void merge(int[] nums, int low, int mid, int high) &#123; int[] temp = new int[high - low + 1]; int i = low;// 左指针 int j = mid + 1;// 右指针 int k = 0; // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (nums[i] &lt; nums[j]) &#123; temp[k++] = nums[i++]; &#125; else &#123; temp[k++] = nums[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = nums[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = nums[j++]; &#125; // 把新数组中的数覆盖nums数组 for (int k2 = 0; k2 &lt; temp.length; k2++) &#123; nums[k2 + low] = temp[k2]; &#125; &#125; 平均效率O（nlogn），适用于排序大列表。 此算法的总时间取决于枢纽值的位置；选择第一个元素作为枢纽，可能导致O（n²）的最糟用例效率。若数基本有序，效率反而最差。选项中间值作为枢纽，效率是O（nlogn）。基于分治法。 堆排序基本思想： 堆排序是一种树形选择排序，是对直接选择排序的有效改进。堆的定义下： 具有n个元素的序列 （h1,h2,…,hn),当且仅当满足（hi&gt;=h2i,hi&gt;=2i+1）或（hi&lt;=h2i,hi&lt;=2i+1） (i=1,2,…,n/2)时称之为堆。在这里只讨论满足前者条件的堆。由堆的定义可以看出，堆顶元素（即第一个元素）必为最大项（大顶堆）。完全二 叉树可以很直观地表示堆的结构。堆顶为根，其它为左子树、右子树。 思想:初始时把要排序的数的序列看作是一棵顺序存储的二叉树，调整它们的存储序，使之成为一个 堆，这时堆的根节点的数最大。然后将根节点与堆的最后一个节点交换。然后对前面(n-1)个数重新调整使之成为堆。依此类推，直到只有两个节点的堆，并对它们作交换，最后得到有n个节点的有序序列。从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆的渗透函数，二是反复调用渗透函数实现排序的函数。 实例 初始序列：46,79,56,38,40,84 建堆： 交换，从堆中踢出最大数: 依次类推：最后堆中剩余的最后两个结点交换，踢出一个，排序完成。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class HeapSort &#123; public static void main(String[] args) &#123; int[] a=&#123;49,38,65,97,76,13,27,49,78,34,12,64&#125;; int arrayLength=a.length; //循环建堆 for(int i=0;i&lt;arrayLength-1;i++)&#123; //建堆 buildMaxHeap(a,arrayLength-1-i); //交换堆顶和最后一个元素 swap(a,0,arrayLength-1-i); System.out.println(Arrays.toString(a)); &#125; &#125; //对data数组从0到lastIndex建大顶堆 public static void buildMaxHeap(int[] data, int lastIndex)&#123; //从lastIndex处节点（最后一个节点）的父节点开始 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //k保存正在判断的节点 int k=i; //如果当前k节点的子节点存在 while(k*2+1&lt;=lastIndex)&#123; //k节点的左子节点的索引 int biggerIndex=2*k+1; //如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if(biggerIndex&lt;lastIndex)&#123; //若果右子节点的值较大 if(data[biggerIndex]&lt;data[biggerIndex+1])&#123; //biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; //如果k节点的值小于其较大的子节点的值 if(data[k]&lt;data[biggerIndex])&#123; //交换他们 swap(data,k,biggerIndex); //将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值 k=biggerIndex; &#125;else&#123; break; &#125; &#125; &#125; &#125; //交换 private static void swap(int[] data, int i, int j) &#123; int tmp=data[i]; data[i]=data[j]; data[j]=tmp; &#125; &#125; 堆排序的时间，主要由建立初始堆和反复重建堆这两部分的时间开销构成，它们均是通过调用Heapify实现的。 堆排序的最坏时间复杂度为O(nlgn)。堆排序的平均性能较接近于最坏性能。由于建初始堆所需的比较次数较多，所以堆排序不适宜于记录数较少的文件。堆排序是就地排序，辅助空间为O(1)，它是不稳定的排序方法。 堆排序与直接插入排序的区别: 直接选择排序中，为了从R[1..n]中选出关键字最小的记录，必须进行n-1次比较，然后在R[2..n]中选出关键字最小的记录，又需要做n-2次比较。事实上，后面的n-2次比较中，有许多比较可能在前面的n-1次比较中已经做过，但由于前一趟排序时未保留这些比较结果，所以后一趟排序时又重复执行了这些比较操作。 堆排序可通过树形结构保存部分比较结果，可减少比较次数。 拓扑排序 (这个较复杂，开文另说)例 ：学生选修课排课先后顺序 拓扑排序：把有向图中各顶点按照它们相互之间的优先关系排列成一个线性序列的过程。方法： 在有向图中选一个没有前驱的顶点且输出 从图中删除该顶点和所有以它为尾的弧 重复上述两步，直至全部顶点均已输出（拓扑排序成功），或者当图中不存在无前驱的顶点（图中有回路）为止。 123456789101112131415161718192021222324252627282930313233343536void TopologicalSort()/*输出拓扑排序函数。若G无回路，则输出G的顶点的一个拓扑序列并返回OK，否则返回ERROR*/ &#123; int indegree[ M]; int i, k, j; char n; int count = 0; Stack thestack; FindInDegree(G, indegree);//对各顶点求入度indegree[0....num] InitStack(thestack);//初始化栈 for (i = 0; i &lt; G.num; i++) Console.WriteLine("结点" + G.vertices[i].data + "的入度为" + indegree[i]); for (i = 0; i &lt; G.num; i++) &#123; if (indegree[i] == 0) Push(thestack.vertices[i]); &#125; Console.Write("拓扑排序输出顺序为："); while (thestack.Peek() != null) &#123; Pop(thestack.Peek()); j = locatevex(G, n); if (j == -2) &#123; Console.WriteLine("发生错误，程序结束。"); exit(); &#125; Console.Write(G.vertices[j].data); count++; for (p = G.vertices[j].firstarc; p != NULL; p = p.nextarc) &#123; k = p.adjvex; if (!(--indegree[k])) Push(G.vertices[k]); &#125; &#125; if (count &lt; G.num) Cosole.WriteLine("该图有环，出现错误，无法排序。"); else Console.WriteLine("排序成功。");&#125; 算法的时间复杂度O（n+e）。 锦标赛排序例子：假如有N 人报名参加联赛，服务器记录下报名人数，并对这些人的战斗后的结果进行排序，决出前16强或者8强。 建树：这里说的建树是建立一颗完全二叉树。当参加排序的数组不足2的N次幂，将其补足。直到满足建立一个完全二叉树 当某结点的比较对手的参选标志为“不再参选”，该结点自动升入双亲结点，此动作不计入排序码比较次数。每次比较出来的第一名都标记为不参赛。 最终结果是返回到原来的数组之中 堆排序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165/** * 联赛系统分组 * * @author Administrator */public class Competition &#123; /** * Player改为玩家ID存储 */ private Player[] playerArray; public Competition() &#123; int playerNum = World.getIns().getCompetition().size(); Player[] playerArray = (Player[]) World.getIns().getCompetition() .toArray(); TournamentSort(playerArray,playerNum); //比赛后结果排序按照数组顺序，放入playerArray中 &#125; /** * 创建一颗树 * @param a * @param n */ public static void TournamentSort(Player[] player, int n) &#123; TournamentPlayer[] tree; int bottomRowSize = nearestPowerOfTwo(n);// 计算满足&gt;=n的2的最小次幂的数: int TreeSize = 2 * bottomRowSize - 1; int loadindex = bottomRowSize - 1; // 外结点开始位置：从根节点开始往下数 tree = new TournamentPlayer[TreeSize]; for (int i = 0; i &lt; TreeSize; i++) &#123; tree[i] = new TournamentPlayer(); &#125; int j = 0; // 在数组player中取数据指针 for (int i = loadindex; i &lt; TreeSize; i++) &#123; // 复制数组数据到树的外结点中 tree[i].setIndex(i); // 下标 if (j &lt; n) &#123; tree[i].setActive(1); tree[i].setData(player[j++]); &#125; // 复制数据 else &#123; tree[i].setActive(0); // 后面的结点为空的外结点 &#125; // System.out.println(tree[i].getIndex()+" "+ tree[i].getData()); &#125; int i = loadindex; // 进行初始比较寻找最小的项 while (i != 0) &#123; j = i; while (j &lt; 2 * i) &#123; // 处理各对比赛者 Player playerRight = tree[j].getData(); Player playerLeft = tree[j + 1].getData(); // @ TODO 计算战斗，返回左边赢 boolean isLeftWin = true; if (tree[j + 1].getActive() == 0 || isLeftWin == true) tree[(j - 1) / 2] = tree[j]; // 胜者送入双亲 else tree[(j - 1) / 2] = tree[j + 1]; // System.out.println(tree[(j - 1) / 2].getIndex()+" "+ tree[(j // - 1) / 2].getData()); j += 2; // 下一对参加比较的项 &#125; i = (i - 1) / 2; // i退到双亲, 直到i=0为止 // System.out.println(tree[(j - 1) / 2].getIndex() + " " // + tree[(j - 1) / 2].getData()); &#125; for (i = 0; i &lt; n - 1; i++) &#123; // 处理其它n-1元素 player[i] = tree[0].getData(); // 当前最小元素送数组a System.out.println(player[i]); tree[tree[0].getIndex()].setActive(0); // 该元素相应外结点不再比赛 UpdateTree(tree, tree[0].getIndex()); // 从该处向上修改 &#125; player[n - 1] = tree[0].getData(); System.out.println(player[n - 1]); // return tree; &#125; /** * 每次比较出胜者之后，更新得到下一次比较的胜者 * i是表中当前最小元素的下标, 即胜者。从它开始向上调整。 * @param tree * @param i */ public static void UpdateTree(TournamentPlayer[] tree, int i) &#123; if (i % 2 == 0) tree[(i - 1) / 2] = tree[i - 1]; // i为偶数, 对手为左结点 else tree[(i - 1) / 2] = tree[i + 1]; // i为奇数, 对手为右结点 // 最小元素输出之后, 它的对手上升到父结点位置 i = (i - 1) / 2; int j = 0;// i上升到双亲结点位置 while (i != 0) &#123; if (i % 2 == 0) j = i - 1; // 确定i的对手是左结点还是右结点 else j = i + 1; if (tree[i].getActive() == 0 || tree[j].getActive() == 0) &#123;// 比赛对手中间有一个为空 if (tree[i].getActive() != 0) tree[(i - 1) / 2] = tree[i]; else tree[(i - 1) / 2] = tree[j]; &#125;// 非空者上升到双亲结点 else // 比赛对手都不为空 &#123; Player playerRight = tree[i].getData(); Player playerLeft = tree[j].getData(); // @ TODO 计算战斗，返回左边赢 boolean isLeftWin = true; if (isLeftWin) tree[(i - 1) / 2] = tree[i]; else tree[(i - 1) / 2] = tree[j]; // 胜者上升到双亲结点 i = (i - 1) / 2; // i上升到双亲结点 &#125; &#125; &#125; /** * 得到最接近且大于 * number的2的N的方 * @param number * @return */ public static int nearestPowerOfTwo(int number) &#123; --number; number |= number &gt;&gt; 16; number |= number &gt;&gt; 8; number |= number &gt;&gt; 4; number |= number &gt;&gt; 2; number |= number &gt;&gt; 1; ++number; return number; &#125; public static void main(String[] args) &#123; Player[] relust = new Competition().getPlayerArray(); &#125; public Player[] getPlayerArray() &#123; return playerArray; &#125; public void setPlayerArray(Player[] playerArray) &#123; this.playerArray = playerArray; &#125;&#125; 基数排序基本思想：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序列。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 基数排序 * 平均O(d(n+r)),最好O(d(n+r)),最坏O(d(n+r));空间复杂度O(n+r);稳定;较复杂 * d为位数,r为分配后链表的个数 * @author zeng * */public class RadixSort &#123; //pos=1表示个位，pos=2表示十位 public static int getNumInPos(int num, int pos) &#123; int tmp = 1; for (int i = 0; i &lt; pos - 1; i++) &#123; tmp *= 10; &#125; return (num / tmp) % 10; &#125; //求得最大位数d public static int getMaxWeishu(int[] a) &#123; int max = a[0]; for (int i = 0; i &lt; a.length; i++) &#123; if (a[i] &gt; max) max = a[i]; &#125; int tmp = 1, d = 1; while (true) &#123; tmp *= 10; if (max / tmp != 0) &#123; d++; &#125; else break; &#125; return d; &#125; public static void radixSort(int[] a, int d) &#123; int[][] array = new int[10][a.length + 1]; for (int i = 0; i &lt; 10; i++) &#123; array[i][0] = 0;// array[i][0]记录第i行数据的个数 &#125; for (int pos = 1; pos &lt;= d; pos++) &#123; for (int i = 0; i &lt; a.length; i++) &#123;// 分配过程 int row = getNumInPos(a[i], pos); int col = ++array[row][0]; array[row][col] = a[i]; &#125; for (int row = 0, i = 0; row &lt; 10; row++) &#123;// 收集过程 for (int col = 1; col &lt;= array[row][0]; col++) &#123; a[i++] = array[row][col]; &#125; array[row][0] = 0;// 复位，下一个pos时还需使用 &#125; &#125; &#125; public static void main(String[] args) &#123; int[] a = &#123; 49, 38, 65, 197, 76, 213, 27, 50 &#125;; radixSort(a, getMaxWeishu(a)); for (int i : a) System.out.print(i + " "); &#125;&#125; 平均O(d(n+r)),最好O(d(n+r)),最坏O(d(n+r));空间复杂度O(n+r);稳定;较复杂]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8 Lambda表达式]]></title>
      <url>%2F20170502%2Fjava8_lambda%2F</url>
      <content type="text"><![CDATA[什么是λ表达式λ表达式本质上是一个匿名方法。让我们来看下面这个例子：123public int add(int x, int y) &#123; return x + y;&#125; 转成λ表达式后是这个样子：1(int x, int y) -&gt; x + y; 参数类型也可以省略，Java编译器会根据上下文推断出来：1(x, y) -&gt; x + y; //返回两数之和 或者1(x, y) -&gt; &#123; return x + y; &#125; //显式指明返回值 可见λ表达式有三部分组成： 参数列表; 箭头（-&gt;）; 以及一个表达式或语句块。 下面这个例子里的λ表达式没有参数，也没有返回值（相当于一个方法接受0个参数，返回void，其实就是Runnable里run方法的一个实现）：1() -&gt; &#123; System.out.println("Hello Lambda!"); &#125; 如果只有一个参数且可以被Java推断出类型，那么参数列表的括号也可以省略：1c -&gt; &#123; return c.size(); &#125; λ表达式的类型（它是Object吗？）λ表达式可以被当做是一个Object（注意措辞）。λ表达式的类型，叫做“目标类型（target type）”。λ表达式的目标类型是“函数接口（functional interface）”，这是Java8新引入的概念。它的定义是：一个接口，如果只有一个显式声明的抽象方法，那么它就是一个函数接口。一般用@FunctionalInterface标注出来（也可以不标）。举例如下：12345678@FunctionalInterfacepublic interface Runnable &#123; void run(); &#125; public interface Callable&lt;V&gt; &#123; V call() throws Exception; &#125; public interface ActionListener &#123; void actionPerformed(ActionEvent e); &#125; public interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2); boolean equals(Object obj); &#125; 注意最后这个Comparator接口。它里面声明了两个方法，貌似不符合函数接口的定义，但它的确是函数接口。这是因为equals方法是Object的，所有的接口都会声明Object的public方法——虽然大多是隐式的。所以，Comparator显式的声明了equals不影响它依然是个函数接口。你可以用一个λ表达式为一个函数接口赋值：1Runnable r1 = () -&gt; &#123;System.out.println("Hello Lambda!");&#125;; 然后再赋值给一个Object：12345 Object obj = r1;``` 但却不能这样干：```java Object obj = () -&gt; &#123;System.out.println("Hello Lambda!");&#125;; // ERROR! Object is not a functional interface! 必须显式的转型成一个函数接口才可以：1Object o = (Runnable) () -&gt; &#123; System.out.println("hi"); &#125;; // correct 一个λ表达式只有在转型成一个函数接口后才能被当做Object使用。所以下面这句也不能编译：1System.out.println( () -&gt; &#123;&#125; ); //错误! 目标类型不明 必须先转型:1System.out.println( (Runnable)() -&gt; &#123;&#125; ); // 正确 假设你自己写了一个函数接口，长的跟Runnable一模一样：1234@FunctionalInterfacepublic interface MyRunnable &#123; public void run();&#125; 那么12Runnable r1 = () -&gt; &#123;System.out.println("Hello Lambda!");&#125;;MyRunnable2 r2 = () -&gt; &#123;System.out.println("Hello Lambda!");&#125;; 都是正确的写法。这说明一个λ表达式可以有多个目标类型（函数接口），只要函数匹配成功即可。但需注意一个λ表达式必须至少有一个目标类型。JDK预定义了很多函数接口以避免用户重复定义。最典型的是Function：1234@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t);&#125; 这个接口代表一个函数，接受一个T类型的参数，并返回一个R类型的返回值。另一个预定义函数接口叫做Consumer，跟Function的唯一不同是它没有返回值。1234@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; void accept(T t);&#125; 还有一个Predicate，用来判断某项条件是否满足。经常用来进行筛滤操作：123456789101112131415161718192021 @FunctionalInterface public interface Predicate&lt;T&gt; &#123; boolean test(T t); &#125;``` 综上所述，一个λ表达式其实就是定义了一个匿名方法，只不过这个方法必须符合至少一个函数接口。 # λ表达式的使用## λ表达式用在何处λ表达式主要用于替换以前广泛使用的内部匿名类，各种回调，比如事件响应器、传入Thread类的Runnable等。看下面的例子：```java Thread oldSchool = new Thread( new Runnable () &#123; @Override public void run() &#123; System.out.println("This is from an anonymous class."); &#125; &#125; ); Thread gaoDuanDaQiShangDangCi = new Thread( () -&gt; &#123; System.out.println("This is from an anonymous method (lambda exp)."); &#125; ); 注意第二个线程里的λ表达式，你并不需要显式地把它转成一个Runnable，因为Java能根据上下文自动推断出来：一个Thread的构造函数接受一个Runnable参数，而传入的λ表达式正好符合其run()函数，所以Java编译器推断它为Runnable。 从形式上看，λ表达式只是为你节省了几行代码。但将λ表达式引入Java的动机并不仅仅为此。Java8有一个短期目标和一个长期目标。 短期目标是：配合“集合类批处理操作”的内部迭代和并行处理（下面将要讲到）； 长期目标是将Java向函数式编程语言这个方向引导（并不是要完全变成一门函数式编程语言，只是让它有更多的函数式编程语言的特性），也正是由于这个原因，Oracle并没有简单地使用内部类去实现λ表达式，而是使用了一种更动态、更灵活、易于将来扩展和改变的策略（invokedynamic）。 λ表达式与集合类批处理操作（或者叫块操作）上文提到了集合类的批处理操作。这是Java8的另一个重要特性，它与λ表达式的配合使用乃是Java8的最主要特性。集合类的批处理操作API的目的是实现集合类的“内部迭代”，并期望充分利用现代多核CPU进行并行计算。 Java8之前集合类的迭代（Iteration）都是外部的，即客户代码。而内部迭代意味着改由Java类库来进行迭代，而不是客户代码。例如：123for(Object o: list) &#123; // 外部迭代 System.out.println(o);&#125; 可以写成：1list.forEach(o -&gt; &#123;System.out.println(o);&#125;); //forEach函数实现内部迭代 集合类（包括List）现在都有一个forEach方法，对元素进行迭代（遍历），所以我们不需要再写for循环了。forEach方法接受一个函数接口Consumer做参数，所以可以使用λ表达式。 这种内部迭代方法广泛存在于各种语言，如C++的STL算法库、python、ruby、scala等。 Java8为集合类引入了另一个重要概念：流（stream）。一个流通常以一个集合类实例为其数据源，然后在其上定义各种操作。流的API设计使用了管道（pipelines）模式。对流的一次操作会返回另一个流。如同IO的API或者StringBuffer的append方法那样，从而多个不同的操作可以在一个语句里串起来。看下面的例子：1234List&lt;Shape&gt; shapes = ...shapes.stream() .filter(s -&gt; s.getColor() == BLUE) .forEach(s -&gt; s.setColor(RED)); 首先调用stream方法，以集合类对象shapes里面的元素为数据源，生成一个流。然后在这个流上调用filter方法，挑出蓝色的，返回另一个流。最后调用forEach方法将这些蓝色的物体喷成红色。（forEach方法不再返回流，而是一个终端方法，类似于StringBuffer在调用若干append之后的那个toString）filter方法的参数是Predicate类型，forEach方法的参数是Consumer类型，它们都是函数接口，所以可以使用λ表达式。还有一个方法叫parallelStream()，顾名思义它和stream()一样，只不过指明要并行处理，以期充分利用现代CPU的多核特性。1shapes.parallelStream(); // 或shapes.stream().parallel() 来看更多的例子。下面是典型的大数据处理方法，Filter-Map-Reduce：12345678910//给出一个String类型的数组，找出其中所有不重复的素数public void distinctPrimary(String... numbers) &#123; List&lt;String&gt; l = Arrays.asList(numbers); List&lt;Integer&gt; r = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .distinct() .collect(Collectors.toList()); System.out.println("distinctPrimary result is: " + r);&#125; 第一步：传入一系列String（假设都是合法的数字），转成一个List，然后调用stream()方法生成流。 第二步：调用流的map方法把每个元素由String转成Integer，得到一个新的流。map方法接受一个Function类型的参数，上面介绍了，Function是个函数接口，所以这里用λ表达式。 第三步：调用流的filter方法，过滤那些不是素数的数字，并得到一个新流。filter方法接受一个Predicate类型的参数，上面介绍了，Predicate是个函数接口，所以这里用λ表达式。 第四步：调用流的distinct方法，去掉重复，并得到一个新流。这本质上是另一个filter操作。 第五步：用collect方法将最终结果收集到一个List里面去。collect方法接受一个Collector类型的参数，这个参数指明如何收集最终结果。在这个例子中，结果简单地收集到一个List中。我们也可以用Collectors.toMap(e-&gt;e, e-&gt;e)把结果收集到一个Map中，它的意思是：把结果收到一个Map，用这些素数自身既作为键又作为值。toMap方法接受两个Function类型的参数，分别用以生成键和值，Function是个函数接口，所以这里都用λ表达式。 你可能会觉得在这个例子里，List l被迭代了好多次，map，filter，distinct都分别是一次循环，效率会不好。实际并非如此。这些返回另一个Stream的方法都是“懒（lazy）”的，而最后返回最终结果的collect方法则是“急（eager）”的。在遇到eager方法之前，lazy的方法不会执行。 当遇到eager方法时，前面的lazy方法才会被依次执行。而且是管道贯通式执行。这意味着每一个元素依次通过这些管道。例如有个元素“3”，首先它被map成整数型3；然后通过filter，发现是素数，被保留下来；又通过distinct，如果已经有一个3了，那么就直接丢弃，如果还没有则保留。这样，3个操作其实只经过了一次循环。 除collect外其它的eager操作还有forEach，toArray，reduce等。 下面来看一下也许是最常用的收集器方法，groupingBy：123456789//给出一个String类型的数组，找出其中各个素数，并统计其出现次数public void primaryOccurrence(String... numbers) &#123; List&lt;String&gt; l = Arrays.asList(numbers); Map&lt;Integer, Integer&gt; r = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .collect( Collectors.groupingBy(p-&gt;p, Collectors.summingInt(p-&gt;1)) ); System.out.println("primaryOccurrence result is: " + r);&#125; 注意这一行：1Collectors.groupingBy(p-&gt;p, Collectors.summingInt(p-&gt;1)) 它的意思是：把结果收集到一个Map中，用统计到的各个素数自身作为键，其出现次数作为值。 下面是一个reduce的例子：12345678910//给出一个String类型的数组，求其中所有不重复素数的和public void distinctPrimarySum(String... numbers) &#123; List&lt;String&gt; l = Arrays.asList(numbers); int sum = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .distinct() .reduce(0, (x,y) -&gt; x+y); // equivalent to .sum() System.out.println("distinctPrimarySum result is: " + sum);&#125; reduce方法用来产生单一的一个最终结果。 流有很多预定义的reduce操作，如sum()，max()，min()等。再举个现实世界里的栗子比如：123456789// 统计年龄在25-35岁的男女人数、比例public void boysAndGirls(List&lt;Person&gt; persons) &#123; Map&lt;Integer, Integer&gt; result = persons.parallelStream().filter(p -&gt; p.getAge()&gt;=25 &amp;&amp; p.getAge()&lt;=35). collect( Collectors.groupingBy(p-&gt;p.getSex(), Collectors.summingInt(p-&gt;1)) ); System.out.print("boysAndGirls result is " + result); System.out.println(", ratio (male : female) is " + (float)result.get(Person.MALE)/result.get(Person.FEMALE));&#125; λ表达式的更多用法12345678910// 嵌套的λ表达式Callable&lt;Runnable&gt; c1 = () -&gt; () -&gt; &#123; System.out.println("Nested lambda"); &#125;;c1.call().run();// 用在条件表达式中Callable&lt;Integer&gt; c2 = true ? (() -&gt; 42) : (() -&gt; 24);System.out.println(c2.call());// 定义一个递归函数private UnaryOperator&lt;Integer&gt; factorial = i -&gt; &#123; return i == 0 ? 1 : i * factorial.apply( i - 1 ); &#125;;...System.out.println(factorial.apply(3)); 在Java中，随声明随调用的方式是不行的，比如下面这样，声明了一个λ表达式(x, y) -&gt; x + y，同时企图通过传入实参(2, 3)来调用它：1int five = ( (x, y) -&gt; x + y ) (2, 3); // ERROR! try to call a lambda in-place 这在C++中是可以的，但Java中不行。Java的λ表达式只能用作赋值、传参、返回值等。 其它相关概念捕获（Capture）捕获的概念在于解决在λ表达式中我们可以使用哪些外部变量（即除了它自己的参数和内部定义的本地变量）的问题。 答案是：与内部类非常相似，但有不同点。不同点在于内部类总是持有一个其外部类对象的引用。而λ表达式呢，除非在它内部用到了其外部类（包围类）对象的方法或者成员，否则它就不持有这个对象的引用。 在Java8以前，如果要在内部类访问外部对象的一个本地变量，那么这个变量必须声明为final才行。在Java8中，这种限制被去掉了，代之以一个新的概念，“effectively final”。 它的意思是你可以声明为final，也可以不声明final但是按照final来用，也就是一次赋值永不改变。换句话说，保证它加上final前缀后不会出编译错误。 在Java8中，内部类和λ表达式都可以访问effectively final的本地变量。λ表达式的例子如下：1234567891011121314151617181920... int tmp1 = 1; //包围类的成员变量static int tmp2 = 2; //包围类的静态成员变量public void testCapture() &#123; int tmp3 = 3; //没有声明为final，但是effectively final的本地变量 final int tmp4 = 4; //声明为final的本地变量 int tmp5 = 5; //普通本地变量 Function&lt;Integer, Integer&gt; f1 = i -&gt; i + tmp1; Function&lt;Integer, Integer&gt; f2 = i -&gt; i + tmp2; Function&lt;Integer, Integer&gt; f3 = i -&gt; i + tmp3; Function&lt;Integer, Integer&gt; f4 = i -&gt; i + tmp4; Function&lt;Integer, Integer&gt; f5 = i -&gt; &#123; tmp5 += i; // 编译错！对tmp5赋值导致它不是effectively final的 return tmp5; &#125;; ... tmp5 = 9; // 编译错！对tmp5赋值导致它不是effectively final的&#125;... Java要求本地变量final或者effectively final的原因是多线程并发问题。内部类、λ表达式都有可能在不同的线程中执行，允许多个线程同时修改一个本地变量不符合Java的设计理念。 方法引用（Method reference）任何一个λ表达式都可以代表某个函数接口的唯一方法的匿名描述符。我们也可以使用某个类的某个具体方法来代表这个描述符，叫做方法引用。例如：123Integer::parseInt //静态方法引用System.out::print //实例方法引用Person::new //构造器引用 下面是一组例子，教你使用方法引用代替λ表达式：123456789101112131415//c1 与 c2 是一样的（静态方法引用）Comparator&lt;Integer&gt; c2 = (x, y) -&gt; Integer.compare(x, y);Comparator&lt;Integer&gt; c1 = Integer::compare; //下面两句是一样的（实例方法引用1）persons.forEach(e -&gt; System.out.println(e));persons.forEach(System.out::println); //下面两句是一样的（实例方法引用2）persons.forEach(person -&gt; person.eat());persons.forEach(Person::eat); //下面两句是一样的（构造器引用）strList.stream().map(s -&gt; new Integer(s));strList.stream().map(Integer::new); 使用方法引用，你的程序会变得更短些。现在distinctPrimarySum方法可以改写如下：12345public void distinctPrimarySum(String... numbers) &#123; List&lt;String&gt; l = Arrays.asList(numbers); int sum = l.stream().map(Integer::new).filter(Primes::isPrime).distinct().sum(); System.out.println("distinctPrimarySum result is: " + sum);&#125; 还有一些其它的方法引用:12super::toString //引用某个对象的父类方法String[]::new //引用一个数组的构造器 默认方法（Default method）Java8中，接口声明里可以有方法实现了，叫做默认方法。在此之前，接口里的方法全部是抽象方法。123456789public interface MyInterf &#123; String m1(); default String m2() &#123; return "Hello default method!"; &#125; &#125; 这实际上混淆了接口和抽象类，但一个类仍然可以实现多个接口，而只能继承一个抽象类。 这么做的原因是：由于Collection库需要为批处理操作添加新的方法，如forEach()，stream()等，但是不能修改现有的Collection接口——如果那样做的话所有的实现类都要进行修改，包括很多客户自制的实现类。所以只好使用这种妥协的办法。 如此一来，我们就面临一种类似多继承的问题。如果类Sub继承了两个接口，Base1和Base2，而这两个接口恰好具有完全相同的两个默认方法，那么就会产生冲突。这时Sub类就必须通过重载来显式指明自己要使用哪一个接口的实现（或者提供自己的实现）：1234567public class Sub implements Base1, Base2 &#123; public void hello() &#123; Base1.super.hello(); //使用Base1的实现 &#125; &#125; 除了默认方法，Java8的接口也可以有静态方法的实现：12345678910111213public interface MyInterf &#123; String m1(); default String m2() &#123; return "Hello default method!"; &#125; static String m3() &#123; return "Hello static method in Interface!"; &#125; &#125; 生成器函数（Generator function）有时候一个流的数据源不一定是一个已存在的集合对象，也可能是个“生成器函数”。一个生成器函数会产生一系列元素，供给一个流。Stream.generate(Supplier s)就是一个生成器函数。其中参数Supplier是一个函数接口，里面有唯一的抽象方法 get()。 下面这个例子生成并打印5个随机数：1Stream.generate(Math::random).limit(5).forEach(System.out::println); 注意这个limit(5)，如果没有这个调用，那么这条语句会永远地执行下去。也就是说这个生成器是无穷的。这种调用叫做终结操作，或者短路（short-circuiting）操作。 参考资料：http://openjdk.java.net/projects/lambda/http://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[实际项目中的常见算法]]></title>
      <url>%2F20170427%2Falgorithms_for_project%2F</url>
      <content type="text"><![CDATA[Emanuele Viola在Stackexchange上提了这样的一个问题，他希望有人能够列举一些目前软件、硬件中正在使用的算法的实际案例来证明算法的重要性，对于大家可能给到的回答，他还提出了几点要求： 使用这些算法的软件或者硬件应该是被广泛应用的; 例子需要具体，并给出确切的系统、算法的引用地址; 在经典的本科生或者博士的课程中应该教过这些算法或者数据结构; Vijay D的回复获得了最佳答案，他的具体回复内容如下： Linux内核中的基本数据结构和算法 链表、双向链表和无锁链表 B+ 树，代码中的注释将会告诉你一些教科书中不能学到的内容： 这是一个简单的B+树实现，我写它的目的是作为练习，并以此了解B+树的工作原理。结果该实现发挥了它的实用价值。 … 一个不经常在教科书中提及的技巧：最小值应该放在右侧，而不是左侧。一个节点内所有被使用的槽位应该在左侧，没有使用的节点应该为NUL，大部分的操作只遍历一次所有的槽位，在第一个NUL处终止。 带权重的有序列表用于互斥锁、驱动等; 红黑树用于调度、虚拟内存管理、跟踪文件描述符和目录条目等; 区间树 Radix树，用于内存管理、NFS相关查找和网络相关的功能; radix树的一个常见的用法是保存页面结构体的指针; 优先级堆，文字上的描述，主要是在教科书中实现，用于control group系统; 包含指针的只允许简单插入的静态大小优先级堆，基于CLR（算法导论）第七章 哈希函数，引用Knuth和他的一篇论文： Knuth建议选择与机器字长所能表达的最大整数约成黄金比例的素数来做乘法散列，Chuck Lever 证实了这个技术的有效性; http://www.citi.umich.edu/techreports/reports/citi-tr-00-1.pdf 这些选择的素数是位稀疏的，也就是说对他们的操作可以使用位移和加法来替换机器中很慢的乘法操作; 有些代码，比如这个驱动，他们是自己实现的哈希函数 哈希表，用于实现索引节点、文件系统完整性检查等; 位数组，用于处理flags、中断等，在Knuth第四卷中有对其特性的描述; Semaphores 和 spin locks 二叉树搜索用于中断处理、登记缓存查找等; 使用B-树进行二叉树查找; 深度优先搜索和他的变体被应用于目录配置; 在命名空间树中执行一个修改过的深度优先算法，开始（和终止于）start_handle所确定的节点。当与参数匹配的节点被发现以后，回调函数将会被调用。如果回调函数返回一个非空的值，搜索将会立即终止，这个值将会回传给调用函数; 广度优先搜索用于在运行时检查锁的正确性; 链表上的合并排序用于垃圾回收、文件系统管理等; 在某个驱动程序的库函数里，冒泡排序居然也被实现了 Knuth-Morris-Pratt 字符串匹配; Knuth、Morris和 Pratt [1]实现了一个线性时间复杂度字符串匹配算法。该算法完全规避了对转换函数DELTA的显式计算。其匹配时间为O(n)（其中n是文本长度），只使用一个辅助函数PI[1…m]（其中m是模式的长度），模式的预处理时间是O(m)。PI这个数组允许DELTA函数在需要时能迅速运行。大体上，对任意状态q=0,1,…,m和任意SIGMA中的字符”a”，PI[“q”]保存了独立于”a”的信息，并用于计算DELTA(“q”,”a”)。由于PI这个数组只包含m个条目，而DELTA包含O(m|SIGMA|)个条目，我们通过计算PI进而在预处理时间保存|SIGMA|的系数，而非计算DELTA。[1] Cormen, Leiserson, Rivest, Stein Introdcution to Algorithms, 2nd Edition, MIT Press[2] See finite automation theory Boyer-Moore模式匹配，如下是引用和对其他算法的使用建议; Boyer-Moore字符串匹配算法:[1] A Fast String Searching Algorithm, R.S. Boyer and Moore. Communications of the Association for Computing Machinery, 20(10), 1977, pp. 762-772.http://www.cs.utexas.edu/users/moore/publications/fstrpos.pdf[2] Handbook of Exact String Matching Algorithms, Thierry Lecroq, 2004 http://www-igm.univ-mlv.fr/~lecroq/string/string.pdf注意：由于Boyer-Moore（BM）自右向左做匹配，有一种可能性是一个匹配分布在不同的块中，这种情况下是不能找到任何匹配的。如果你想确保这样的事情不会发生，使用Knuth-Pratt-Morris（KMP）算法来替代。也就是说，根据你的设置选择合适的字符串查找算法。如果你使用文本搜索架构来过滤、网络入侵检测（NIDS）或者任何安全为目的，那么选择KMP。如果你关乎性能，比如你在分类数据包，并应用服务质量（QoS）策略，并且你不介意可能需要在分布在多个片段中匹配，然后就选择BM。 Chromium 浏览器中的数据结构和算法 伸展树 此树会被分配策略参数化，这个策略负责在C的自由存储空间和区域中分配列表，参见zone.h Demo中使用了Voronoi图 基于Bresenham算法的标签管理 同时，代码中还包含了一些第三方的算法和数据结构，例如： 二叉树 红黑树 AVL树 用于压缩的Rabin-Karp字符串匹配 计算自动机的后缀 苹果实现的布隆过滤器 布氏算法 编程语言类库 C++ STL，包含的有列表、堆、栈、向量、排序、搜索和堆操作算法 Java API 非常广泛，包含的太多 Boost C++ 类库，包含了诸如Boyer-Moore和Knuth-Morris-Pratt字符串匹配算法等; 分配和调度算法 最近最少使用算法有多种实现方式，在Linux内核中是基于列表实现的; 其他可能需要了解的是先入先出、最不常用和轮询; VAX、VMS系统中大量使用FIFO的变体; Richard Carr的时钟算法被用于Linux中页面帧替换; Intel i860处理器中使用了随机替换策略; 自适应缓存替换被用于一些IBM的存储控制中，由于专利原因在PostgreSQL只有简单的应用; Knuth在TAOCP第一卷中提到的伙伴内存分配算法被用于Linux内核中，FreeBSD和Facebook都在使用jemalloc并发分配器; unix系统中的核心组件 grep和awk都实现了使用Thompson-McNaughton-Yamada构建算法实现从正则表达式中创建NFA tsort实现了拓扑排序 fgrep实现了Aho-Corasick 字符串匹配算法; GNU grep，据作者Mike Haertel所说，实现了Boyer-Moore算法; Unix中的crypt(1)实现了哑谜机（Enigma Machine）中的加密算法的变种; Doug Mcllroy基于和James合作的原型实现的Unix diff，比用来计算Levenshtein距离的标准动态规划算法更好，Linux版本被用来计算最短编辑距离; 加密算法 Merkle树，尤其是Tiger Tree Hash的变种，用于点对点的程序，例如GTK Gnutella 和LimeWire; MD5用于为软件包提供校验码，还用于*nix系统（Linux实现）中的完整性校验，同时他还支持Windows和OS X系统; OpenSSL实现了需要加密算法，诸如AES，Blowfish，DES，SHA-1，SHA-2，RSA，DES等; 编译器 yacc和bison实现了LALR解析器 支配算法用于基于SSA形式的最优化编译器; lex和flex将正则表达式编译为NFA; 压缩和图片处理 为GIF图片格式而出现的Lempel-Zivsraf算法在图片处理程序中经常被应用，从一个简单的*nix组件转化为一个复杂的程序; 运行长度编码被用于生成PCX文件（用于Paintbrush这个程序中），压缩BMP文件和TIFF文件; 小波压缩（Wavelet压缩）是JPEG 2000的基础，所以所有生成JPEG 2000文件的数码相机都是实现了这个算法; Reed-Solomon纠错用于Linux内核、CD驱动、条形码读取，并且结合卷积从航行团队进行图片传输; 冲突驱动条款学习算法（Conflict Driven Clause Learning）自2000年以来，在工业标准中的SAT（布尔满足性问题）求解器的运行时间每年都在成倍减少。这一发展的一个非常重要的原因是冲突驱动条款学习算法（Conflict Driven Clause Learning）的使用，它结合了Davis Logemann和Loveland的约束编程和人工智能研究技术的原始论文中关于布尔约束传播的算法。具体来说，工业建模中SAT被认为是一个简单的问题（见讨论）。对我来说，这是近代最伟大的成功故事之一，因为它结合了先进的算法、巧妙的设计思路、实验反馈，并以一致的共同努力来解决这个问题。Malik和Zhang的CACM论文是一个很好的阅读材料。许多大学都在教授这个算法，但通常是在逻辑或形式化方法的课程中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[多版本并发控制(MVCC)在分布式系统中的应用]]></title>
      <url>%2F20170427%2Fconcurrence_control_mvcc%2F</url>
      <content type="text"><![CDATA[问题最近项目中遇到了一个分布式系统的并发控制问题。该问题可以抽象为：某分布式系统由一个数据中心D和若干业务处理中心L1，L2 … Ln组成；D本质上是一个key-value存储，它对外提供基于HTTP协议的CRUD操作接口。L的业务逻辑可以抽象为下面3个步骤： read: 根据keySet {k1, … kn}从D获取keyValueSet {k1:v1, … kn:vn} do: 根据keyValueSet进行业务处理，得到需要更新的数据集keyValueSet’ {k1′:v1′, … km’:vm’} (注：读取的keySet和更新的keySet’可能不同) update: 把keyValueSet’更新到D （注：D保证在一次调用更新多个key的原子性） 在没有事务支持的情况下，多个L进行并发处理可能会导致数据一致性问题。比如，考虑L1和L2的如下执行顺序： L1从D读取key:123对应的值100 L2从D读取key:123对应的100 L1将key:123更新为100 + 1 L2将key:123更新为100 + 2 如果L1和L2串行执行，key:123对应的值将为103，但上面并发执行中L1的执行效果完全被L2所覆盖，实际key:123所对应的值变成了102。 解决方案1：基于锁的事务为了让L的处理具有可串行化特性(Serializability)，一种最直接的解决方案就是考虑为D加上基于锁的简单事务。让L在进行业务处理前先锁定D，完成以后释放锁。另外，为了防止持有锁的L由于某种原因长时间未提交事务，D还需要具有超时机制，当L尝试提交一个已超时的事务时会得到一个错误响应。 本方案的优点是实现简单，缺点是锁定了整个数据集，粒度太大；时间上包含了L的整个处理时间，跨度太长。虽然我们可以考虑把锁定粒度降低到数据项级别，按key进行锁定，但这又会带来其他的问题。由于更新的keySet’可能是事先不确定的，所以可能无法在开始事务时锁定所有的key；如果分阶段来锁定需要的key，又可能出现死锁(Deadlock)问题。另外，按key锁定在有锁争用的情况下并不能解决锁定时间太长的问题。所以，按key锁定仍然存在重要的不足之处。 解决方案2：多版本并发控制为了实现可串行化，同时避免锁机制存在的各种问题，我们可以采用基于多版本并发控制（Multiversion concurrency control，MVCC）思想的无锁事务机制。人们一般把基于锁的并发控制机制称成为悲观机制，而把MVCC机制称为乐观机制。这是因为锁机制是一种预防性的，读会阻塞写，写也会阻塞读，当锁定粒度较大，时间较长时并发性能就不会太好；而MVCC是一种后验性的，读不阻塞写，写也不阻塞读，等到提交的时候才检验是否有冲突，由于没有锁，所以读写不会相互阻塞，从而大大提升了并发性能。我们可以借用源代码版本控制来理解MVCC，每个人都可以自由地阅读和修改本地的代码，相互之间不会阻塞，只在提交的时候版本控制器会检查冲突，并提示merge。目前，Oracle、PostgreSQL和MySQL都已支持基于MVCC的并发机制，但具体实现各有不同。 MVCC的一种简单实现是基于CAS（Compare-and-swap）思想的有条件更新（Conditional Update）。普通的update参数只包含了一个keyValueSet’，Conditional Update在此基础上加上了一组更新条件conditionSet { … data[keyx]=valuex, … }，即只有在D满足更新条件的情况下才将数据更新为keyValueSet’；否则，返回错误信息。这样，L就形成了如下图所示的Try/Conditional Update/(Try again)的处理模式： 虽然对单个L来讲不能保证每次都成功更新，但从整个系统来看，总是有任务能够顺利进行。这种方案利用Conditional Update避免了大粒度和长时间的锁定，当各个业务之间资源争用不大的情况下，并发性能很好。不过，由于Conditional Update需要更多的参数，如果condition中value的长度很长，那么每次网络传送的数据量就会比较大，从而导致性能下降。特别是当需要更新的keyValueSet’很小，而condition很大时，就显得非常不经济。 为了避免condition太大所带来的性能问题，可以为每条数据项增加一个int型的版本号字段，由D维护该版本号，每次数据有更新就增加版本号；L在进行Conditional Update时，通过版本号取代具体的值。 另一个问题是上面的解决方案假设了D是可以支持Conditional Update的；那么，如果D是一个不支持Conditional Update的第三方的key-value存储怎么办呢？这时，我们可以在L和D之间增加一个P作为代理，所有的CRUD操作都必须经过P，让P来进行条件检查，而实际的数据操作放在D。这种方式实现了条件检查和数据操作的分离，但同时降低了性能，需要在P中增加cache，提升性能。由于P是D的唯一客户端；所以，P的cache管理是非常简单的，不必像多客户端情形担心缓存的失效。不过，实际上，据我所知redis和Amazon SimpleDB都已经有了Conditional Update的支持。 悲观锁和MVCC对比上面介绍了悲观锁和MVCC的基本原理，但是对于它们分别适用于什么场合，不同的场合下两种机制优劣具体表现在什么地方还不是很清楚。这里我就对一些典型的应用场景进行简单的分析。需要注意的是下面的分析不针对分布式，悲观锁和MVCC两种机制在分布式系统、单数据库系统、甚至到内存变量各个层次都存在。 场景1：对读的响应速度要求高有一类系统更新特别频繁，并且对读的响应速度要求很高，如股票交易系统。在悲观锁机制下，写会阻塞读，那么当有写操作时，读操作的响应速度就会受到影响；而MVCC不存在读写锁，读操作是不受任何阻塞的，所以读的响应速度会更快更稳定。 场景2：读远多于写对于许多系统来讲，读操作的比例往往远大于写操作，特别是某些海量并发读的系统。在悲观锁机制下，当有写操作占用锁，就会有大量的读操作被阻塞，影响并发性能；而MVCC可以保持比较高且稳定的读并发能力。 场景3：写操作冲突频繁如果系统中写操作的比例很高，且冲突频繁，这时就需要仔细评估。假设两个有冲突的业务L1和L2，它们在单独执行是分别耗时t1，t2。在悲观锁机制下，它们的总时间大约等于串行执行的时间： T = t1 + t2 而在MVCC下，假设L1在L2之前更新，L2需要retry一次，它们的总时间大约等于L2执行两次的时间（这里假设L2的两次执行耗时相等，更好的情况是，如果第1次能缓存下部分有效结果，第二次执行L2耗时是可能减小的）： T’ = 2 * t2 这时关键是要评估retry的代价，如果retry的代价很低，比如，对某个计数器递增，又或者第二次执行可以比第一次快很多，这时采用MVCC机制就比较适合。反之，如果retry的代价很大，比如，报表统计运算需要算几小时甚至一天那就应该采用锁机制避免retry。 从上面的分析，我们可以简单的得出这样的结论：对读的响应速度和并发性要求比较高的场景适合MVCC；而retry代价越大的场景越适合悲观锁机制。 总结本文介绍了一种基于多版本并发控制（MVCC）思想的Conditional Update解决分布式系统并发控制问题的方法。和基于悲观锁的方法相比，该方法避免了大粒度和长时间的锁定，能更好地适应对读的响应速度和并发性要求高的场景。 参考Wikipedia – SerializabilityWikipedia – Compare-and-swapWikipedia – Multiversion concurrency controlLock-free algorithms: The try/commit/(try again) patternAmazon SimpleDB FAQs – Does Amazon SimpleDB support transactions?redis – TransactionsA Quick Survey of MultiVersion Concurrency Algorithms非阻塞算法思想在关系数据库应用程序开发中的使用 本文转载自：http://coolshell.cn/articles/6790.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式系统常用思想和技术总结]]></title>
      <url>%2F20170427%2Fthink_in_distributed_tec%2F</url>
      <content type="text"><![CDATA[分布式系统的难点分布式系统比起单机系统存在哪些难点呢？ 网络因素由于服务和数据分布在不同的机器上，每次交互都需要跨机器运行，这带来如下几个问题： 网络延迟：性能、超时 同机房的网络IO还是比较块的，但是跨机房，尤其是跨IDC，网络IO就成为不可忽视的性能瓶颈了。并且，延迟不是带宽，带宽可以随便增加，千兆网卡换成万兆，只是成本的问题，但延迟是物理限制，基本不可能降低。 这带来的问题就是系统整体性能的降低，会带来一系列的问题，比如资源的锁住，所以系统调用一般都要设置一个超时时间进行自我保护，但是过度的延迟就会带来系统的RPC调用超时，引发一个令人头疼的问题：分布式系统调用的三态结果：成功、失败、超时。不要小看这个第三态，这几乎是所有分布式系统复杂性的根源。 针对这个问题有一些相应的解决方案：异步化，失败重试。 而对于跨IDC数据分布带来的巨大网络因素影响，则一般会采用数据同步，代理专线等处理方式。 网络故障：丢包、乱序、抖动。 这个可以通过将服务建立在可靠的传输协议上来解决，比如TCP协议。不过带来的是更多的网络交互。因此是性能和流量的一个trade off。这个在移动互联网中更需要考虑。 鱼与熊掌不可兼得——CAP定律CAP理论是由Eric Brewer提出的分布式系统中最为重要的理论之一： Consistency：[强]一致性，事务保障，ACID模型。 Availiablity：[高]可用性，冗余以避免单点，至少做到柔性可用（服务降级）。 Partition tolerance：[高]可扩展性（分区容忍性）：一般要求系统能够自动按需扩展，比如HBase。 CAP原理告诉我们，这三个因素最多只能满足两个，不可能三者兼顾。对于分布式系统来说，分区容错是基本要求，所以必然要放弃一致性。对于大型网站来说，分区容错和可用性的要求更高，所以一般都会选择适当放弃一致性。对应CAP理论，NoSQL追求的是AP，而传统数据库追求的是CA，这也可以解释为什么传统数据库的扩展能力有限的原因。 在CAP三者中，“可扩展性”是分布式系统的特有性质。分布式系统的设计初衷就是利用集群多机的能力处理单机无法解决的问题。当需要扩展系统性能时，一种做法是优化系统的性能或者升级硬件(scale up)，一种做法就是“简单”的增加机器来扩展系统的规模(scale out)。好的分布式系统总在追求”线性扩展性”，即性能可以随集群数量增长而线性增长。 可用性和可扩展性一般是相关联的，可扩展行好的系统，其可用性一般会比较高，因为有多个服务(数据)节点，不是整体的单点。所以分布式系统的所有问题，基本都是在一致性与可用性和可扩展性这两者之间的一个协调和平衡。对于没有状态的系统，不存在一致性问题，根据CAP原理，它们的可用性和分区容忍性都是很高，简单的添加机器就可以实现线性扩展。而对于有状态的系统，则需要根据业务需求和特性在CAP三者中牺牲其中的一者。一般来说，交易系统类的业务对一致性的要求比较高，一般会采用ACID模型来保证数据的强一致性，所以其可用性和扩展性就比较差。而其他大多数业务系统一般不需要保证强一致性，只要最终一致就可以了，它们一般采用BASE模型，用最终一致性的思想来设计分布式系统，从而使得系统可以达到很高的可用性和扩展性。 CAP定律其实也是衡量分布式系统的重要指标，另一个重要的指标是性能。 一致性模型主要有三种： Strong Consistency（强一致性）：新的数据一旦写入，在任意副本任意时刻都能读到新值。比如：文件系统，RDBMS，Azure Table都是强一致性的。 Week Consistency（弱一致性）：不同副本上的值有新有旧，需要应用方做更多的工作获取最新值。比如Dynamo。 Evantual Consistency（最终一致性）：一旦更新成功，各副本的数据最终将达到一致。 从这三种一致型的模型上来说，我们可以看到，Weak和Eventually一般来说是异步冗余的，而Strong一般来说是同步冗余的(多写)，异步的通常意味着更好的性能，但也意味着更复杂的状态控制。同步意味着简单，但也意味着性能下降。 以及其他变体： Causal Consistency（因果一致性）：如果Process A通知Process B它已经更新了数据，那么Process B的后续读取操作则读取A写入的最新值，而与A没有因果关系的C则可以最终一致性。 Read-your-writes Consistency（读你所写一致性）：如果Process A写入了最新的值，那么 Process A的后续操作都会读取到最新值。但是其它用户可能要过一会才可以看到。 Session Consistency（会话一致性）：一次会话内一旦读到某个值，不会读到更旧的值。Monotonic Read Consistency（单调一致性）：一个用户一旦读到某个值，不会读到比这个值更旧的值，其他用户不一定。等等。 其中最重要的变体是第二条：Read-your-Writes Consistency。特别适用于数据的更新同步，用户的修改马上对自己可见，但是其他用户可以看到他老的版本。Facebook的数据同步就是采用这种原则。 分布式系统常用技术和应用场景 consistent hashing [with virtual node]：一致性哈希，数据分布 vector clock：时钟向量，多版本数据修改 Quorum W+R&gt;N [with vector clock]：抽屉原理，数据一致性的另一种解决方案。时钟向量，多版本数据修改。 Merkle tree [with anti-entropy]：数据复制 MVCC：copy-on-write与snapshot 2PC/3PC：分布式事务 Paxos：强一致性协议 Symmetry and Decentralization：对称性和去中心化。对称性(symmetry)简化了系统的配置和维护。去中心化是对对称性的延伸，可以避免master单点，同时方便集群scale out。 Map-Reduce：分而治之；移动数据不如移动计算。将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化计算。本地化计算是计算调度的一种重要优化。 Gossip协议：节点管理 Lease机制： consistent hashing：一致性哈希，解决数据均衡分布问题普通hash()我们通常使用的hash算法是hash() mod n，但是如果发生某个节点失效时，无法快速切换到其他节点。为了解决单点故障的问题，我们为每个节点都增加一个备用节点，当某个节点失效时，就自动切换到备用节点上，类似于数据库的master和slave。但是依然无法解决增加或删除节点后，需要做hash重分布的问题，也就是无法动态增删节点。这时就引入了一致性hash的概念 ，将所有的节点分布到一个hash环上，每个请求都落在这个hash环上的某个位置，只需要按照顺时针方向找到的第一个节点，就是自己需要的服务节点。当某个节点发生故障时，只需要在环上找到下一个可用节点即可。 一致性hash算法最常用于分布式cache中，比如注意的memcached。Dynamo也用其作为数据分布算法，并且对一致性算法进行了改进，提出了基于虚拟节点的改进算法，其核心思路是引入虚拟节点，每个虚拟节点都有一个对应的物理节点，而每个物理节点可以对应若干个虚拟节点。 关于一致性hash的更多内容，可以参考笔者另一篇博文：Memcached的分布式算法学习。 这篇文章也可以看看：某分布式应用实践一致性哈希的一些问题 virtual node前面说过，有的Consistent Hashing的实现方法采用了虚拟节点的思想。使用一般的hash函数的话，服务器的映射地点的分布非常不均匀。因此，使用虚拟节点的思想，为每个物理节点（服务器）在continuum上分配100～200个点。这样就能抑制分布不均匀，最大限度地减小服务器增减时的缓存重新分布。 Quorum W+R&gt;N：抽屉原理，数据一致性的另一种解决方案 N: 复制的节点数，即一份数据被保存的份数。 R: 成功读操作的最小节点数，即每次读取成功需要的份数。 W: 成功写操作的最小节点数 ，即每次写成功需要的份数。 所以 W+R&gt;N的意思是：对于有N份拷贝的分布式系统，写到W(W&lt;=N)份成功算写成功，读R(R&lt;=N)份数据算读成功。 这三个因素决定了可用性，一致性和分区容错性。W+R&gt;N可以保证数据的一致性(C)，W越大数据一致性越高。这个NWR模型把CAP的选择权交给了用户，让用户自己在功能，性能和成本效益之间进行权衡。 对于一个分布式系统来说，N通常都大于3，也就说同一份数据需要保存在三个以上不同的节点上，以防止单点故障。W是成功写操作的最小节点数，这里的写成功可以理解为“同步”写，比如N=3，W=1，那么只要写成功一个节点就可以了，另外的两份数据是通过异步的方式复制的。R是成功读操作的最小节点数，读操作为什么要读多份数据呢？在分布式系统中，数据在不同的节点上可能存在着不一致的情况，我们可以选择读取多个节点上的不同版本，来达到增强一致性的目的。 NWR模型的一些设置会造成脏数据和版本冲突问题，所以一般要引入vector clock算法来解决这个问题。 需要保证系统中有max(N-W+1,N-R+1)个节点可用。 关于NWR模型，建议阅读 分布式系统的事务处理，写的很通俗易懂。 vector clock：时钟向量，多版本数据修改参见 分布式系统的事务处理，写的很通俗易懂。 lease机制chubby、zookeeper 获得lease（租约）的节点得到系统的承诺：在有效期内数据/节点角色等是有效的，不会变化的。 lease机制的特点： lease颁发过程只需要网络可以单向通信，同一个lease可以被颁发者不断重复向接受方发送。即使颁发者偶尔发送lease失败，颁发者也可以简单的通过重发的办法解决。 机器宕机对lease机制的影响不大。如果颁发者宕机，则宕机的颁发者通常无法改变之前的承诺，不会影响lease的正确性。在颁发者机恢复后，如果颁发者恢复出了之前的lease 信息，颁发者可以继续遵守lease的承诺。如果颁发者无法恢复lease信息，则只需等待一个最大的lease超时时间就可以使得所有的lease都失效，从而不破坏lease机制。 lease机制依赖于有效期，这就要求颁发者和接收者的时钟是同步的。 如果颁发者的时钟比接收者的时钟慢，则当接收者认为lease已经过期的时候，颁发者依旧认为lease有效。接收者可以用在lease到期前申请新的lease的方式解决这个问题。 如果颁发者的时钟比接收者的时钟快，则当颁发者认为lease已经过期的时候，可能将lease颁发给其他节点，造成承诺失效，影响系统的正确性。对于这种时钟不同步，实践中的通常做法是将颁发者的有效期设置得比接收者的略大，只需大过时钟误差就可以避免对lease的有效性的影响。 工程中，常选择的lease时长是10秒级别，这是一个经过验证的经验值，实践中可以作为参考并综合选择合适的时长。 双主问题（脑裂问题）lease机制可以解决网络分区问题造成的“双主”问题，即所谓的“脑裂”现象。配置中心为一个节点发放lease，表示该节点可以作为primary节点工作。当配置中心发现primary有问题时，只需要等到前一个primary的lease过期，就可以安全地颁发新的lease给新的primary节点，而不会出现“双主”问题。 在实际系统中，若用一个中心节点作为配置中心发送lease也有很大的风险。实际系统总是使用多个中心节点互为副本，成为一个小的集群，该小集群具有高可用性，对外提供颁发lease的功能。chubby和zookeeper都是基于这样的设计。 chubby一般有五台机器组成一个集群，可以部署成两地三机房。chubby内部的五台机器需要通过Paxos协议选取一个chubby master机器，其它机器是chubby slave，同一时刻只有一个chubby master。chubby相关的数据，比如锁信息，客户端的session信息等都需要同步到整个集群，采用半同步的做法，超过一半的机器成功就可以回复客户端。最后可以确保只有一个和原有的chubby master保持完全同步的chubby slave被选取为新的chubby master。 Gossip协议Gossip用于P2P系统中自治节点获悉对集群认识（如集群的节点状态，负载情况等）。 系统中的节点定期互相八卦，很快八卦就在整个系统传开了。 A、B两个节点八卦的方式主要是：A告诉B知道哪些人的什么八卦；B告诉A这些八卦里B知道哪些更新了；B更新A告诉他的八卦…… 说是自治系统，其实节点中还有一些种子节点。种子节点的作用主要是在有新节点加入系统时体现。新节点加入系统中，先与种子节点八卦，新节点获得系统信息，种子节点知道系统中多了新节点。其他节点定期与种子节点八卦的时候就知道有新节点加入了。 各个节点互相八卦的过程中，如果发现某个节点的状态很长时间都没更新，就认为该节点已经宕机了。 Dynamo使用了Gossip协议来做会员和故障检测。 2PC、3PC、Paxos协议: 分布式事务的解决方案分布式事务很难做，所以除非必要，一般来说都是采用最终一致性来规避分布式事务。 目前底层NoSQL存储系统实现分布式事务的只有Google的系统，它在Bigtable之上用Java语言开发了一个系统 Megastore，实现了两阶段锁，并通过Chubby来避免两阶段锁协调者宕机带来的问题。Megastore实现目前只有简单介绍，还没有相关论文。 2PC实现简单，但是效率低，所有参与者需要block，throughput低；无容错，一个节点失败整个事务失败。如果第一阶段完成后，参与者在第二阶没有收到决策，那么数据结点会进入“不知所措”的状态，这个状态会block住整个事务。 3PC改进版的2PC，把2PC的第一个段break成了两段: 询问，然后再锁资源，最后真正提交。3PC的核心理念是：在询问的时候并不锁定资源，除非所有人都同意了，才开始锁资源。 3PC比2PC的好处是，如果结点处在P状态（PreCommit）的时候发生了Fail/Timeout的问题，3PC可以继续直接把状态变成C状态（Commit），而2PC则不知所措。 不过3PC实现比较困难，而且无法处理网络分离问题。如果preCommit消息发送后两个机房断开，这时候coordinator所在的机房会abort，剩余的participant会commit。 PaxosPaxos的目的是让整个集群的结点对某个值的变更达成一致。Paxos算法是一种基于消息传递的一致性算法。Paxos算法基本上来说是个民主选举的算法——大多数的决定会成个整个集群的统一决定。 任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以Paxos算法需要集群中的结点是单数）。这个是Paxos相对于2PC和3PC最大的区别，在2f+1个节点的集群中，允许有f个节点不可用。 Paxos的分布式民主选举方式，除了保证数据变更的一致性之外，还常用于单点切换，比如Master选举。 Paxos协议的特点就是难，both 理解 and 实现 :( 关于2PC，3PC和Paxos，强烈推荐阅读 分布式系统的事务处理。 目前大部分支付系统其实还是在2PC的基础上进行自我改进的。一般是引入一个差错处理器，进行差错协调（回滚或者失败处理）。 MVCC：多版本并发控制这个是很多RDMS存储引擎实现高并发修改的一个重要实现机制。具体可以参考： 多版本并发控制(MVCC)在分布式系统中的应用MVCC (Oracle, Innodb, Postgres).pdf Map-Reduce思想 分而治之 移动数据不如移动计算如果计算节点和存储节点位于不同的物理机器则计算的数据需要通过网络传输，此种方式的开销很大。另一种思路是，将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化计算。本地化计算是计算调度的一种重要优化。 经典论文和分布式系统学习DynamoHBaseLSM TreeLSM（Log Structured Merge Trees）是B+ Tree一种改进： 牺牲了部分读性能，用来大幅提高写性能 思路：拆分树 首先写WAL，然后记录数据到入到内存中，构建一颗有序子树(memstore) 随着子树越来越大，内存的子树会flush到磁盘上(storefile) 读取数据：必须遍历所有的有序子树（不知数据在哪棵子树） Compact：后台线程对磁盘中的子树进行归并，变成大树（子树多了读得慢） 事实上，lucene的索引机制也类似Hbase的LSM树。也是写的时候分别写在单独的segment，后台进行segement合并。 参考文档：NoSQL漫谈多IDC的数据分布设计(一)分布式系统的事务处理海量存储系列之四-单机事务处理本人的一些技术方面的分享集合Learning from google megastore (Part-1)本文出自：http://kyle.xlau.org/, 原文地址：http://arganzheng.me/posts/thinking-in-distributed-systems.html, 感谢原作者分享。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[实际项目中分布式ID生成算法]]></title>
      <url>%2F20170427%2Falgorithms_for_distributed_id%2F</url>
      <content type="text"><![CDATA[需求缘起几乎所有的业务系统，都有生成一个记录标识的需求，例如： 消息标识：message-id 订单标识：order-id 帖子标识：tiezi-id 这个记录标识往往就是数据库中的唯一主键，数据库上会建立聚集索引(cluster index)，即在物理存储上以这个字段排序。 这个记录标识上的查询，往往又有分页或者排序的业务需求，例如： 拉取最新的一页消息：select message-id order by time limit 100 拉取最新的一页订单：select order-id order by time limit 100 拉取最新的一页帖子：select tiezi-id order by time limit 100 所以往往要有一个time字段，并且在time字段上建立普通索引(non-cluster index)。 我们都知道普通索引存储的是实际记录的指针，其访问效率会比聚集索引慢，如果记录标识在生成时能够基本按照时间有序，则可以省去这个time字段的索引查询：1select message-id (order by message-id) limit 100 再次强调，能这么做的前提是，message-id的生成基本是趋势时间递增的。这就引出了记录标识生成(也就是上文提到的三个XXX-id)的两大核心需求： 全局唯一 趋势有序这也是本文要讨论的核心问题：如何高效生成趋势有序的全局唯一ID。 常见方法、不足与优化常见方法一：使用数据库的 auto_increment 来生成全局唯一递增ID优点： 简单，使用数据库已有的功能 能够保证唯一性 能够保证递增性 步长固定 缺点： 可用性难以保证：数据库常见架构是一主多从+读写分离，生成自增ID是写请求，主库挂了就玩不转了 扩展性差，性能有上限：因为写入是单点，数据库主库的写性能决定ID的生成性能上限，并且难以扩展 改进方法： 增加主库，避免写入单点 数据水平切分，保证各主库生成的ID不重复 如上图所述，由1个写库变成3个写库，每个写库设置不同的auto_increment初始值，以及相同的增长步长，以保证每个数据库生成的ID是不同的（上图中库0生成0,3,6,9…，库1生成1,4,7,10，库2生成2,5,8,11…） 改进后的架构保证了可用性，但缺点是： 丧失了ID生成的“绝对递增性”：先访问库0生成0,3，再访问库1生成1，可能导致在非常短的时间内，ID生成不是绝对递增的(这个问题不大，我们的目标是趋势递增，不是绝对递增) 数据库的写压力依然很大，每次生成ID都要访问数据库 为了解决上述两个问题，引出了第二个常见的方案 常见方法二：单点批量ID生成服务分布式系统之所以难，很重要的原因之一是“没有一个全局时钟，难以保证绝对的时序”，要想保证绝对的时序，还是只能使用单点服务，用本地时钟保证“绝对时序”。数据库写压力大，是因为每次生成ID都访问了数据库，可以使用批量的方式降低数据库写压力。 如上图所述，数据库使用双master保证可用性，数据库中只存储当前ID的最大值，例如0。ID生成服务假设每次批量拉取6个ID，服务访问数据库，将当前ID的最大值修改为5，这样应用访问ID生成服务索要ID，ID生成服务不需要每次访问数据库，就能依次派发0,1,2,3,4,5这些ID了，当ID发完后，再将ID的最大值修改为11，就能再次派发6,7,8,9,10,11这些ID了，于是数据库的压力就降低到原来的1/6了。 优点： 保证了ID生成的绝对递增有序 大大的降低了数据库的压力，ID生成可以做到每秒生成几万几十万个 缺点： 服务仍然是单点 如果服务挂了，服务重启起来之后，继续生成ID可能会不连续，中间出现空洞（服务内存是保存着0,1,2,3,4,5，数据库中max-id是5，分配到3时，服务重启了，下次会从6开始分配，4和5就成了空洞，不过这个问题也不大） 虽然每秒可以生成几万几十万个ID，但毕竟还是有性能上限，无法进行水平扩展 改进方法：单点服务的常用高可用优化方案是“备用服务”，也叫“影子服务”，所以我们能用以下方法优化上述缺点（1）： 如上图，对外提供的服务是主服务，有一个影子服务时刻处于备用状态，当主服务挂了的时候影子服务顶上。这个切换的过程对调用方是透明的，可以自动完成，常用的技术是vip+keepalived，具体就不在这里展开。 常见方法三：uuid上述方案来生成ID，虽然性能大增，但由于是单点系统，总还是存在性能上限的。同时，上述两种方案，不管是数据库还是服务来生成ID，业务方Application都需要进行一次远程调用，比较耗时。有没有一种本地生成ID的方法，即高性能，又时延低呢？ uuid是一种常见的方案：string ID =GenUUID(); 优点： 本地生成ID，不需要进行远程调用，时延低 扩展性好，基本可以认为没有性能上限 缺点： 无法保证趋势递增 uuid过长，往往用字符串表示，作为主键建立索引查询效率低，常见优化方案为“转化为两个uint64整数存储”或者“折半存储”（折半后不能保证唯一性） 常见方法四：取当前毫秒数uuid是一个本地算法，生成性能高，但无法保证趋势递增，且作为字符串ID检索效率低，有没有一种能保证递增的本地算法呢？ 取当前毫秒数是一种常见方案：uint64 ID = GenTimeMS(); 优点： 本地生成ID，不需要进行远程调用，时延低 生成的ID趋势递增 生成的ID是整数，建立索引后查询效率高 缺点： 如果并发量超过1000，会生成重复的ID 我去，这个缺点要了命了，不能保证ID的唯一性。当然，使用微秒可以降低冲突概率，但每秒最多只能生成1000000个ID，再多的话就一定会冲突了，所以使用微秒并不从根本上解决问题。 常见方法五：类snowflake算法snowflake是twitter开源的分布式ID生成算法，其核心思想是：一个long型的ID，使用其中41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号。这个算法单机每秒内理论上最多可以生成1000(2^12)，也就是400W的ID，完全能满足业务的需求。* 借鉴snowflake的思想，结合各公司的业务逻辑和并发量，可以实现自己的分布式ID生成算法。 举例，假设某公司ID生成器服务的需求如下： 单机高峰并发量小于1W，预计未来5年单机高峰并发量小于10W 有2个机房，预计未来5年机房数量小于4个 每个机房机器数小于100台 目前有5个业务线有ID生成需求，预计未来业务线数量小于10个 … 分析过程如下： 高位取从2016年1月1日到现在的毫秒数（假设系统ID生成器服务在这个时间之后上线），假设系统至少运行10年，那至少需要10年365天24小时3600秒1000毫秒=320*10^9，差不多预留39bit给毫秒数 每秒的单机高峰并发量小于10W，即平均每毫秒的单机高峰并发量小于100，差不多预留7bit给每毫秒内序列号 5年内机房数小于4个，预留2bit给机房标识 每个机房小于100台机器，预留7bit给每个机房内的服务器标识 业务线小于10个，预留4bit给业务线标识 这样设计的64bit标识，优点是： 每个业务线、每个机房、每个机器生成的ID都是不同的 同一个机器，每个毫秒内生成的ID都是不同的 同一个机器，同一个毫秒内，以序列号区区分保证生成的ID是不同的 将毫秒数放在最高位，保证生成的ID是趋势递增的 缺点： 由于“没有一个全局时钟”，每台服务器分配的ID是绝对递增的，但从全局看，生成的ID只是趋势递增的(有些服务器的时间早，有些服务器的时间晚) 最后一个容易忽略的问题：生成的ID，例如message-id , order-id, tiezi-id，在数据量大时往往需要分库分表，这些ID经常作为取模分库分表的依据，为了分库分表后数据均匀，ID生成往往有“取模随机性”的需求，所以我们通常把每秒内的序列号放在ID的最末位，保证生成的ID是随机的。又如果，我们在跨毫秒时，序列号总是归0，会使得序列号为0的ID比较多，导致生成的ID取模后不均匀。解决方法是，序列号不是每次都归0，而是归一个0到9的随机数，这个地方。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[实际项目中数据结构—队列的应用]]></title>
      <url>%2F20170427%2Fdata_structure_queue%2F</url>
      <content type="text"><![CDATA[队列：一种数据结构，有非阻塞对列和阻塞对列 特点：先进先出 两种典型操作：队尾添加、队头删除 非阻塞对列：当对列满或空时进行插入或者读取删除操作，抛出异常或者返回false,不对当前线程阻塞，没有同步或者唤醒策略。 阻塞对列：当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。 阻塞队列使用：多线程协调，合作 线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素。 java中阻塞队列种类：LinkedBlockingQueue：由链表结构组成的有界阻塞队列，此队列按FIFO（先进先出）排序元素。此队列的默认和最大长度为Integer.MAX_VALUE。 LinkedTransferQueue：由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：由链表结构组成的双向阻塞队列。 ArrayBlockingQueue：由数组结构组成的有界阻塞队列。此队列按FIFO（先进先出）原则对元素进行排序。构造时需要指定容量，并可以选择是否需要公平性。如果公平参数被设置true，等待时间最长的线程会优先得到处理，会使你在性能上付出代价。 PriorityBlockingQueue：支持优先级排序的无界阻塞队列，而不是先进先出队列。元素按优先级顺序被移除，该队列也没有上限，put时是不会受阻的，对列为空，take时就会阻塞。进入该队列中的元素要具有比较能力。默认情况下元素采取自然顺序排列，也可以通过比较器comparator来指定元素的排序规则。元素按照升序排列。 DelayQueue：是一个存放Delayed元素的无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部是延迟期满后保存时间最长的Delayed元素。如果延迟都还没有期满，则队列没有头部，并且poll将返回null。当一个元素的getDelay(TimeUnit.NANOSECONDS)方法返回一个小于或等于零的值时，则出现期满，poll就以移除这个元素了。此队列不允许使用 null 元素。 DelayQueue运用在以下应用场景： 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。 定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。 SynchronousQueue：不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用，SynchronousQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。 阻塞队列控制线程操作实例多线程操作共同的队列时不需要额外的同步，队列会自动平衡负载，即那边（生产与消费两边）处理快了就会被阻塞掉，从而减少两边的处理速度差距。不需要再单独考虑同步和线程间通信的问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Test &#123; private int queueSize = 10; private ArrayBlockingQueue&lt;Integer&gt; queue = new ArrayBlockingQueue&lt;Integer&gt;(queueSize); public static void main(String[] args) &#123; Test test = new Test(); Producer producer = test.new Producer(); Consumer consumer = test.new Consumer(); producer.start(); consumer.start(); &#125; class Consumer extends Thread&#123; @Override public void run() &#123; consume(); &#125; private void consume() &#123; while(true)&#123; try &#123; queue.take(); System.out.println("从队列取走一个元素，队列剩余"+queue.size()+"个元素"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; class Producer extends Thread&#123; @Override public void run() &#123; produce(); &#125; private void produce() &#123; while(true)&#123; try &#123; queue.put(1); System.out.println("向队列取中插入一个元素，队列剩余空间："+(queueSize-queue.size())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 在并发编程中，一般推荐使用阻塞队列，这样实现可以尽量地避免程序出现意外的错误。阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。还有其他类似的场景，只要符合生产者-消费者模型的都可以使用阻塞队列。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[小身材，大味道——Leopold FC660M铝板红轴机械键盘简评]]></title>
      <url>%2F20170425%2Fleopold_fc660m_cons%2F</url>
      <content type="text"><![CDATA[介绍标题借用一下某副食品广告的宣传语。用过手中这块Leopold的FC660M新款铝板红轴机械键盘后，除了“小身材，大味道”，实在是找不出更为贴切的用词来形容它了：紧凑的键位，却能尝出远超一般紧凑键盘的味道。 Leopold这个品牌，以及代理FC660M等型号产品的志海和团队楼主不多做介绍，前人之述备矣，估计多数玩家对此比楼主更加熟悉。FC660M属于系列中比较流行，有一定保有量的一个型号，除了产品自身的品质，在外壳、键帽、轴型等方面的刻意求工和可DIY性都是量产键盘中非常少见的，也是为FC660M加分的砝码。 这次的新品，实际上是Leopold升级的一批彩色铝板FC660M，旨在用彩铝板进一步提升细节上的感觉，同时在保持机械质感的基础上尽可能让键盘变得更轻便。外壳颜色有蓝色、纯白和香槟金等，据称铝板颜色与外壳一致。轴型增加了Cherry MX红轴。楼主手中这块为样品，不能保证与市售产品完全一致，文字将以介绍为主，当中会夹杂一些主观的评价，请各位各取所需，顺便欢迎互喷。 早期的FC660M是有蓝黑色封套的，后来全部更换为无图案的牛皮瓦楞纸包装盒，用的纸板材质很硬，盒子折线棱角非常凌厉，整体倒是多了几分复古的美感。其实这种风格上的简化是受不少人欢迎的，因为封套这玩意大多是见光死，而且对于以后的收纳取用来说就是个累赘。 盒盖右上角印了LEOPOLD International的字样，之前的热升华标贴不见了，说明键帽大概是更改了刻印工艺。盒子左侧贴了规格参数，包括轴型、键数键距、尺寸重量等一系列信息，具体看图吧，自认为拍的很清楚，就不详细列举了。接口USB/PS2均可，特别标注了“采用PS2专用转换头”——但是据楼主了解，FC660M就从来没给配过USB-PS2转接口，这着实让人有点没脾气。此外，支持的系统中有Win8，但是依然没有苹果的Mac OS，貌似能支持Mac OS的机械键盘确实很少，楼(jiao)主(ni)为(men)此(you)感(qian)到(ren)略(mai)遗(Mac)憾(ha)啊(ha)。 盒子下缘还贴有一张型号、名称的标签。可以看到型号为FC660MR/PPW3，至于每一项代表什么意思，逐个对照下面的中文能基本弄明白，其中PP这两项楼主专门问过有关部门，得到的答案是粉色代号。对此楼主猜测可能是考虑到实际配色的效果，对色系进行了调整，总之不要在意这些细节就对了。 打开颇具逼格的双排扣(什么鬼)，内部附件包含键盘、键盘线、拔键器和印刷品。实际上拔键器是在包装盒外面的，盒子内部空间由一块纸板分隔成两个区域，分别放置键盘和键盘线，已经没有多余的地方来容纳这个凹凸有致的拔键器了，就当是额外附送的吧，心理感觉还能更棒一些。 键盘外面包裹的塑料袋上有警示语，这主要是针对袋子写的，大意是别让熊孩子们靠近这个袋子，不小心被塑料薄膜封住嘴巴鼻子可不是闹着玩的——好吧，这个不点赞恐怕有点不道德。总体来讲，附件虽然略显简单，但是给人感觉很“干净”，会产生一种莫名的好感。 键盘本体键盘本体。配列显然是FC660M的主要亮点，也是一些玩家会爱上它的重要原因。一共有66键，与常规的60%键盘(61键)相比，增加了四个方向键、两个功能键，去掉了一个1.25×键位。方向键独立，采用嵌入的方式与主键区连接在一起，同时将常规的Win键改成了1×规格；将RShift改成了2.25×规格(与LShift相同)。倒置RCtrl与Fn键位——这大概是为了保留Fn键常规的位置以迎合人们使用组合键的习惯——当然喜欢用RCtrl的兄弟们就会比较杯具了。Ins与Del键使用独立键位，这是FC660M的一个标志性设计，也为不少用户所称道。不过楼主平时很少用到这两个键，对该设计的好感仅仅是因为它对整个键盘的点缀作用，有这么一点特立独行的味道，在一定程度上增加了逼格。 白色键帽、香槟金色外壳(略带一些淡粉的感觉，或许是P代号的由来)，整体感觉清新而淡雅。 底盘使用了Leopold常用的防滑垫排布，撑脚上也有胶套，实测防滑能力很厚道。中间是贴纸铭牌。 底盘左侧有一个四位DIP开关，具体作用如下： FC660M的键帽接近原厂高度，比常规的OEM键帽矮一些，但是纵向的阶梯感仍很突出。支起撑脚后键帽整体表面与水平面形成一个约12°的完美夹角。 常规的窄边框设计。外壳是ABS材质，喷漆的效果酷似铝材的阳极氧化工艺。键盘线接口使用的依然是较传统的MiniUSB，位置在外壳上缘的右侧，四周做了内陷，可惜口大了点，无法对键盘线的USB头起到固定作用，仅仅属于美观设计。 键帽的白色很正，但又没有白得过分刺眼，略显柔和的感觉。刻印方式确认是激光蚀刻，不过触摸表面几乎感觉不到字符的凸起，工艺水平很高。与早期版本不同，组合键的侧刻同样使用了激光蚀刻，使之整体看起来更统一、协调。 加厚的PBT键帽，手感非常扎实，十字菊花做了倒角处理，易于安装。Caps和Ins两个键灯窗也很精致。唯一可惜的地方在于这一版本的白色空格键改回了三菊花——尽管这对FC660M本身并不影响什么。 键盘线是常规的胶线，镀金USB口、抗屏蔽磁环、理线带等一应俱全，接口上还套了保护罩，连MiniUSB口上都有，俨然是高配线材的赶脚，美中不足是线有点硬。 Leopold原装的拔键器，做工非常精致，柄上有阴刻的Leopold标识，手柄长度较短，便于收纳携带。(楼主有不少Filco的拔键器，手柄都偏长，放袋子里就不太方便) 拔掉键帽看轴，那是一片红彤彤的光景，让人忍不住要唱一首《好日子》(有完没完了)。楼主刚入门的时候，还没有OEM红轴键盘可选，后来逐渐烂大街，红轴党们也是铺天盖地，而现在樱桃只对部分品牌供轴了，似乎又紧俏了起来，真是风水轮流转(你个头啊)。 全键盘正装轴，仅有的两个带灯键位采用的是234方形LED，基本上大神们都很推崇这种灯珠，不管是体积还是发光效果用作按键背光确实要更合适些。至于轴体正装这事，背光党们其实也用不着觉得蛋疼——因为板子不留灯位这一点早已经让你们蛋碎了，身为反背光党楼主感觉毫无压力。而说回来，这更多的是产品风格和方向问题吧，楼主觉得只要不是那种离了灯就没法活的人，应该还是能接受牺牲掉一点炫酷来换取一些纯粹的质感的。 大键位采用的是卫星轴，手感调节尚可，按起来虽然不能说爽脆，但是没什么特别肉的感觉，并且继承了卫星轴大键下盘扎实的特点，个人还是比较喜爱这种手感的。空格键的伪轴位置与其它键盘有或多或少的区别，这给替换第三方空格带来了一定的困难，好在志海和本身就是做键帽的大户，这方面基本上是一条龙服务。 拆解进入拆解篇。全键盘只使用了一颗螺丝，位置在DIP开关旁OK贴下方。卸掉螺丝，再撬开上下边的八个卡榫就行了。值得注意的一点是：下缘两边的那两个卡榫特别难撬，要用点力气；上缘MiniUSB口附近的那个卡榫别大力艹，避免弄断镂空位置的细边。 铝板采用了阳极氧化的工艺，这也是亮点之一。颜色目测并不是纯正的香槟金，而是银色同时似乎看着又有点淡粉色在里面，就这一问题楼主也咨询过有关部门，得到的解释是阳极的香槟金色系颜色很重，真实效果不太耐看，因此换成了浅粉色(不知道是楼主色差还是粉色确实很微弱，总体颜色感觉接近银白)。 铝板上下边钣金处理成向上弯曲，正好嵌入到上壳内部以起到额外的支撑作用；四角全部切去了一小部分，用于容纳上壳内部的加强筋结构；铝板四条边均压住底盘边缘，按键力道全部由铝板和底盘承受，避免了PCB额外受力。底板上有两个限位＋支撑柱，同时与底盘三面都连接有加强筋，力学设计虽不复杂，但支撑一块铝板已是非常周到。 湖蓝色喷油、玻纤基板、双面电路PCB。背面布线较为简洁，留有大面积的覆铜。电路标注得很详细，包括键位、元件指示。支持日版配列，并且标示在了对应的空余轴位上。原装使用的是三脚轴，但留有安装五角轴的孔。除了方向键，其余键位都没有预留灯位。方向键同样是轴体正装，或许可以用测刻透光键帽来展示这一缕仅存的骚气。 焊点如图。每个键位都有贴片无冲二极管，不过并未模拟USB口下的全键无冲，实测使用USB连接的话，只支持任意六键无冲。好在几乎没有人会拿紧凑键盘玩双人模拟器游戏，原生六键无冲一般情况下也足够了。PCB下缘中间的位置有镂空刻印的LEOPOLD裸铜字样，基本属于Leopold键盘的一个标志性做法。 FC660M采用了合泰8位MCU、6MHz晶振。MiniUSB接口直接焊在了板子上，与底盘出口的契合精度还是很高的，不过对比了底板的结构后发现保护措施不是很到位。铝板上还带有多处定位点，可以卡住PCB，这也是Leopold键盘上比较多见的特色，固定措施总是不嫌多嘛。铝板和PCB的厚度还算可观，都略厚于一元硬币。 使用&amp;测试冲突测试： U口任意六键无冲。 P口全键无冲。 手感测试：简单说一下樱桃红轴，总行程：4.0-0.4mm；触发行程：2±0.6mm；初始压力：30cN min.；触发压力：45±15cN；触底压力能达到60cN左右。属于轻量级的樱桃轴，线性无段落，打字很轻盈，但是部分游戏党可能会觉得下手难知轻重，影响操作的稳定性——这个自然是因人而异。 除了樱桃轴、大键位伪轴的调节对手感的影响，铝板和底盘的力学结构也有不少的提升作用：按键下压力首先传递到铝板上，然后通过四周边缘及中间的支撑柱扩散至底盘，可以说整个过程中力的反馈是很均匀的；其次铝板相对于钢板质感更偏轻柔，搭配樱桃红轴这种比较轻盈的轴体，手感可以说刚柔并济，起码给人的心理暗示就非常微妙。 功能测试：除了DPI开关对部分键位的调节作用，FC660M的各类组合键也附带了相当实用的功能。如Esc键可分别与Shift、Fn键组合打出~和字符，亦可通过Fn＋Q直接将Esc切换为常规的“键”；Fn＋任一数字键则是对应数字序号的F区功能键；Fn＋RCrtl可组合成常规104键盘上的属性键等等… 详细的按键功能表如图。 总结优点： 配列、组合键及个别键位的设计非常合理、便捷； 键盘整体做工、用料、结构设计、工程审美都属于较高水平； 彩色铝板的采用，使得键盘更加轻便，作为带“板”的紧凑机械键盘，已具有相当优势的便携性； 加厚PBT白色键帽手感比较扎实，蚀刻字符凸起感很弱，工艺不错。 不足： 作为一把萌萌哒的紧凑键盘，操作系统支持不够全面还是有点遗憾的； MiniUSB口内部没有强化支撑，外部也没有对键盘线设计固定措施； 轴板未预留灯位，虽然无关键盘本身，楼主也并非背光党，但对于大多数玩家来说，不得不承认确实少了一份乐趣。 Leopold的键盘一般强调做工、特色和功能性，而性价比一直都不能算是它的强项。彩铝板FC660M目前仍未进入市售环节，价格暂时不得而知，但是一般情况下阳极氧化铝板总比钢板贵一些，所以楼主猜测同样的轴型价格应该是高于钢板款的。首发渠道据有关部门称，此次可能会选择囧东或者天喵。 小五原创(in外设ID：fio )，转载请注明]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java正则速成秘籍（三）之见招拆招篇]]></title>
      <url>%2F20170421%2Fregular_java_3%2F</url>
      <content type="text"><![CDATA[导读正则表达式是什么？有什么用？正则表达式(Regular Expression)是一种文本规则，可以用来校验、查找、替换与规则匹配的文本。又爱又恨的正则正则表达式是一个强大的文本匹配工具，但是它的规则实在很繁琐，而且理解起来也颇为蛋疼，容易让人望而生畏。如何学习正则刚接触正则时，我看了一堆正则的语义说明，但是仍然不明所以。后来，我多接触一些正则的应用实例，渐渐有了感觉，再结合语义说明，终有领悟。我觉得正则表达式和武侠修练武功差不多，应该先练招式，再练心法。如果一开始就直接看正则的规则，保证你会懵逼。当你熟悉基本招式（正则基本使用案例）后，也该修炼修炼心法（正则语法）了。真正的高手不能只靠死记硬背那么几招把式。就像张三丰教张无忌太极拳一样，领悟心法，融会贯通，少侠你就可以无招胜有招，成为传说中的绝世高手。 以上闲话可归纳为一句：学习正则应该从实例去理解规则。 打开秘籍：欲练神功，必先自宫！没有蛋，也就不会蛋疼了。Java正则速成秘籍分三篇： Java正则速成秘籍（一）之招式篇展示Java对于正则表达式的支持。 Java正则速成秘籍（二）之心法篇介绍正则表达式的语法规则。 Java正则速成秘籍（三）之见招拆招篇从实战出发，介绍正则的常用案例。 本文是Java正则速成秘籍的最后一篇——见招拆招篇。在 Java正则速成秘籍（一）之招式篇 和 Java正则速成秘籍（二）之心法篇，我们学习了Java支持正则功能的API以及正则表达式的语法。本文则主要展示正则表达式在现实场景的应用。文中不会再提及正则的语法以及Java正则相关的API，如有疑问，可以参考前面两篇文章。 正则应用虽然本系列洋洋洒洒的大谈特谈正则表达式。但是我还是要在这里建议，如果一个正则表达式没有经过充分测试，还是要谨慎使用。正则是把双刃剑，它可以为你节省大量的代码行。但是由于它不易阅读，维护起来可是头疼的哦（你需要一个字符一个字符的去理解）。 最实用的正则校验中文描述：校验字符串中只能有中文字符（不包括中文标点符号）。中文字符的Unicode编码范围是\u4e00 到 \u9fa5。如有兴趣，可以参考百度百科-Unicode 。 ^[\u4e00-\u9fa5]+$匹配： 春眠不觉晓不匹配：春眠不觉晓， 校验身份证号码描述：身份证为15位或18位。15位是第一代身份证。从1999年10月1日起，全国实行公民身份证号码制度，居民身份证编号由原15位升至18位。 15位身份证 描述：由15位数字组成。排列顺序从左至右依次为：六位数字地区码；六位数字出生日期；三位顺序号，其中15位男为单数，女为双数。 18位身份证描述：由十七位数字本体码和一位数字校验码组成。排列顺序从左至右依次为：六位数字地区码；八位数字出生日期；三位数字顺序码和一位数字校验码（也可能是X）。 身份证号含义详情请见：百度百科-居民身份证号码 地区码（6位）(1[1-5]|2[1-3]|3[1-7]|4[1-3]|5[0-4]|6[1-5])\d{4}出生日期（8位）注：下面的是18位身份证的有效出生日期，如果是15位身份证，只要将第一个\d{4}改为\d{2}即可。((\d{4}((0[13578]|1[02])(0[1-9]|[12]\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\d|30)|02(0[1-9]|1\d|2[0-8])))|([02468][048]|[13579][26])0229) 15位有效身份证 ^((1[1-5]|2[1-3]|3[1-7]|4[1-3]|5[0-4]|6[1-5])\d{4})((\d{2}((0[13578]|1[02])(0[1-9]|[12]\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\d|30)|02(0[1-9]|1\d|2[0-8])))|([02468][048]|[13579][26])0229)(\d{3})$匹配：110001700101031不匹配：110001701501031 18位有效身份证 ^((1[1-5]|2[1-3]|3[1-7]|4[1-3]|5[0-4]|6[1-5])\d{4})((\d{4}((0[13578]|1[02])(0[1-9]|[12]\d|3[01])|(0[13456789]|1[012])(0[1-9]|[12]\d|30)|02(0[1-9]|1\d|2[0-8])))|([02468][048]|[13579][26])0229)(\d{3}(\d|X))$匹配：110001199001010310 | 11000019900101015X不匹配：990000199001010310 | 110001199013010310 校验有效用户名、密码描述：长度为6-18个字符，允许输入字母、数字、下划线，首字符必须为字母。^[a-zA-Z]\w{5,17}$匹配：he_llo@worl.d.com | hel.l-o@wor-ld.museum | h1ello@123.com不匹配：hello@worl_d.com | he&amp;llo@world.co1 | .hello@wor#.co.uk 校验邮箱描述：不允许使用IP作为域名，如 : hello@154.145.68.12@符号前的邮箱用户和.符号前的域名(domain)必须满足以下条件： 字符只能是英文字母、数字、下划线_、.、- ； 首字符必须为字母或数字； _、.、- 不能连续出现。 域名的根域只能为字母，且至少为两个字符。 ^[A-Za-z0-9](([_\.\-]?[a-zA-Z0-9]+)*)@([A-Za-z0-9]+)(([\.\-]?[a-zA-Z0-9]+)*)\.([A-Za-z]{2,})$匹配：he_llo@worl.d.com | hel.l-o@wor-ld.museum | h1ello@123.com不匹配：hello@worl_d.com | he&amp;llo@world.co1 | .hello@wor#.co.uk 校验URL描述：校验URL。支持http、https、ftp、ftps。^(ht|f)(tp|tps)\://[a-zA-Z0-9\-\.]+\.([a-zA-Z]{2,3})?(/\S*)?$匹配：http://google.com/help/me | http://www.google.com/help/me/ | https://www.google.com/help.asp | ftp://www.google.com | ftps://google.org不匹配：http://un/www.google.com/index.asp 校验时间描述：校验时间。时、分、秒必须是有效数字，如果数值不是两位数，十位需要补零。^([0-1][0-9]|[2][0-3]):([0-5][0-9])$匹配：00:00:00 | 23:59:59 | 17:06:30不匹配：17:6:30 | 24:16:30 校验日期描述：校验日期。日期满足以下条件： 格式yyyy-MM-dd或yyyy-M-d 连字符可以没有或是-、/、.之一 闰年的二月可以有29日；而平年不可以。 一、三、五、七、八、十、十二月为31日。四、六、九、十一月为30日。 ^(?:(?!0000)[0-9]{4}([-/.]?)(?:(?:0?[1-9]|1[0-2])\1(?:0?[1-9]|1[0-9]|2[0-8])|(?:0?[13-9]|1[0-2])\1(?:29|30)|(?:0?[13578]|1[02])\1(?:31))|(?:[0-9]{2}(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)([-/.]?)0?2\2(?:29))$匹配：2016/1/1 | 2016/01/01 | 20160101 | 2016-01-01 | 2016.01.01 | 2000-02-29不匹配：2001-02-29 | 2016/12/32 | 2016/6/31 | 2016/13/1 | 2016/0/1 校验中国手机号码描述：中国手机号码正确格式：11位数字。移动有16个号段：134、135、136、137、138、139、147、150、151、152、157、158、159、182、187、188。其中147、157、188是3G号段，其他都是2G号段。联通有7种号段：130、131、132、155、156、185、186。其中186是3G（WCDMA）号段，其余为2G号段。电信有4个号段：133、153、180、189。其中189是3G号段（CDMA2000），133号段主要用作无线网卡号。总结：13开头手机号0-9；15开头手机号0-3、5-9；18开头手机号0、2、5-9。此外，中国在国际上的区号为86，所以手机号开头有+86、86也是合法的。以上信息来源于 百度百科-手机号 ^((\+)?86\s*)?((13[0-9])|(15([0-3]|[5-9]))|(18[0,2,5-9]))\d{8}$匹配：+86 18012345678 | 86 18012345678 | 15812345678不匹配：15412345678 | 12912345678 | 180123456789 校验中国固话号码描述：固话号码，必须加区号（以0开头）。3位有效区号：010、020~029，固话位数为8位。4位有效区号：03xx开头到09xx，固话位数为7。如果想了解更详细的信息，请参考 百度百科-电话区号 。 ^(010|02[0-9])(\s|-)\d{8}|(0[3-9]\d{2})(\s|-)\d{7}$匹配：010-12345678 | 010 12345678 | 0512-1234567 | 0512 1234567不匹配：1234567 | 12345678 校验IPv4地址描述：IP地址是一个32位的二进制数，通常被分割为4个“8位二进制数”（也就是4个字节）。IP地址通常用“点分十进制”表示成（a.b.c.d）的形式，其中，a,b,c,d都是0~255之间的十进制整数。 ^([01]?\d\d?|2[0-4]\d|25[0-5])\.([01]?\d\d?|2[0-4]\d|25[0-5])\.([01]?\d\d?|2[0-4]\d|25[0-5])\.([01]?\d\d?|2[0-4]\d|25[0-5])$匹配：0.0.0.0 | 255.255.255.255 | 127.0.0.1不匹配：10.10.10 | 10.10.10.256 校验IPv6地址描述：IPv6的128位地址通常写成8组，每组为四个十六进制数的形式。IPv6地址可以表示为以下形式： IPv6 地址 零压缩 IPv6 地址(section 2.2 of rfc5952) 带有本地链接区域索引的 IPv6 地址 (section 11 of rfc4007) 嵌入IPv4的 IPv6 地址(section 2 of rfc6052 映射IPv4的 IPv6 地址 (section 2.1 of rfc2765) 翻译IPv4的 IPv6 地址 (section 2.1 of rfc2765)显然，IPv6地址的表示方式很复杂。你也可以参考百度百科-IPv6 Stack overflow上的IPv6正则表达高票答案(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))匹配： 1:2:3:4:5:6:7:8 | 1:: | 1::8 | 1::6:7:8 | 1::5:6:7:8 | 1::4:5:6:7:8 | 1::3:4:5:6:7:8 | ::2:3:4:5:6:7:8 | 1:2:3:4:5:6:7:: | 1:2:3:4:5:6::8 | 1:2:3:4:5::8 | 1:2:3:4::8 | 1:2:3::8 | 1:2::8 | 1::8 | ::8 | fe80::7:8%1 | ::255.255.255.255 | 2001:db8:3:4::192.0.2.33 | 64:ff9b::192.0.2.33不匹配： 1.2.3.4.5.6.7.8 | 1::2::3 特定字符 匹配长度为3的字符串：^.{3}$。 匹配由26个英文字母组成的字符串：^[A-Za-z]+$。 匹配由26个大写英文字母组成的字符串：^[A-Z]+$。 匹配由26个小写英文字母组成的字符串：^[a-z]+$。 匹配由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$。 匹配由数字、26个英文字母或者下划线组成的字符串：^\w+$。 特定数字 匹配正整数：^[1-9]\d*$ 匹配负整数：^-[1-9]\d*$ 匹配整数：^(-?[1-9]\d*)|0$ 匹配正浮点数：^[1-9]\d*\.\d+|0\.\d+$ 匹配负浮点数：^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$ 匹配浮点数：^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ 参考正则应用之——日期正则表达式http://www.regexlib.com/作者：静默虚空出处：http://www.cnblogs.com/jingmoxukong/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java正则速成秘籍（二）之心法篇]]></title>
      <url>%2F20170421%2Fregular_java_2%2F</url>
      <content type="text"><![CDATA[导读正则表达式是什么？有什么用？正则表达式(Regular Expression)是一种文本规则，可以用来校验、查找、替换与规则匹配的文本。又爱又恨的正则正则表达式是一个强大的文本匹配工具，但是它的规则实在很繁琐，而且理解起来也颇为蛋疼，容易让人望而生畏。如何学习正则刚接触正则时，我看了一堆正则的语义说明，但是仍然不明所以。后来，我多接触一些正则的应用实例，渐渐有了感觉，再结合语义说明，终有领悟。我觉得正则表达式和武侠修练武功差不多，应该先练招式，再练心法。如果一开始就直接看正则的规则，保证你会懵逼。当你熟悉基本招式（正则基本使用案例）后，也该修炼修炼心法（正则语法）了。真正的高手不能只靠死记硬背那么几招把式。就像张三丰教张无忌太极拳一样，领悟心法，融会贯通，少侠你就可以无招胜有招，成为传说中的绝世高手。 以上闲话可归纳为一句：学习正则应该从实例去理解规则。 打开秘籍：欲练神功，必先自宫！没有蛋，也就不会蛋疼了。Java正则速成秘籍分三篇： Java正则速成秘籍（一）之招式篇展示Java对于正则表达式的支持。 Java正则速成秘籍（二）之心法篇介绍正则表达式的语法规则。 Java正则速成秘籍（三）之见招拆招篇从实战出发，介绍正则的常用案例。在 Java正则速成秘籍（一）之招式篇 一文，我们学习了Java支持正则功能的API。本文是Java正则速成秘籍的心法篇。主要介绍正则表达式的语法规则。正则语法规则是一种标准，主流开发语言对于正则语法的支持大体相同。分组构造、贪婪与懒惰属于正则表达式中较为复杂的应用，建议理解完基本元字符后再去了解。本文案例中使用的checkMatches、findAll方法请见附录。 概述为了理解下面章节的内容，你需要先了解一些基本概念。 正则表达式 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。 元字符元字符(metacharacters)就是正则表达式中具有特殊意义的专用字符。 普通字符普通字符包括没有显式指定为元字符的所有可打印和不可打印字符。这包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。 元字符基本元字符正则表达式的元字符难以记忆，很大程度上是因为有很多为了简化表达而出现的等价字符。而实际上最基本的元字符，并没有那么多。对于大部分的场景，基本元字符都可以搞定。让我们从一个个实例出发，由浅入深的去体会正则的奥妙。 多选 - |例 匹配一个确定的字符串1checkMatches("abc", "abc"); 如果要匹配一个确定的字符串，非常简单，如例1所示。如果你不确定要匹配的字符串，希望有多个选择，怎么办？答案是：使用元字符| ，它的含义是或。 例 匹配多个可选的字符串1234// 测试正则表达式字符：|Assert.assertTrue(checkMatches("yes|no", "yes"));Assert.assertTrue(checkMatches("yes|no", "no"));Assert.assertFalse(checkMatches("yes|no", "right")); 输出123yes matches： yes|nono matches： yes|noright not matches： yes|no 分组 - ()如果你希望表达式由多个子表达式组成，你可以使用()。 例 匹配组合字符串1234Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "ended"));Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "ending"));Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "playing"));Assert.assertTrue(checkMatches("(play|end)(ing|ed)", "played")); 输出1234ended matches： (play|end)(ing|ed)ending matches： (play|end)(ing|ed)playing matches： (play|end)(ing|ed)played matches： (play|end)(ing|ed) 指定单字符有效范围 - []前面展示了如何匹配字符串，但是很多时候你需要精确的匹配一个字符，这时可以使用[] 。例 字符在指定范围1234567// 测试正则表达式字符：[]Assert.assertTrue(checkMatches("[abc]", "b")); // 字符只能是a、b、cAssert.assertTrue(checkMatches("[a-z]", "m")); // 字符只能是a - zAssert.assertTrue(checkMatches("[A-Z]", "O")); // 字符只能是A - ZAssert.assertTrue(checkMatches("[a-zA-Z]", "K")); // 字符只能是a - z和A - ZAssert.assertTrue(checkMatches("[a-zA-Z]", "k"));Assert.assertTrue(checkMatches("[0-9]", "5")); // 字符只能是0 - 9 输出123456b matches： [abc]m matches： [a-z]O matches： [A-Z]K matches： [a-zA-Z]k matches： [a-zA-Z]5 matches： [0-9] 指定单字符无效范围 - [^]例 字符不能在指定范围 如果需要匹配一个字符的逆操作，即字符不能在指定范围，可以使用[^]。1234567// 测试正则表达式字符：[^]Assert.assertFalse(checkMatches("[^abc]", "b")); // 字符不能是a、b、cAssert.assertFalse(checkMatches("[^a-z]", "m")); // 字符不能是a - zAssert.assertFalse(checkMatches("[^A-Z]", "O")); // 字符不能是A - ZAssert.assertFalse(checkMatches("[^a-zA-Z]", "K")); // 字符不能是a - z和A - ZAssert.assertFalse(checkMatches("[^a-zA-Z]", "k"));Assert.assertFalse(checkMatches("[^0-9]", "5")); // 字符不能是0 - 9 输出123456b not matches： [^abc]m not matches： [^a-z]O not matches： [^A-Z]K not matches： [^a-zA-Z]k not matches： [^a-zA-Z]5 not matches： [^0-9] 限制字符数量 - {}如果想要控制字符出现的次数，可以使用{}。字符描述{n}n 是一个非负整数。匹配确定的 n 次。{n,}n 是一个非负整数。至少匹配 n 次。{n,m}m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。 例 限制字符出现次数1234567891011121314151617// &#123;n&#125;: n 是一个非负整数。匹配确定的 n 次。checkMatches("ap&#123;1&#125;", "a");checkMatches("ap&#123;1&#125;", "ap");checkMatches("ap&#123;1&#125;", "app");checkMatches("ap&#123;1&#125;", "apppppppppp");// &#123;n,&#125;: n 是一个非负整数。至少匹配 n 次。checkMatches("ap&#123;1,&#125;", "a");checkMatches("ap&#123;1,&#125;", "ap");checkMatches("ap&#123;1,&#125;", "app");checkMatches("ap&#123;1,&#125;", "apppppppppp");// &#123;n,m&#125;: m 和 n 均为非负整数，其中 n &lt;= m。最少匹配 n 次且最多匹配 m 次。checkMatches("ap&#123;2,5&#125;", "a");checkMatches("ap&#123;2,5&#125;", "ap");checkMatches("ap&#123;2,5&#125;", "app");checkMatches("ap&#123;2,5&#125;", "apppppppppp"); 输出123456789101112a not matches： ap&#123;1&#125;ap matches： ap&#123;1&#125;app not matches： ap&#123;1&#125;apppppppppp not matches： ap&#123;1&#125;a not matches： ap&#123;1,&#125;ap matches： ap&#123;1,&#125;app matches： ap&#123;1,&#125;apppppppppp matches： ap&#123;1,&#125;a not matches： ap&#123;2,5&#125;ap not matches： ap&#123;2,5&#125;app matches： ap&#123;2,5&#125;apppppppppp not matches： ap&#123;2,5&#125; 转义字符 - /如果想要查找元字符本身，你需要使用转义符，使得正则引擎将其视作一个普通字符，而不是一个元字符去处理。 * 的转义字符：\* + 的转义字符：\+ ? 的转义字符：\? ^ 的转义字符：\^ $ 的转义字符：\$ . 的转义字符：\.如果是转义符\本身，你也需要使用\\ 。 指定表达式字符串的开始和结尾 - ^、$如果希望匹配的字符串必须以特定字符串开头，可以使用^ 。注：请特别留意，这里的^ 一定要和 [^] 中的 ^ 区分。 例 限制字符串头部12Assert.assertTrue(checkMatches("^app[a-z]&#123;0,&#125;", "apple")); // 字符串必须以app开头Assert.assertFalse(checkMatches("^app[a-z]&#123;0,&#125;", "aplause")); 输出12apple matches： ^app[a-z]&#123;0,&#125;aplause not matches： ^app[a-z]&#123;0,&#125; 如果希望匹配的字符串必须以特定字符串开头，可以使用$ 。例 限制字符串尾部12Assert.assertTrue(checkMatches("[a-z]&#123;0,&#125;ing$", "playing")); // 字符串必须以ing结尾Assert.assertFalse(checkMatches("[a-z]&#123;0,&#125;ing$", "long")); 输出12playing matches： [a-z]&#123;0,&#125;ing$long not matches： [a-z]&#123;0,&#125;ing$ 等价字符等价字符，顾名思义，就是对于基本元字符表达的一种简化（等价字符的功能都可以通过基本元字符来实现）。在没有掌握基本元字符之前，可以先不用理会，因为很容易把人绕晕。等价字符的好处在于简化了基本元字符的写法。 表示某一类型字符的等价字符下表中的等价字符都表示某一类型的字符。 字符 描述 . 匹配除\n之外的任何单个字符。 \d 匹配一个数字字符。等价于[0-9]。 \D 匹配一个非数字字符。等价于[^0-9]。 \w 匹配包括下划线的任何单词字符。类似但不等价于[A-Za-z0-9_]，这里的单词字符指的是Unicode字符集。 \W 匹配任何非单词字符。 \s 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。 \S 匹配任何可见字符。等价于[ \f\n\r\t\v]。 案例 基本等价字符的用法12345678910111213141516171819202122// 匹配除“\n”之外的任何单个字符Assert.assertTrue(checkMatches(".&#123;1,&#125;", "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_"));Assert.assertTrue(checkMatches(".&#123;1,&#125;", "~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\"));Assert.assertFalse(checkMatches(".", "\n"));Assert.assertFalse(checkMatches("[^\n]", "\n"));// 匹配一个数字字符。等价于[0-9]Assert.assertTrue(checkMatches("\\d&#123;1,&#125;", "0123456789"));// 匹配一个非数字字符。等价于[^0-9]Assert.assertFalse(checkMatches("\\D&#123;1,&#125;", "0123456789"));// 匹配包括下划线的任何单词字符。类似但不等价于“[A-Za-z0-9_]”，这里的单词字符指的是Unicode字符集Assert.assertTrue(checkMatches("\\w&#123;1,&#125;", "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_"));Assert.assertFalse(checkMatches("\\w&#123;1,&#125;", "~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\"));// 匹配任何非单词字符Assert.assertFalse(checkMatches("\\W&#123;1,&#125;", "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_"));Assert.assertTrue(checkMatches("\\W&#123;1,&#125;", "~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\"));// 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]Assert.assertTrue(checkMatches("\\s&#123;1,&#125;", " \f\r\n\t"));// 匹配任何可见字符。等价于[^ \f\n\r\t\v]Assert.assertFalse(checkMatches("\\S&#123;1,&#125;", " \f\r\n\t")); 输出123456789101112ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_ matches： .&#123;1,&#125;~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\ matches： .&#123;1,&#125;\n not matches： .\n not matches： [^\n]0123456789 matches： \\d&#123;1,&#125;0123456789 not matches： \\D&#123;1,&#125;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_ matches： \\w&#123;1,&#125;~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\ not matches： \\w&#123;1,&#125;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_ not matches： \\W&#123;1,&#125;~!@#$%^&amp;*()+`-=[]&#123;&#125;;:&lt;&gt;,./?|\\ matches： \\W&#123;1,&#125; \f\r\n\t matches： \\s&#123;1,&#125; \f\r\n\t not matches： \\S&#123;1,&#125; 限制字符数量的等价字符在基本元字符章节中，已经介绍了限制字符数量的基本元字符 - {} 。此外，还有 *、+、? 这个三个为了简化写法而出现的等价字符，我们来认识一下。字符描述*匹配前面的子表达式零次或多次。等价于{0,}。+匹配前面的子表达式一次或多次。等价于{1,}。?匹配前面的子表达式零次或一次。等价于{0,1}。 案例 限制字符数量的等价字符1234567891011121314151617// *: 匹配前面的子表达式零次或多次。* 等价于&#123;0,&#125;。checkMatches("ap*", "a");checkMatches("ap*", "ap");checkMatches("ap*", "app");checkMatches("ap*", "apppppppppp");// +: 匹配前面的子表达式一次或多次。+ 等价于 &#123;1,&#125;。checkMatches("ap+", "a");checkMatches("ap+", "ap");checkMatches("ap+", "app");checkMatches("ap+", "apppppppppp");// ?: 匹配前面的子表达式零次或一次。? 等价于 &#123;0,1&#125;。checkMatches("ap?", "a");checkMatches("ap?", "ap");checkMatches("ap?", "app");checkMatches("ap?", "apppppppppp"); 输出123456789101112a matches： ap*ap matches： ap*app matches： ap*apppppppppp matches： ap*a not matches： ap+ap matches： ap+app matches： ap+apppppppppp matches： ap+a matches： ap?ap matches： ap?app not matches： ap?apppppppppp not matches： ap? 元字符优先级顺序正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 说明 \ 转义符 (), (?:), (?=), [] 括号和中括号 *,+, ?, {n}, {n,}, {n,m} 限定符 ^, $, *任何元字符、任何字符* 定位点和序列 \ &nbsp; 字符具有高于替换运算符的优先级，使得m|food匹配m或food。若要匹配mood或food，请使用括号创建子表达式，从而产生(m|f)ood。 分组构造在基本元字符章节，提到了 () 字符可以用来对表达式分组。实际上分组还有更多复杂的用法。所谓分组构造，是用来描述正则表达式的子表达式，用于捕获字符串中的子字符串。 捕获与非捕获下表为分组构造中的捕获和非捕获分类。 表达式 描述 捕获或非捕获 (exp) 匹配的子表达式 捕获 (?&lt;name&gt;exp) 命名的反向引用 捕获 (?:exp) 非捕获组 非捕获 (?=exp) 零宽度正预测先行断言 非捕获 (?!exp) 零宽度负预测先行断言 非捕获 (?&lt;=exp) 零宽度正回顾后发断言 非捕获 (?&lt;!exp) 零宽度负回顾后发断言 非捕获 注：Java正则引擎不支持平衡组。 反向引用带编号的反向引用带编号的反向引用使用以下语法：\number其中number是正则表达式中捕获组的序号位置。 例如，\4 匹配第四个捕获组的内容。 如果正则表达式模式中未定义number，则将发生分析错误 例 匹配重复的单词和紧随每个重复的单词的单词(不命名子表达式)123// (\w+)\s\1\W(\w+) 匹配重复的单词和紧随每个重复的单词的单词Assert.assertTrue(findAll("(\\w+)\\s\\1\\W(\\w+)", "He said that that was the the correct answer.") &gt; 0); 输出123regex = (\w+)\s\1\W(\w+), content: He said that that was the the correct answer.[1th] start: 8, end: 21, group: that that was[2th] start: 22, end: 37, group: the the correct 说明 (\w+): 匹配一个或多个单词字符。 \s: 与空白字符匹配。 \1: 匹配第一个组，即(\w+)。 \W: 匹配包括空格和标点符号的一个非单词字符。 这样可以防止正则表达式模式匹配从第一个捕获组的单词开头的单词。 命名的反向引用命名后向引用通过使用下面的语法进行定义：\k&lt;name&gt;例 匹配重复的单词和紧随每个重复的单词的单词(命名子表达式)123// (?&lt;duplicateWord&gt;\w+)\s\k&lt;duplicateWord&gt;\W(?&lt;nextWord&gt;\w+) 匹配重复的单词和紧随每个重复的单词的单词Assert.assertTrue(findAll("(?&lt;duplicateWord&gt;\\w+)\\s\\k&lt;duplicateWord&gt;\\W(?&lt;nextWord&gt;\\w+)", "He said that that was the the correct answer.") &gt; 0); 输出123regex = (?&lt;duplicateWord&gt;\w+)\s\k&lt;duplicateWord&gt;\W(?&lt;nextWord&gt;\w+), content: He said that that was the the correct answer.[1th] start: 8, end: 21, group: that that was[2th] start: 22, end: 37, group: the the correct 说明 (?\w+): 匹配一个或多个单词字符。 命名此捕获组 duplicateWord。 \s: 与空白字符匹配。 \k: 匹配名为 duplicateWord 的捕获的组。 \W: 匹配包括空格和标点符号的一个非单词字符。 这样可以防止正则表达式模式匹配从第一个捕获组的单词开头的单词。 (?\w+): 匹配一个或多个单词字符。 命名此捕获组 nextWord。 非捕获组(?:exp) 表示当一个限定符应用到一个组，但组捕获的子字符串并非所需时，通常会使用非捕获组构造。例 匹配以.结束的语句。12// 匹配由句号终止的语句。Assert.assertTrue(findAll("(?:\\b(?:\\w+)\\W*)+\\.", "This is a short sentence. Never end") &gt; 0); 输出12regex = (?:\b(?:\w+)\W*)+\., content: This is a short sentence. Never end[1th] start: 0, end: 25, group: This is a short sentence. 零宽断言用于查找在某些内容(但并不包括这些内容)之前或之后的东西，也就是说它们像\b,^,$那样用于指定一个位置，这个位置应该满足一定的条件(即断言)，因此它们也被称为零宽断言。 表达式 描述 (?=exp) 匹配exp前面的位置 (?&lt;=exp) 匹配exp后面的位置 (?!exp) 匹配后面跟的不是exp的位置 (?&lt;!exp) 匹配前面不是exp的位置 匹配exp前面的位置(?=exp) 表示输入字符串必须匹配子表达式中的正则表达式模式，尽管匹配的子字符串未包含在匹配结果中。12345// \b\w+(?=\sis\b) 表示要捕获is之前的单词Assert.assertTrue(findAll("\\b\\w+(?=\\sis\\b)", "The dog is a Malamute.") &gt; 0);Assert.assertFalse(findAll("\\b\\w+(?=\\sis\\b)", "The island has beautiful birds.") &gt; 0);Assert.assertFalse(findAll("\\b\\w+(?=\\sis\\b)", "The pitch missed home plate.") &gt; 0);Assert.assertTrue(findAll("\\b\\w+(?=\\sis\\b)", "Sunday is a weekend day.") &gt; 0); 输出12345678regex = \b\w+(?=\sis\b), content: The dog is a Malamute.[1th] start: 4, end: 7, group: dogregex = \b\w+(?=\sis\b), content: The island has beautiful birds.not foundregex = \b\w+(?=\sis\b), content: The pitch missed home plate.not foundregex = \b\w+(?=\sis\b), content: Sunday is a weekend day.[1th] start: 0, end: 6, group: Sunday 说明 \b: 在单词边界处开始匹配。 \w+: 匹配一个或多个单词字符。 (?=\sis\b): 确定单词字符是否后接空白字符和字符串is，其在单词边界处结束。 如果如此，则匹配成功。 匹配exp后面的位置(?&lt;=exp) 表示子表达式不得在输入字符串当前位置左侧出现，尽管子表达式未包含在匹配结果中。零宽度正回顾后发断言不会回溯。12// (?&lt;=\b20)\d&#123;2&#125;\b 表示要捕获以20开头的数字的后面部分Assert.assertTrue(findAll("(?&lt;=\\b20)\\d&#123;2&#125;\\b", "2010 1999 1861 2140 2009") &gt; 0); 输出123regex = (?&lt;=\b20)\d&#123;2&#125;\b, content: 2010 1999 1861 2140 2009[1th] start: 2, end: 4, group: 10[2th] start: 22, end: 24, group: 09 说明 \d{2}: 匹配两个十进制数字。 {?&lt;=\b20): 如果两个十进制数字的字边界以小数位数“20”开头，则继续匹配。 \b: 在单词边界处结束匹配。 匹配后面跟的不是exp的位置(?!exp) 表示输入字符串不得匹配子表达式中的正则表达式模式，尽管匹配的子字符串未包含在匹配结果中。例 捕获未以“un”开头的单词12// \b(?!un)\w+\b 表示要捕获未以“un”开头的单词Assert.assertTrue(findAll("\\b(?!un)\\w+\\b", "unite one unethical ethics use untie ultimate") &gt; 0); 输出12345regex = \b(?!un)\w+\b, content: unite one unethical ethics use untie ultimate[1th] start: 6, end: 9, group: one[2th] start: 20, end: 26, group: ethics[3th] start: 27, end: 30, group: use[4th] start: 37, end: 45, group: ultimate 说明 \b: 在单词边界处开始匹配。 (?!un): 确定接下来的两个的字符是否为“un”。 如果没有，则可能匹配。 \w+: 匹配一个或多个单词字符。 \b: 在单词边界处结束匹配。 匹配前面不是exp的位置(?&lt;!exp) 表示子表达式不得在输入字符串当前位置的左侧出现。 但是，任何不匹配子表达式 的子字符串不包含在匹配结果中。例 捕获任意工作日123456// (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b 表示要捕获任意工作日（即周一到周五）Assert.assertTrue(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Monday February 1, 2010") &gt; 0);Assert.assertTrue(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Wednesday February 3, 2010") &gt; 0);Assert.assertFalse(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Saturday February 6, 2010") &gt; 0);Assert.assertFalse(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Sunday February 7, 2010") &gt; 0);Assert.assertTrue(findAll("(?&lt;!(Saturday|Sunday) )\\b\\w+ \\d&#123;1,2&#125;, \\d&#123;4&#125;\\b", "Monday, February 8, 2010") &gt; 0); 输出12345678910regex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Monday February 1, 2010[1th] start: 7, end: 23, group: February 1, 2010regex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Wednesday February 3, 2010[1th] start: 10, end: 26, group: February 3, 2010regex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Saturday February 6, 2010not foundregex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Sunday February 7, 2010not foundregex = (?&lt;!(Saturday|Sunday) )\b\w+ \d&#123;1,2&#125;, \d&#123;4&#125;\b, content: Monday, February 8, 2010[1th] start: 8, end: 24, group: February 8, 2010 贪婪与懒惰当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符。以这个表达式为例：a.*b，它将会匹配最长的以a开始，以b结束的字符串。如果用它来搜索aabab的话，它会匹配整个字符串aabab。这被称为贪婪匹配。有时，我们更需要懒惰匹配，也就是匹配尽可能少的字符。前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。这样.*?就意味着匹配任意数量的重复，但是在能使整个匹配成功的前提下使用最少的重复。 表达式 描述 *? 重复任意次，但尽可能少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复 例 Java正则中贪婪与懒惰的示例123456789// 贪婪匹配Assert.assertTrue(findAll("a\\w*b", "abaabaaabaaaab") &gt; 0);// 懒惰匹配Assert.assertTrue(findAll("a\\w*?b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w+?b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w??b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w&#123;0,4&#125;?b", "abaabaaabaaaab") &gt; 0);Assert.assertTrue(findAll("a\\w&#123;3,&#125;?b", "abaabaaabaaaab") &gt; 0); 输出123456789101112131415161718192021222324regex = a\w*b, content: abaabaaabaaaab[1th] start: 0, end: 14, group: abaabaaabaaaabregex = a\w*?b, content: abaabaaabaaaab[1th] start: 0, end: 2, group: ab[2th] start: 2, end: 5, group: aab[3th] start: 5, end: 9, group: aaab[4th] start: 9, end: 14, group: aaaabregex = a\w+?b, content: abaabaaabaaaab[1th] start: 0, end: 5, group: abaab[2th] start: 5, end: 9, group: aaab[3th] start: 9, end: 14, group: aaaabregex = a\w??b, content: abaabaaabaaaab[1th] start: 0, end: 2, group: ab[2th] start: 2, end: 5, group: aab[3th] start: 6, end: 9, group: aab[4th] start: 11, end: 14, group: aabregex = a\w&#123;0,4&#125;?b, content: abaabaaabaaaab[1th] start: 0, end: 2, group: ab[2th] start: 2, end: 5, group: aab[3th] start: 5, end: 9, group: aaab[4th] start: 9, end: 14, group: aaaabregex = a\w&#123;3,&#125;?b, content: abaabaaabaaaab[1th] start: 0, end: 5, group: abaab[2th] start: 5, end: 14, group: aaabaaaab 说明本例中代码展示的是使用不同贪婪或懒惰策略去查找字符串abaabaaabaaaab 中匹配以a开头，以b结尾的所有子字符串。请从输出结果中，细细体味使用不同的贪婪或懒惰策略，对于匹配子字符串有什么影响。 附录匹配正则字符串的方法由于正则表达式中很多元字符本身就是转义字符，在Java字符串的规则中不会被显示出来。为此，可以使用一个工具类org.apache.commons.lang3.StringEscapeUtils来做特殊处理，使得转义字符可以打印。这个工具类提供的都是静态方法，从方法命名大致也可以猜出用法，这里不多做说明。如果你了解maven，可以直接引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;$&#123;commons-lang3.version&#125;&lt;/version&gt;&lt;/dependency&gt; 本文为了展示正则匹配规则用到的方法12345678910111213141516171819202122232425262728private boolean checkMatches(String regex, String content) &#123; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); boolean flag = m.matches(); if (m.matches()) &#123; System.out.println(StringEscapeUtils.escapeJava(content) + "\tmatches： " + StringEscapeUtils.escapeJava(regex)); &#125; else &#123; System.out.println(StringEscapeUtils.escapeJava(content) + "\tnot matches： " + StringEscapeUtils.escapeJava(regex)); &#125; return flag;&#125;public int findAll(String regex, String content) &#123; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); System.out.println("regex = " + regex + ", content: " + content); int count = 0; while (m.find()) &#123; count++; System.out.println("[" + count + "th] " + "start: " + m.start() + ", end: " + m.end() + ", group: " + m.group()); &#125; if (0 == count) &#123; System.out.println("not found"); &#125; return count;&#125; 速查元字符字典为了方便快查正则的元字符含义，在本节根据元字符的功能集中罗列正则的各种元字符。 限定符 字符 描述 * 匹配前面的子表达式零次或多次。例如，zo 能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。 {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 定位符 字符 描述 ^ 匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与 \n 或 \r 之后的位置匹配。 $ 匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与 \n 或 \r 之前的位置匹配。 \b 匹配一个字边界，即字与空格间的位置。 \B 非字边界匹配。 非打印字符 字符 描述 \cx 匹配由x指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \f 匹配一个换页符。等价于 \x0c 和 \cL。 \n 匹配一个换行符。等价于 \x0a 和 \cJ。 \r 匹配一个回车符。等价于 \x0d 和 \cM。 \s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 \S 匹配任何非空白字符。等价于 [ \f\n\r\t\v]。 \t 匹配一个制表符。等价于 \x09 和 \cI。 \v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 分组 表达式 描述 (exp) 匹配的子表达式。()中的内容就是子表达式。 (?&lt;name&gt;exp) 命名的子表达式（反向引用）。 (?:exp) 非捕获组，表示当一个限定符应用到一个组，但组捕获的子字符串并非所需时，通常会使用非捕获组构造。 (?=exp) 匹配exp前面的位置。 (?&lt;=exp) 匹配exp后面的位置。 (?!exp) 匹配后面跟的不是exp的位置。 (?&lt;!exp) 匹配前面不是exp的位置。 特殊符号 字符 描述 \ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’\n’ 匹配换行符。序列 ‘\’ 匹配 “”，而 ‘(‘ 则匹配 “(“。 \&#124; 指明两项之间的一个选择。 [] 匹配方括号范围内的任意一个字符。形式如：[xyz]、[^xyz]、[a-z]、[^a-z]、[x,y,z] 参考正则表达式30分钟入门教程msdn 正则表达式教程.aspx)作者：静默虚空出处：http://www.cnblogs.com/jingmoxukong/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java正则速成秘籍（一）之招式篇]]></title>
      <url>%2F20170421%2Fregular_java_1%2F</url>
      <content type="text"><![CDATA[导读正则表达式是什么？有什么用？正则表达式(Regular Expression)是一种文本规则，可以用来校验、查找、替换与规则匹配的文本。又爱又恨的正则正则表达式是一个强大的文本匹配工具，但是它的规则实在很繁琐，而且理解起来也颇为蛋疼，容易让人望而生畏。如何学习正则刚接触正则时，我看了一堆正则的语义说明，但是仍然不明所以。后来，我多接触一些正则的应用实例，渐渐有了感觉，再结合语义说明，终有领悟。我觉得正则表达式和武侠修练武功差不多，应该先练招式，再练心法。如果一开始就直接看正则的规则，保证你会懵逼。当你熟悉基本招式（正则基本使用案例）后，也该修炼修炼心法（正则语法）了。真正的高手不能只靠死记硬背那么几招把式。就像张三丰教张无忌太极拳一样，领悟心法，融会贯通，少侠你就可以无招胜有招，成为传说中的绝世高手。 以上闲话可归纳为一句：学习正则应该从实例去理解规则。 打开秘籍：欲练神功，必先自宫！没有蛋，也就不会蛋疼了。Java正则速成秘籍分三篇： Java正则速成秘籍（一）之招式篇展示Java对于正则表达式的支持。 Java正则速成秘籍（二）之心法篇介绍正则表达式的语法规则。 Java正则速成秘籍（三）之见招拆招篇从实战出发，介绍正则的常用案例。本文是Java正则速成秘籍的招式篇。主要介绍JDK对于正则表达式的支持。 概述JDK中的java.util.regex包提供了对正则表达式的支持。java.util.regex有三个核心类： Pattern类：Pattern是一个正则表达式的编译表示。 Matcher类：Matcher是对输入字符串进行解释和匹配操作的引擎。 PatternSyntaxException：PatternSyntaxException是一个非强制异常类，它表示一个正则表达式模式中的语法错误。注：需要格外注意一点，在Java中使用反斜杠\时必须写成 \\。所以本文的代码出现形如String regex = &quot;\\$\\{.*?\\}&quot; 其实就是&quot;\$\{.*?\}&quot;，不要以为是画风不对哦。 Pattern类Pattern类没有公共构造方法。要创建一个Pattern对象，你必须首先调用其静态方法compile，加载正则规则字符串，然后返回一个Pattern对象。与Pattern类一样，Matcher类也没有公共构造方法。你需要调用Pattern对象的matcher方法来获得一个Matcher对象。案例：Pattern和Matcher的初始化12Pattern p = Pattern.compile(regex);Matcher m = p.matcher(content); Matcher类Matcher类可以说是java.util.regex核心类中的必杀技！Matcher类有三板斧（三类功能）： 校验 查找 替换下面我们来领略一下这三块的功能。 校验文本是否与正则规则匹配为了检查文本是否与正则规则匹配，Matcher提供了以下几个返回值为boolean的方法。 序号 方法 说明 1 public boolean lookingAt() 尝试将从区域开头开始的输入序列与该模式匹配。 2 public boolean find() 尝试查找与该模式匹配的输入序列的下一个子序列。 3 public boolean find(int start) 重置此匹配器，然后尝试查找匹配该模式、从指定索引开始的输入序列的下一个子序列。 4 public boolean matches() 尝试将整个区域与模式匹配。 如果你傻傻分不清上面的查找方法有什么区别，那么下面一个例子就可以让你秒懂。案例：lookingAt vs find vs matches1234567891011121314151617181920212223242526272829303132333435363738394041public static void main(String[] args) &#123; checkLookingAt("hello", "helloworld"); checkLookingAt("world", "helloworld"); checkFind("hello", "helloworld"); checkFind("world", "helloworld"); checkMatches("hello", "helloworld"); checkMatches("world", "helloworld"); checkMatches("helloworld", "helloworld");&#125;private static void checkLookingAt(String regex, String content) &#123; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); if (m.lookingAt()) &#123; System.out.println(content + "\tlookingAt： " + regex); &#125; else &#123; System.out.println(content + "\tnot lookingAt： " + regex); &#125;&#125;private static void checkFind(String regex, String content) &#123; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); if (m.find()) &#123; System.out.println(content + "\tfind： " + regex); &#125; else &#123; System.out.println(content + "\tnot find： " + regex); &#125;&#125;private static void checkMatches(String regex, String content) &#123; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); if (m.matches()) &#123; System.out.println(content + "\tmatches： " + regex); &#125; else &#123; System.out.println(content + "\tnot matches： " + regex); &#125;&#125; 输出1234567helloworld lookingAt： hellohelloworld not lookingAt： worldhelloworld find： hellohelloworld find： worldhelloworld not matches： hellohelloworld not matches： worldhelloworld matches： helloworld 说明regex = &quot;world&quot; 表示的正则规则是以world开头的字符串，regex = &quot;hello&quot; 和regex = &quot;hello world 也是同理。 lookingAt方法从头部开始，检查content字符串是否有子字符串于正则规则匹配。 find方法检查content字符串是否有子字符串于正则规则匹配，不管字符串所在位置。 matches方法检查content字符串整体是否与正则规则匹配。 查找匹配正则规则的文本位置为了查找文本匹配正则规则的位置，Matcher提供了以下方法： 序号 方法 说明 1 public int start() 返回以前匹配的初始索引。 2 public int start(int group) 返回在以前的匹配操作期间，由给定组所捕获的子序列的初始索引 3 public int end() 返回最后匹配字符之后的偏移量。 4 public int end(int group) 返回在以前的匹配操作期间，由给定组所捕获子序列的最后字符之后的偏移量。 5 public String group() 返回前一个符合匹配条件的子序列。 6 public String group(int group) 返回指定的符合匹配条件的子序列。 案例：使用start()、end()、group() 查找所有匹配正则条件的子序列12345678910111213141516public static void main(String[] args) &#123; final String regex = "world"; final String content = "helloworld helloworld"; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); System.out.println("content: " + content); int i = 0; while (m.find()) &#123; i++; System.out.println("[" + i + "th] found"); System.out.print("start: " + m.start() + ", "); System.out.print("end: " + m.end() + ", "); System.out.print("group: " + m.group() + "\n"); &#125;&#125; 输出12345content: helloworld helloworld[1th] foundstart: 5, end: 10, group: world[2th] foundstart: 16, end: 21, group: world 说明例子很直白，不言自明了吧。 替换匹配正则规则的文本替换方法是替换输入字符串里文本的方法： 序号 方法 说明 1 public Matcher appendReplacement(StringBuffer sb, String replacement) 实现非终端添加和替换步骤。 2 public StringBuffer appendTail(StringBuffer sb) 实现终端添加和替换步骤。 3 public String replaceAll(String replacement) 替换模式与给定替换字符串相匹配的输入序列的每个子序列。 4 public String replaceFirst(String replacement) 替换模式与给定替换字符串匹配的输入序列的第一个子序列。 5 public static String quoteReplacement(String s) 返回指定字符串的字面替换字符串。这个方法返回一个字符串，就像传递给Matcher类的appendReplacement 方法一个字面字符串一样工作。 案例：replaceFirst vs replaceAll123456789101112public static void main(String[] args) &#123; String regex = "can"; String replace = "can not"; String content = "I can because I think I can."; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); System.out.println("content: " + content); System.out.println("replaceFirst: " + m.replaceFirst(replace)); System.out.println("replaceAll: " + m.replaceAll(replace));&#125; 输出123content: I can because I think I can.replaceFirst: I can not because I think I can.replaceAll: I can not because I think I can not. 说明replaceFirst：替换第一个匹配正则规则的子序列。replaceAll：替换所有匹配正则规则的子序列。 案例：appendReplacement、appendTail和replaceAll1234567891011121314151617public static void main(String[] args) &#123; String regex = "can"; String replace = "can not"; String content = "I can because I think I can."; StringBuffer sb = new StringBuffer(); StringBuffer sb2 = new StringBuffer(); System.out.println("content: " + content); Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); while (m.find()) &#123; m.appendReplacement(sb, replace); &#125; System.out.println("appendReplacement: " + sb); m.appendTail(sb); System.out.println("appendTail: " + sb);&#125; 输出123content: I can because I think I can.appendReplacement: I can not because I think I can notappendTail: I can not because I think I can not. 说明从输出结果可以看出，appendReplacement和appendTail方法组合起来用，功能和replaceAll是一样的。如果你查看replaceAll的源码，会发现其内部就是使用appendReplacement和appendTail方法组合来实现的。 案例：quoteReplacement和replaceAll，解决特殊字符替换问题123456789101112public static void main(String[] args) &#123; String regex = "\\$\\&#123;.*?\\&#125;"; String replace = "$&#123;product&#125;"; String content = "product is $&#123;productName&#125;."; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); String replaceAll = m.replaceAll(replace); System.out.println("content: " + content); System.out.println("replaceAll: " + replaceAll);&#125; 输出12345678910Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: No group with name &#123;product&#125; at java.util.regex.Matcher.appendReplacement(Matcher.java:849) at java.util.regex.Matcher.replaceAll(Matcher.java:955) at org.zp.notes.javase.regex.RegexDemo.wrongMethod(RegexDemo.java:42) at org.zp.notes.javase.regex.RegexDemo.main(RegexDemo.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147) 说明String regex = &quot;\\$\\{.*?\\}&quot;;表示匹配类似${name}这样的字符串。由于$、{ 、}都是特殊字符，需要用反义字符\来修饰才能被当做一个字符串字符来处理。上面的例子是想将${productName} 替换为${product} ，然而replaceAll方法却将传入的字符串中的$当做特殊字符来处理了。结果产生异常。如何解决这个问题?JDK1.5引入了quoteReplacement方法。它可以用来转换特殊字符。其实源码非常简单，就是判断字符串中如果有\或$，就为它加一个转义字符\我们对上面的代码略作调整：m.replaceAll(replace)改为m.replaceAll(Matcher.quoteReplacement(replace))，新代码如下：123456789101112public static void main(String[] args) &#123; String regex = "\\$\\&#123;.*?\\&#125;"; String replace = "$&#123;product&#125;"; String content = "product is $&#123;productName&#125;."; Pattern p = Pattern.compile(regex); Matcher m = p.matcher(content); String replaceAll = m.replaceAll(Matcher.quoteReplacement(replace)); System.out.println("content: " + content); System.out.println("replaceAll: " + replaceAll);&#125; 输出12content: product is $&#123;productName&#125;.replaceAll: product is $&#123;product&#125;. 说明字符串中如果有\或$，不能被正常解析的问题解决。 出处：http://www.cnblogs.com/jingmoxukong/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux 查找目录或文件]]></title>
      <url>%2F20170421%2Flinux_find_file%2F</url>
      <content type="text"><![CDATA[查找目录：find /（查找范围） -name &#39;查找关键字&#39; -type d查找文件：find /（查找范围） -name 查找关键字 -print如果需要更进一步的了解，可以参看Linux的命令详解。 这里摘抄如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146·find path -option [ -print ] [ -exec -ok command ] &#123;&#125; /;#-print 将查找到的文件输出到标准输出#-exec command &#123;&#125; /; -----将查到的文件执行command操作,&#123;&#125; 和 /;之间有空格#-ok 和-exec相同，只不过在操作前要询用户====================================================-name filename #查找名为filename的文件-perm #按执行权限来查找-user username #按文件属主来查找-group groupname #按组来查找-mtime -n +n #按文件更改时间来查找文件，-n指n天以内，+n指n天以前-atime -n +n #按文件访问时间来查-perm #按执行权限来查找-user username #按文件属主来查找-group groupname #按组来查找-mtime -n +n #按文件更改时间来查找文件，-n指n天以内，+n指n天以前-atime -n +n #按文件访问时间来查找文件，-n指n天以内，+n指n天以前 -ctime -n +n #按文件创建时间来查找文件，-n指n天以内，+n指n天以前 -nogroup #查无有效属组的文件，即文件的属组在/etc/groups中不存在-nouser #查无有效属主的文件，即文件的属主在/etc/passwd中不存-newer f1 !f2 找文件，-n指n天以内，+n指n天以前 -ctime -n +n #按文件创建时间来查找文件，-n指n天以内，+n指n天以前 -nogroup #查无有效属组的文件，即文件的属组在/etc/groups中不存在-nouser #查无有效属主的文件，即文件的属主在/etc/passwd中不存-newer f1 !f2 #查更改时间比f1新但比f2旧的文件-type b/d/c/p/l/f #查是块设备、目录、字符设备、管道、符号链接、普通文件-size n[c] #查长度为n块[或n字节]的文件-depth #使查找在进入子目录前先行查找完本目录-fstype #查更改时间比f1新但比f2旧的文件-type b/d/c/p/l/f #查是块设备、目录、字符设备、管道、符号链接、普通文件-size n[c] #查长度为n块[或n字节]的文件-depth #使查找在进入子目录前先行查找完本目录-fstype #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到-mount #查文件时不跨越文件系统mount点-follow #如果遇到符号链接文件，就跟踪链接所指的文件-cpio #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到-mount #查文件时不跨越文件系统mount点-follow #如果遇到符号链接文件，就跟踪链接所指的文件-cpio #对匹配的文件使用cpio命令，将他们备份到磁带设备中-prune #忽略某个目录====================================================$find ~ -name "*.txt" -print #在$HOME中查.txt文件并显示$find . -name "*.txt" -print$find . -name "[A-Z]*" -pri26nbsp; #对匹配的文件使用cpio命令，将他们备份到磁带设备中-prune #忽略某个目录=====================================================$find ~ -name "*.txt" -print #在$HOME中查.txt文件并显示$find . -name "*.txt" -print$find . -name "[A-Z]*" -print #查以大写字母开头的文件$find /etc -name "host*" -print #查以host开头的文件$find . -name "[a-z][a-z][0--9][0--9].txt" -print #查以两个小写字母和两个数字开头的txt文件$find . -perm 755 -print$find . -perm -007 -exec ls -l &#123;&#125; /; #查所有用户都可读写执行的文件同-perm 777$find . -type d -print$find . ! -type d -print $find . -type l -print$find . -size +1000000c -print #查长度大于1Mb的文件$find . -size 100c -print # 查长度为100c的文件$find . -size +10 -print #查长度超过期作废10块的文件（1块=512字节）$cd /$find etc home apps -depth -print | cpio -ivcdC65536 -o /dev/rmt0$find /etc -name "passwd*" -exec grep "cnscn" &#123;&#125; /; #看是否存在cnscn用户$find . -name "yao*" | xargs file$find . -name "yao*" | xargs echo "" &gt; /tmp/core.log$find . -name "yao*" | xargs chmod o-w======================================================$find -name april* #在当前目录下查找以april开始的文件$find -name april* fprint file #在当前目录下查找以april开始的文件，并把结果输出到file中$find -name ap* -o -name may* #查找以ap或may开头的文件$find /mnt -name tom.txt -ftype vfat #在/mnt下查找名称为tom.txt且文件系统类型为vfat的文件$find /mnt -name t.txt ! -ftype vfat #在/mnt下查找名称为tom.txt且文件系统类型不为vfat的文件$find /tmp -name wa* -type l #在/$tmp下查找名为wa开头且类型为符号链接的文件$find /home -mtime -2 #在/home下查最近两天内改动过的文件$find /home -atime -1 #查1天之内被存取过的文件$find /home -mmin +60 #在/home下查60分钟前改动过的文件$find /home -amin +30 #查最近30分钟前被存取过的文件$find /home -newer tmp.txt #在/home下查更新时间比tmp.txt近的文件或目录$find /home -anewer tmp.txt #在/home下查存取时间比tmp.txt近的文件或目录$find /home -used -2 #列出文件或目录被改动过之后，在2日内被存取过的文件或目录$find /home -user cnscn #列出/home目录内属于用户cnscn的文件或目录$find /home -uid +501 #列出/home目录内用户的识别码大于501的文件或目录$find /home -group cnscn #列出/home内组为cnscn的文件或目录$find /home -gid 501 #列出/home内组id为501的文件或目录$find /home -nouser #列出/home内不属于本地用户的文件或目录$find /home -nogroup #列出/home内不属于本地组的文件或目录$find /home -name tmp.txt -maxdepth 4 #列出/home内的tmp.txt 查时深度最多为3层$find /home -name tmp.txt -mindepth 3 #从第2层开始查$find /home -empty #查找大小为0的文件或空目录$find /home -size +512k #查大于512k的文件$find /home -size -512k #查小于512k的文件$find /home -links +2 #查硬连接数大于2的文件或目录$find /home -perm 0700 #查权限为700的文件或目录$find /tmp -name tmp.txt -exec cat &#123;&#125; /;$find /tmp -name tmp.txt -ok rm &#123;&#125; /;$find / -amin -10 # 查找在系统中最后10分钟访问的文件$find / -atime -2 # 查找在系统中最后48小时访问的文件$find / -empty # 查找在系统中为空的文件或者文件夹$find / -group cat # 查找在系统中属于 groupcat的文件$find / -mmin -5 # 查找在系统中最后5分钟里修改过的文件$find / -mtime -1 #查找在系统中最后24小时里修改过的文件$find / -nouser #查找在系统中属于作废用户的文件$find / -user fred #查找在系统中属于FRED这个用户的文件#查当前目录下的所有普通文件$find . -type f -exec ls -l &#123;&#125; /; -rw-r--r-- 1 root root 34928 2003-02-25 ./conf/httpd.conf -rw-r--r-- 1 root root 12959 2003-02-25 ./conf/magic -rw-r--r-- 1 root root 180 2003-02-25 ./conf.d/README#查当前目录下的所有普通文件，并在-exec选项中使用ls -l命令将它们列出#在/logs目录中查找更改时间在5日以前的文件并删除它们：$find logs -type f -mtime +5 -exec -ok rm &#123;&#125; /;#查询当天修改过的文件$find ./ -mtime -1 -type f -exec ls -l &#123;&#125; /;#查询文件并询问是否要显示$find ./ -mtime -1 -type f -ok ls -l &#123;&#125; /; &lt; ls ... ./classDB.inc.PHP &gt; ? y-rw-r--r-- 1 cnscn cnscn 13709 1月 12 12:22 ./classDB.inc.php$find ./ -mtime -1 -type f -ok ls -l &#123;&#125; /; &lt; ls ... ./classDB.inc.php &gt; ? n#查询并交给awk去处理$who | awk '&#123;print $1"/t"$2&#125;'cnscn pts/0$awk---grep---sed$df -k | awk '&#123;print $1&#125;' | grep -v 'none' | sed s"///dev////g"文件系统sda2sda1$df -k | awk '&#123;print $1&#125;' | grep -v 'none'文件系统/dev/sda2/dev/sda1#在/tmp中查找所有的*.h，并在这些文件中查找“SYSCALL_VECTOR"，最后打印出所有包含"SYSCALL_VECTOR"的文件名A) find /tmp -name "*.h" | xargs -n50 grep SYSCALL_VECTORB) grep SYSCALL_VECTOR /tmp/*.h | cut -d':' -f1| uniq &gt; filenameC) find /tmp -name "*.h" -exec grep "SYSCALL_VECTOR" &#123;&#125; /; -print#查询并删除find / -name filename -exec rm -rf &#123;&#125; /;find / -name filename -ok rm -rf &#123;&#125; /;#比如要查找磁盘中大于3M的文件：find . -size +3000k -exec ls -ld &#123;&#125; ;#将find出来的东西拷到另一个地方find *.c -exec cp '&#123;&#125;' /tmp ';'#如果有特殊文件，可以用cpio，也可以用这样的语法：find dir -name filename -print | cpio -pdv newdir#查找2004-11-30 16:36:37时更改过的文件$ A=`find ./ -name "*php"` | ls -l --full-time $A 2&gt;/dev/null | grep "2004-11-30 16:36:37"]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS7下firewalld使用指南]]></title>
      <url>%2F20170421%2Fcentos7_firewalld_guid%2F</url>
      <content type="text"><![CDATA[1、firewalld的基本使用启动systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。 启动一个服务：systemctl start firewalld.service 关闭一个服务：systemctl stop firewalld.service 重启一个服务：systemctl restart firewalld.service 显示一个服务的状态：systemctl status firewalld.service 在开机时启用一个服务：systemctl enable firewalld.service 在开机时禁用一个服务：systemctl disable firewalld.service 查看服务是否开机启动：systemctl is-enabled firewalld.service 查看已启动的服务列表：systemctl list-unit-files|grep enabled 查看启动失败的服务列表：systemctl --failed 3.配置firewalld-cmd查看版本： firewall-cmd --version 查看帮助： firewall-cmd --help 显示状态： firewall-cmd --state 查看所有打开的端口： firewall-cmd --zone=public --list-ports 更新防火墙规则： firewall-cmd --reload 查看区域信息: firewall-cmd --get-active-zones 查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态： firewall-cmd --panic-off 查看是否拒绝： firewall-cmd --query-panic 那怎么开启一个端口呢添加:firewall-cmd --zone=public --add-port=80/tcp --permanent（–permanent永久生效，没有此参数重启后失效） 重新载入: firewall-cmd --reload 查看:firewall-cmd --zone= public --query-port=80/tcp 删除:firewall-cmd --zone= public --remove-port=80/tcp --permanent 批量操作：firewall-cmd --permanent --add-port={8500/tcp,8300/tcp,8301/tcp,3375/tcp,2375/tcp}]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dockerfile命令介绍及实例]]></title>
      <url>%2F20170420%2Finto_dockerfile_example%2F</url>
      <content type="text"><![CDATA[Dockerfile命令介绍及实例基础镜像可以用于创建Docker容器。镜像可以非常基础，仅仅包含操作系统；也可以非常丰富，包含灵巧的应用栈，随时可以发布。当你在使用Docker构建镜像的时候，每一个命令都会在前一个命令的基础上形成一个新层。这些基础镜像可以用于创建新的容器。本篇文章将手把手教您如何从基础镜像，一步一步，一层一层的从Dockerfile构建容器的过程。 Docker简介Docker项目提供了构建在Linux内核功能之上，协同在一起的的高级工具。其目标是帮助开发和运维人员更容易地跨系统跨主机交付应用程序和他们的依赖。Docker通过Docker容器，一个安全的，基于轻量级容器的环境，来实现这个目标。这些容器由镜像创建，而镜像可以通过命令行手工创建或 者通过Dockerfile自动创建。 DockerfileDockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。它们简化了从头到尾的流程并极大的简化了部署工作。Dockerfile从FROM命令开始，紧接着跟随者各种方法，命令和参数。其产出为一个新的可以用于创建容器的镜像。 Dockerfile 语法在我们深入讨论Dockerfile之前，让我们快速过一下Dockerfile的语法和它们的意义。 什么是语法？非常简单，在编程中，语法意味着一个调用命令，输入参数去让应用执行程序的文法结构。这些语法被规则或明或暗的约束。程序员遵循语法规范以和计算机 交互。如果一段程序语法不正确，计算机将无法识别。Dockerfile使用简单的，清楚的和干净的语法结构，极为易于使用。这些语法可以自我释义，支持注释。 Dockerfile 语法示例Dockerfile语法由两部分构成，注释和命令+参数 Dockerfile 命令Dockerfile有十几条命令可用于构建镜像，下文将简略介绍这些命令。 ADDADD命令有两个参数，源和目标。它的基本作用是从源系统的文件系统上复制文件到目标容器的文件系统。如果源是一个URL，那该URL的内容将被下载并复制到容器中。12# Usage: ADD [source directory or URL] [destination directory]ADD /my_app_folder /my_app_folder CMD和RUN命令相似，CMD可以用于执行特定的命令。和RUN不同的是，这些命令不是在镜像构建的过程中执行的，而是在用镜像构建容器后被调用。12# Usage 1: CMD application "argument", "argument", ..CMD "echo" "Hello docker!" ENTRYPOINTENTRYPOINT 帮助你配置一个容器使之可执行化，如果你结合CMD命令和ENTRYPOINT命令，你可以从CMD命令中移除“application”而仅仅保留参数，参数将传递给ENTRYPOINT命令。12345678# Usage: ENTRYPOINT application "argument", "argument", ..# Remember: arguments are optional. They can be provided by CMD# or during the creation of a container.ENTRYPOINT echo# Usage example with CMD:# Arguments set with CMD can be overridden during *run*CMD "Hello docker!"ENTRYPOINT echo ENVENV命令用于设置环境变量。这些变量以”key=value”的形式存在，并可以在容器内被脚本或者程序调用。这个机制给在容器中运行应用带来了极大的便利。12# Usage: ENV key valueENV SERVER_WORKS 4 EXPOSEEXPOSE用来指定端口，使容器内的应用可以通过端口和外界交互。12# Usage: EXPOSE [port]EXPOSE 8080 FROMFROM命令可能是最重要的Dockerfile命令。改命令定义了使用哪个基础镜像启动构建流程。基础镜像可以为任意镜 像。如果基础镜像没有被发现，Docker将试图从Docker image index来查找该镜像。FROM命令必须是Dockerfile的首个命令。12# Usage: FROM [image name]FROM ubuntu MAINTAINER我建议这个命令放在Dockerfile的起始部分，虽然理论上它可以放置于Dockerfile的任意位置。这个命令用于声明作者，并应该放在FROM的后面。12# Usage: MAINTAINER [name]MAINTAINER authors_name RUNRUN命令是Dockerfile执行命令的核心部分。它接受命令作为参数并用于创建镜像。不像CMD命令，RUN命令用于创建镜像（在之前commit的层之上形成新的层）。12# Usage: RUN [command]RUN aptitude install -y riak USERUSER命令用于设置运行容器的UID。12# Usage: USER [UID]USER 751 VOLUMEVOLUME命令用于让你的容器访问宿主机上的目录。12# Usage: VOLUME ["/dir_1", "/dir_2" ..]VOLUME ["/my_files"] WORKDIRWORKDIR命令用于设置CMD指明的命令的运行目录。12# Usage: WORKDIR /pathWORKDIR ~/ 如何使用Dockerfiles使用Dockerfiles和手工使用Docker Daemon运行命令一样简单。脚本运行后输出为新的镜像ID。123# Build an image using the Dockerfile at current location# Example: sudo docker build -t [name] .$sudo docker build -t my_mongodb . Dockerfile 示例一：创建一个最小的带glibc的linux镜像在这部分中，我们讲一步一步创建一个Dockfile，这个Dockerfile可用于构建一个最小的linux容器。 创建一个Dockerfile使用nano文本编辑器，让我们创建Dockerfile。1$sudo vi Dockerfile 定义文件和它的目的让阅读者明确Dockerfile的目的永远是必要的。为此，我们通常从注释开始写Dockerfile。12345678910111213141516171819202122232425262728293031323334353637383940414243############################################################# Dockerfile to build a min linux based on alpine and glibc# Based on alpine#############################################################设置基础镜像 # Set the base image to alpineFROM alpine:3.5#定义作者# File AuthorMAINTAINER zhaoshg# Here we install GNU libc (aka glibc) and set C.UTF-8 locale as default.RUN ALPINE_GLIBC_BASE_URL="https://github.com/sgerrand/alpine-pkg-glibc/releases/download" &amp;&amp; \ ALPINE_GLIBC_PACKAGE_VERSION="2.25-r0" &amp;&amp; \ ALPINE_GLIBC_BASE_PACKAGE_FILENAME="glibc-$ALPINE_GLIBC_PACKAGE_VERSION.apk" &amp;&amp; \ ALPINE_GLIBC_BIN_PACKAGE_FILENAME="glibc-bin-$ALPINE_GLIBC_PACKAGE_VERSION.apk" &amp;&amp; \ ALPINE_GLIBC_I18N_PACKAGE_FILENAME="glibc-i18n-$ALPINE_GLIBC_PACKAGE_VERSION.apk" &amp;&amp; \ apk add --no-cache --virtual=.build-dependencies wget ca-certificates &amp;&amp; \ wget \ "https://raw.githubusercontent.com/andyshinn/alpine-pkg-glibc/master/sgerrand.rsa.pub" \ -O "/etc/apk/keys/sgerrand.rsa.pub" &amp;&amp; \ wget \ "$ALPINE_GLIBC_BASE_URL/$ALPINE_GLIBC_PACKAGE_VERSION/$ALPINE_GLIBC_BASE_PACKAGE_FILENAME" \ "$ALPINE_GLIBC_BASE_URL/$ALPINE_GLIBC_PACKAGE_VERSION/$ALPINE_GLIBC_BIN_PACKAGE_FILENAME" \ "$ALPINE_GLIBC_BASE_URL/$ALPINE_GLIBC_PACKAGE_VERSION/$ALPINE_GLIBC_I18N_PACKAGE_FILENAME" &amp;&amp; \ apk add --no-cache \ "$ALPINE_GLIBC_BASE_PACKAGE_FILENAME" \ "$ALPINE_GLIBC_BIN_PACKAGE_FILENAME" \ "$ALPINE_GLIBC_I18N_PACKAGE_FILENAME" &amp;&amp; \ \ rm "/etc/apk/keys/sgerrand.rsa.pub" &amp;&amp; \ /usr/glibc-compat/bin/localedef --force --inputfile POSIX --charmap UTF-8 C.UTF-8 || true &amp;&amp; \ echo "export LANG=C.UTF-8" &gt; /etc/profile.d/locale.sh &amp;&amp; \ \ apk del glibc-i18n &amp;&amp; \ \ rm "/root/.wget-hsts" &amp;&amp; \ apk del .build-dependencies &amp;&amp; \ rm \ "$ALPINE_GLIBC_BASE_PACKAGE_FILENAME" \ "$ALPINE_GLIBC_BIN_PACKAGE_FILENAME" \ "$ALPINE_GLIBC_I18N_PACKAGE_FILENAME"ENV LANG=C.UTF-8 保存Dockerfile。 构建镜像使用上述的Dockerfile，我们已经可以开始构建镜像1$sudo docker build -t my_alpine . Dockerfile 示例二：创建一个最小化的JDK镜像简述目前JDK官方并不提供docker镜像，只有OpenJDK镜像提供，但是遇到必须使用JDK的情况时，我们就只能自己构建了。和上个例子不同，我们使用上个例子中构建好的镜像，运用FROM命令和MAINTAINER命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465############################################################# Dockerfile to build min JDK# Based on my_alpine############################################################# Set the base image to UbuntuFROM my_alpine# File Author MAINTAINER zhaoshg@qq.comENV JAVA_VERSION=8 \ JAVA_UPDATE=121 \ JAVA_BUILD=13 \ JAVA_PATH=e9e7ea248e2c4826b92b3f075a80e441 \ JAVA_HOME="/usr/lib/jvm/default-jvm"#安装一些工具并下载JDK进行安装#在安装完毕后删除一些不必要的文件进行精简#删除之前安装的工具RUN apk add --no-cache --virtual=build-dependencies wget ca-certificates unzip &amp;&amp; \ cd "/tmp" &amp;&amp; \ wget --header "Cookie: oraclelicense=accept-securebackup-cookie;" \ "http://download.oracle.com/otn-pub/java/jdk/$&#123;JAVA_VERSION&#125;u$&#123;JAVA_UPDATE&#125;-b$&#123;JAVA_BUILD&#125;/$&#123;JAVA_PATH&#125;/jdk-$&#123;JAVA_VERSION&#125;u$&#123;JAVA_UPDATE&#125;-linux-x64.tar.gz" &amp;&amp; \ tar -xzf "jdk-$&#123;JAVA_VERSION&#125;u$&#123;JAVA_UPDATE&#125;-linux-x64.tar.gz" &amp;&amp; \ mkdir -p "/usr/lib/jvm" &amp;&amp; \ mv "/tmp/jdk1.$&#123;JAVA_VERSION&#125;.0_$&#123;JAVA_UPDATE&#125;" "/usr/lib/jvm/java-$&#123;JAVA_VERSION&#125;-oracle" &amp;&amp; \ ln -s "java-$&#123;JAVA_VERSION&#125;-oracle" "$JAVA_HOME" &amp;&amp; \ ln -s "$JAVA_HOME/bin/"* "/usr/bin/" &amp;&amp; \ rm -rf "$JAVA_HOME/"*src.zip &amp;&amp; \ rm -rf "$JAVA_HOME/lib/missioncontrol" \ "$JAVA_HOME/lib/visualvm" \ "$JAVA_HOME/lib/"*javafx* \ "$JAVA_HOME/jre/lib/plugin.jar" \ "$JAVA_HOME/jre/lib/ext/jfxrt.jar" \ "$JAVA_HOME/jre/bin/javaws" \ "$JAVA_HOME/jre/lib/javaws.jar" \ "$JAVA_HOME/jre/lib/desktop" \ "$JAVA_HOME/jre/plugin" \ "$JAVA_HOME/jre/lib/"deploy* \ "$JAVA_HOME/jre/lib/"*javafx* \ "$JAVA_HOME/jre/lib/"*jfx* \ "$JAVA_HOME/jre/lib/amd64/libdecora_sse.so" \ "$JAVA_HOME/jre/lib/amd64/"libprism_*.so \ "$JAVA_HOME/jre/lib/amd64/libfxplugins.so" \ "$JAVA_HOME/jre/lib/amd64/libglass.so" \ "$JAVA_HOME/jre/lib/amd64/libgstreamer-lite.so" \ "$JAVA_HOME/jre/lib/amd64/"libjavafx*.so \ "$JAVA_HOME/jre/lib/amd64/"libjfx*.so &amp;&amp; \ rm -rf "$JAVA_HOME/jre/bin/jjs" \ "$JAVA_HOME/jre/bin/keytool" \ "$JAVA_HOME/jre/bin/orbd" \ "$JAVA_HOME/jre/bin/pack200" \ "$JAVA_HOME/jre/bin/policytool" \ "$JAVA_HOME/jre/bin/rmid" \ "$JAVA_HOME/jre/bin/rmiregistry" \ "$JAVA_HOME/jre/bin/servertool" \ "$JAVA_HOME/jre/bin/tnameserv" \ "$JAVA_HOME/jre/bin/unpack200" \ "$JAVA_HOME/jre/lib/ext/nashorn.jar" \ "$JAVA_HOME/jre/lib/jfr.jar" \ "$JAVA_HOME/jre/lib/jfr" \ "$JAVA_HOME/jre/lib/oblique-fonts" &amp;&amp; \ wget --header "Cookie: oraclelicense=accept-securebackup-cookie;" \ "http://download.oracle.com/otn-pub/java/jce/$&#123;JAVA_VERSION&#125;/jce_policy-$&#123;JAVA_VERSION&#125;.zip" &amp;&amp; \ unzip -jo -d "$&#123;JAVA_HOME&#125;/jre/lib/security" "jce_policy-$&#123;JAVA_VERSION&#125;.zip" &amp;&amp; \ rm "$&#123;JAVA_HOME&#125;/jre/lib/security/README.txt" &amp;&amp; \ apk del build-dependencies &amp;&amp; \ rm "/tmp/"* 保存 dockfile。 使用Dockerfile构建JDK镜像 Dockerfile 示例三：创建一个最小的带JDK的tomcat镜像123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#使用之前的JDK镜像FROM FROM registry.cn-hangzhou.aliyuncs.com/zhaoshg1984/jdk:min# File Author / MaintainerMAINTAINER zhaoshg@qq.com#set envsENV JAVA_HOME="/usr/lib/jvm/default-jvm"ENV CATALINA_HOME /usr/local/tomcatENV PATH $CATALINA_HOME/bin:$PATHRUN mkdir -p "$CATALINA_HOME"WORKDIR $CATALINA_HOMEENV TOMCAT_NATIVE_LIBDIR $CATALINA_HOME/native-jni-libENV LD_LIBRARY_PATH $&#123;LD_LIBRARY_PATH:+$LD_LIBRARY_PATH:&#125;$TOMCAT_NATIVE_LIBDIRRUN apk add --no-cache gnupg curlENV GPG_KEYS 05AB33110949707C93A279E3D3EFE6B686867BA6 07E48665A34DCAFAE522E5E6266191C37C037D42 47309207D818FFD8DCD3F83F1931D684307A10A5 541FBE7D8F78B25E055DDEE13C370389288584E7 61B832AC2F1C5A90F0F9B00A1C506407564C17A3 713DA88BE50911535FE716F5208B0AB1D63011C7 79F7026C690BAA50B92CD8B66A3AD3F4F22C4FED 9BA44C2621385CB966EBA586F72C284D731FABEE A27677289986DB50844682F8ACB77FC2E86E29AC A9C5DF4D22E99998D9875A5110C01C5A2F6059E7 DCFD35E0BF8CA7344752DE8B6FB21E8933C60243 F3A04C595DB5B6A5F1ECA43E3B7BBB100D811BBE F7DA48BB64BCB84ECBA7EE6935CD23C10D498E23RUN set -ex; \ for key in $GPG_KEYS; do \ gpg --keyserver keyserver.ubuntu.com --recv-keys "$key"; \ doneENV TOMCAT_MAJOR 8ENV TOMCAT_VERSION 8.0.43# https://issues.apache.org/jira/browse/INFRA-8753?focusedCommentId=14735394#comment-14735394ENV TOMCAT_TGZ_URL https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz# not all the mirrors actually carry the .asc files :'(ENV TOMCAT_ASC_URL https://www.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz.ascRUN set -x \ \ &amp;&amp; apk add --no-cache --virtual .fetch-deps \ ca-certificates \ tar \ wget \ openssl \ &amp;&amp; wget -O tomcat.tar.gz "$TOMCAT_TGZ_URL" \ &amp;&amp; wget -O tomcat.tar.gz.asc "$TOMCAT_ASC_URL" \ &amp;&amp; gpg --batch --verify tomcat.tar.gz.asc tomcat.tar.gz \ &amp;&amp; tar -xvf tomcat.tar.gz --strip-components=1 \ &amp;&amp; rm bin/*.bat \ &amp;&amp; rm tomcat.tar.gz* \ \ &amp;&amp; nativeBuildDir="$(mktemp -d)" \ &amp;&amp; tar -xvf bin/tomcat-native.tar.gz -C "$nativeBuildDir" --strip-components=1 \ &amp;&amp; apk add --no-cache --virtual .native-build-deps \ apr-dev \ gcc \ libc-dev \ make \# "openjdk$&#123;JAVA_VERSION%%[-~bu]*&#125;"="$JAVA_ALPINE_VERSION" \ openssl-dev \ &amp;&amp; ( \ export CATALINA_HOME="$PWD" \ &amp;&amp; cd "$nativeBuildDir/native" \ &amp;&amp; ./configure \ --libdir="$TOMCAT_NATIVE_LIBDIR" \ --prefix="$CATALINA_HOME" \ --with-apr="$(which apr-1-config)" \ --with-java-home="$JAVA_HOME" \ --with-ssl=yes \ &amp;&amp; make -j$(getconf _NPROCESSORS_ONLN) \ &amp;&amp; make install \ ) \ &amp;&amp; runDeps="$( \ scanelf --needed --nobanner --recursive "$TOMCAT_NATIVE_LIBDIR" \ | awk '&#123; gsub(/,/, "\nso:", $2); print "so:" $2 &#125;' \ | sort -u \ | xargs -r apk info --installed \ | sort -u \ )" \ &amp;&amp; apk add --virtual .tomcat-native-rundeps $runDeps \ &amp;&amp; apk del .fetch-deps .native-build-deps \ &amp;&amp; rm -rf "$nativeBuildDir" \ &amp;&amp; rm bin/tomcat-native.tar.gz# verify Tomcat Native is working properlyRUN sed '447 a tail -f /dev/null' -i bin/catalina.sh \ &amp;&amp; set -e \ &amp;&amp; nativeLines="$(catalina.sh configtest 2&gt;&amp;1)" \ &amp;&amp; nativeLines="$(echo "$nativeLines" | grep 'Apache Tomcat Native')" \ &amp;&amp; nativeLines="$(echo "$nativeLines" | sort -u)" \ &amp;&amp; if ! echo "$nativeLines" | grep 'INFO: Loaded APR based Apache Tomcat Native library' &gt;&amp;2; then \ echo &gt;&amp;2 "$nativeLines"; \ exit 1; \ fiEXPOSE 8080CMD ["catalina.sh", "start"]# 这种在构建过程中需要下载的情况，最好是托管到阿里云或者网易云，用他们的海外服务器来进行构建，否则会有些内容无法下载，例如上面的keyserver.ubuntu.com 具体的可以去我在阿里云上的镜像仓库看看]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker常用命令]]></title>
      <url>%2F20170420%2Fdocker_common_command%2F</url>
      <content type="text"><![CDATA[常用命令 最常用几个命令1234567891011121314151617181920#显示现有镜像$docker images#查看正在运行的容器$docker ps#查看所有容器$docker ps -a#进入容器$ docker exec -it &lt;containerName/Id&gt; "bin/bash"#停止所有容器$docker stop $(docker ps -a -q)#删除所有已经停止的容器$docker rm $(docker ps -a -q)#删除所有的容器,包括正在运行的$docker rm -f $(docker ps -a -q) 镜像操作检查Docker的安装是否正确：1$docker info 查询仓库的镜像1$docker search &lt;name&gt; 下载镜像1$docker pull &lt;name&gt; 删除镜像1$docker rmi &lt;imageName&gt; 删除所有镜像1$docker rmi $(docker images -q -a) 查看镜像列表：1$docker images 查看镜像的历史版本1$docker history &lt;imageId&gt; 将镜像推送到registry1$docker push &lt;repo_name&gt; 运行镜像1$docker run &lt;imageId/imageName&gt; Docker 运行时常用参数1234567891011121314151617181920212223242526272829303132333435363738394041 Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] -d, --detach=false 指定容器运行于前台还是后台，默认为false -i, --interactive=false 打开STDIN，用于控制台交互 -t, --tty=false 分配tty设备，该可以支持终端登录，默认为false -u, --user="" 指定容器的用户 -a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir="" 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory="" 指定容器的内存上限 -P, --publish-all=false 指定容器暴露的端口 -p, --publish=[] 指定容器暴露的端口 -h, --hostname="" 指定容器的主机名 -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities --cidfile="" 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法 --cpuset="" 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU --device=[] 添加主机设备给容器，相当于设备直通 --dns=[] 指定容器的dns服务器 --dns-search=[] 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件 --entrypoint="" 覆盖image的入口点 --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 --link=[] 指定容器间的关联，使用其他容器的IP、env等信息 --lxc-conf=[] 指定容器的配置文件，只有在指定--exec-driver=lxc时使用 --name="" 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 --net="bridge" 容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge），但是不进行配置 --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart="no" 指定容器停止后的重启策略: no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 容器操作查看正在运行的容器：1$docker ps 启动时设置root用户密码1$docker run -d -e ROOT_PASS=&lt;mypass&gt; &lt;imageID&gt; 查看所有容器（包括已经关闭的）：1$docker ps -a 列出最近一次启动的container1$docker ps -l 用一行列出所有正在运行的container（容器多的时候非常清晰）1$docker ps | less -S 查看镜像/容器信息1$docker inspect &lt;imageId/containerId&gt; 显示一个运行的容器里面的进程信息1$docker top &lt;containerName/containerID&gt; 停止容器1$docker stop &lt;containerId&gt; 停止所有容器1$docker stop $(docker ps -q); 杀死容器1$docker kill &lt;containerName/containerID&gt; 杀死所有容器1$docker kill $(docker ps -q); 删除所有容器1$docker rm $(docker ps -a -q) 启动容器1$docker start &lt;containerId&gt; 重启容器1$docker restart &lt;containerId&gt; 从容器里面拷贝文件/目录到本地一个路径12$docker cp &lt;containerName:/container_path&gt; to_path $docker cp &lt;containerID:/container_path&gt; to_path 删除所有容器1$docker rm `docker ps -a -q` 如何连接运行中的容器方法一（推荐）：12#后面的bin/bash由容器版本决定，可能是bin/bash（ubuntu\debian）,也可能是bin/sh（alpine）$docker exec -it &lt;containerId/containername&gt; "bin/bash" 方法二：1$docker attach &lt;containerId&gt; 方法三：安装nsenter1$docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter 查看所连接容器的PID12#获取PID$PID=$(docker inspect --format &#123;&#123;.State.Pid&#125;&#125; &lt;container_name_or_ID&gt;) 连接容器1$sudo nsenter --target $PID --mount --uts --ipc --net --pid]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker的安装]]></title>
      <url>%2F20170420%2Fdocker_install%2F</url>
      <content type="text"><![CDATA[Docker的安装 卸载旧版本 docker 或者 docker-engine 12345$sudo yum remove docker \ docker-common \ container-selinux \ docker-selinux \ docker-engine 安装Docker CE 12345$ sudo yum install -y yum-utils$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo$ sudo yum-config-manager --enable docker-ce-edge$ sudo yum makecache fast$ sudo yum install docker-ce 启动Docker1$sudo systemctl start docker 详见官方文档 去除sudo如果还没有 docker group 就添加一个：1$sudo groupadd docker 将用户加入该 group 内。然后退出并重新登录就生效啦。1$sudo gpasswd -a $&#123;USER&#125; docker 重启 docker 服务1$sudo systemctl restart docker 切换当前会话到新 group 或者重启 X 会话1$newgrp - docker OR1$pkill X 注意，最后一步是必须的，否则因为 groups 命令获取到的是缓存的组信息，刚添加的组信息未能生效，所以 docker images 执行时同样有错。 原因分析 因为 /var/run/docker.sock 所属 docker 组具有 setuid 权限 12$sudo ls -l /var/run/docker.socksrw-rw---- 1 root docker 0 May 1 21:35 /var/run/docker.sock 检查、测试12$docker info$docker run hello-world]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[基于 Consul 的 Docker Swarm 服务发现]]></title>
      <url>%2F20170420%2Fdocker_consul_swarm%2F</url>
      <content type="text"><![CDATA[Docker 是一种新型的虚拟化技术，它的目标在于实现轻量级操作系统的虚拟化。相比传统的虚拟化方案，Docker 虚拟化技术有一些很明显的优势：启动容器的速度明显快于传统虚拟化技术，同时创建一台虚拟机占用的资源也要远远小于传统的虚拟技术。Swarm 是 Docker 集群化的技术，而 Swarm 集群化 Docker 离不开服务发现。Consul 能够解决 Swarm 的服务发现问题。本文将介绍 Swarm 如何使用 Consul 作为服务发现。 Docker Swarm 服务发现Docker 集群化可以通过 Swarm 来实现。Swarm 对 Docker 集群中节点的动态加入和退出的感知叫做服务发现。Docker Swarm 支持多种服务发现方式，下面进行详细介绍。 服务发现方式 Docker Swarm 支持的服务发现方式主要有以下几种： TokenToken 发现策略使用 ID 来唯一标识集群，每一个节点通过指定集群 ID 来标识加入的集群。所以首先使用 Swarm 产生一个集群 ID，然后每一个节点通过 join Cluster-ID 动态加入这个集群。 NodesNodes 发现策略依赖于集群节点，我们在集群 manage 节点执行加入集群指令时，就需要指定要加入集群的其他节点。所以集群成员需要预先定义。 File首先将加入集群的节点存储在一个文件中，我们在集群 manage 节点执行加入集群指令时，指定存储集群中所有节点的文件。所以集群成员也是需要预先定义。 分布式 key/value 存储Swarm 使用第三方软件的 key/value 形式存储节点信息，分布式 key-value 存储不仅能够实现 Swarm 节点的动态加入，同时提供了很多其他的功能，直观显示集群中的每个节点以及每个节点提供的服务等。Swarm 通过 key/value 存储实现的服务发现有三种，接下来，分别进行介绍。 分布式 key/value 存储Swarm 通过分布式 key/value 存储实现的服务发现方式有以下三种： ZooKeeperZooKeeper 是比较成熟的分布式 key/value 存储，但是使用复杂，入门门槛较高，需要借助第三方软件来发送 key-value 数据给 ZooKeeper 完成数据存储。 EtcdEtcd 部署使用简单，提供了可靠的数据存储，但是需要借助第三方软件，手动将 key/value 数据发送给 Etcd 来存储。 ConsulConsul 提供了可靠的数据存储，并且提供了服务发现框架，不需要借助第三方软件。本文主要介绍第三方服务发现 Consul 在 Docker Swarm 中的的使用，接下来对 Consul 进行介绍。 Consul 简介Consul 提供了分布式环境中服务的注册和发现，支持分布式，高可用，多数据中心。 Consul 重要概念Consul 中的重要概念： Agent：Consul 集群中每个成员运行的守护进程，以 Client 或者 Server 的模式存在。 Client：发送 RPC 请求给服务器的 Agent。 Server：是一个 Agent，负责响应 RPC 查询，维护集群状态，参与 Raft 仲裁等。Server 有三种存在状态。接下来，分别介绍这三种状态以及它们之间的关系。 Server 存在状态Server 的三种状态形式：Leader，Follower，Candidate。 Candidate：Server 参与 Raft 仲裁，竞选期间所有服务器的状态。 Leader：Server 参与 Raft 仲裁，竞选结束获胜服务器的状态。 Follower：Server 参与 Raft 仲裁，竞选结束未获胜服务器的状态。 三种状态之间关系如下：Consul 集群 Server 节点中要有一个 Leader。Leader 负责维护集群中所有节点的状态。当集群还没有 Leader 或者 Leader 出现故障时候，所有的 Server 运行 Raft 算法，开始竞选。竞选期间所有 Server 的状态称为 Candidate。最终集群中的 Server 经过竞选，只有一台 Server 获胜，竞选结束。这个时候集群中获胜的 Server 称为 Leader，其他的 Server 称为 Follower。 Consul 架构为了从整体上对 Consul 有一个了解，下面以一个数据中心的 Consul 部署结构图来对 Consul 进行说明。一个数据中心的 Consul 集群由客户端和服务器组成，服务器以 Leader 和 Follower 两种角色存在。Client 会定时向 Server 发送 RPC 请求，汇报自己的运行状态。Leader 收到 Client 的 RPC 请求，会给 client 发送 RPC 响应，同时存储 Client 的状态等信息。Follower 收到 Client 的 RPC 请求，会转发给 Leader。Leader 存储该 Client 的信息。Consul 的架构如下图所示。 对 Swarm 的服务发现策略和 Consul 有了整体了解后，下面具体介绍在代码实现中，Swarm 如何使用 Consul 作为服务发现。 Swarm Consul 服务发现源码解析在 GitHub 官网可以下载Swarm源码。本文以 Swarm 1.2.4 为例，通过介绍 swarm join 的流程，来说明 Swarm 使用 Consul 的服务发现过程。 首先，我们简单说明 Swarm 源码文件夹结构以及每个文件的功能。 Swarm 源码文件夹结构Swarm 源码的文件夹结构如下表 1 所示。 文件夹名称 文件夹说明 api Swarm对外提供的 API cli Swarm命令行解析 cluster Swarm集群管理 discovery Swarm 集群发现（Token 方式） docs Swarm 文档 experimental Swarm 实验性功能 Godeps Go 语言包依赖管理工具 scheduler Swarm 调度器 script Swarm 脚本 swarmclient Docker Engine 操作 Swarm 的 API test Swarm 测试 vendor Swarm 的依赖包 version Swarm 版本 main.go Swarm 入口函数 表 1. Swarm 源码的文件夹结构 Swarm join 是 Swarm 节点加入 Swarm 集群的命令，并且节点在执行 swarm join 命令时，可以指定 Swarm 的服务发现方式。在对 Swarm 源码的文件结构有了整体了解后，接下来我们通过分析 swarm join 的源码，理解 Swarm 使用 Consul 作为服务发现的过程。 Swarm join 源码解析Swarm 支持一定的命令行操作。当客户端输入 swarm join 命令时，Swarm 会首先在自己支持的命令集合中找到该命令，同时找到该命令对应的处理函数。然后执行 swarm join 的处理函数。在该处理函数中，swarm 会根据命令行输入的服务发现策略 Consul，初始化一个 Consul 客户端，而后向 Consul 服务器发送注册消息，完成客户端加入集群的操作。 Swarm 所有操作的入口函数是 main 函数。123func main() &#123; cli.Run()&#125; main 函数的功能是启动命令行应用程序。命令行应用程序在启动的时候主要做三件事：1、创建命令行应用程序。2、初始化 Swarm 支持的命令。3、运行命令行应用程序。其中初始化 Swarm 支持的命令，定义了每个版本的 Swarm 支持的命令行集合，以及每个命令对应的处理函数。下面是命令行程序启动时的主要代码。12345678910func Run() &#123; //1、创建 go 的命令行应用 app app := cli.NewApp() //2、初始化 app 的命令行参数 app.Commands = commands //3、运行 app if err := app.Run(os.Args); err != nil &#123; log.Fatal(err) &#125;&#125; 以上代码清单位于文件 cli/cli.go。下面对以上代码的主要功能进行详细说明。 创建命令行应用程序该功能是利用第三方库 github.com/codegangsta/cli 来创建 Go 的命令行应用程序。在 Swarm 的第三方依赖文件夹 vendor/github.com/codegangsta/cli 可以找到创建 Go 应用程序的依赖文件。 初始化 Swarm 支持的命令这个部分是很关键的一部分，该版本的 Swarm 支持的所有命令以及每个命令对应的处理函数等信息都在此处完成初始化。Swarm 使用数组 commands 完成所有命令的初始化。commands 的定义位于文件 cli\commands.go，关键代码如下。12345678910111213141516171819202122232425262728293031var ( commands = []cli.Command&#123; &#123; Name: "create", ShortName: "c", Usage: "Create a cluster", Action: create, &#125;, &#123; Name: "list", ShortName: "l", Usage: "List nodes in a cluster", Flags: []cli.Flag&#123;flTimeout, flDiscoveryOpt&#125;, Action: list, &#125;, &#123; Name: "manage", ShortName: "m", Usage: "Manage a docker cluster", //Flags 定义... Action: manage, &#125;, &#123; Name: "join", ShortName: "j", Usage: "Join a docker cluster", //Flags 定义... Action: join, &#125;, &#125;) 在上面的 commands 的定义中，Name 字段指定了 Swarm 支持的每个命令，Action 字段指定了每个命令的处理函数。下面我们把 swarm join 命令和上面的定义结合起来，具体说明下当在节点的终端输入 join 命令时，swarm 代码是如何执行的。 join 命令在终端的使用如下：1$docker run -d -p 2376:2375 --name swarm-slave-01 swarm join -addr 192.168.1.28:2376 consul://192.168.1.28:8500 当我们在终端输入以上命令，Swarm 会首先解析命令，解析出用户要执行的命令是 join 命令。然后在上面 commands 的定义中找到 join 命令的处理函数是 join 函数。接下来就调用 join 函数完成 join 命令的执行。下面代码展示了 Swarm 解析执行终端命令的过程。12345678910111213141516171819func (a *App) Run(arguments []string) (err error)&#123; args := context.Args() if args.Present() &#123; //... c := a.Command(name) if c != nil &#123; //调用 Command 的 Run 函数来执行操作 return c.Run(context) &#125; &#125; // Run default Action a.Action(context)&#125;//Command 的 Run 函数func (c Command) Run(ctx *Context) error &#123; context.Command = c//调用 Command 的 Action 函数，如果我们输入的是 join 函数，接下来就会执行 join 函数 c.Action(context)&#125; 以上代码清单位于 github.com/codegangsta/cli/app.go 中的 Run 函数。 Swarm 在初始化的时候，会初始化它支持的第三方服务发现。当我们在终端指定第三方服务发现的时候，Swarm 会调用对应的第三方服务发现接口，创建并初始化第三方服务发现客户端，然后向第三方服务发现服务器发送注册消息，完成注册。 下一步，我们将要考虑 join 函数的具体实现，Swarm 创建 Consul 客户端以及向 Consul 服务器的注册过程。join 函数如下所示。12345678func join(c *cli.Context) &#123; dflag := getDiscovery(c) 1、创建服务发现 d, err := discovery.New(dflag, hb, ttl, getDiscoveryOpt(c)) for &#123; 2、注册服务发现 if err := d.Register(addr); err != nil &#123;//....&#125; &#125;//. 以上代码位于 cli/join.go。 join 函数主要功能是：创建服服务发现客户端和向服务发现服务器注册。 创建服务发现创建第三方服务发现客户端使用的是简单工厂模式。Swarm 会首先将支持的第三方服务发现初始化在一个 map 中，然后根据我们在命令行指定的第三方服务发现，去调用对应的初始化方法。所以如果我们自己写了一个第三方服务发现软件，可以很方便地嵌入到 Swarm 中。创建服务发现的数据流程图如下图 所示。 Swarm 首先调用 discovery 包下面的 New 函数，在该函数中调用 Backen 接口的 Initialize 方法，在 Initialize 方法中，调用 libkv 包下的 NewStore 方法。在 NewStore 方法中，首先判断 Swarm 是否支持终端输入的服务发现，如果支持，就去调用该服务发现的初始化方法完成第三方服务发现的初始化。 Consul 初始化函数 New 函数位于 github/com/docker/libkv/store/consul/consul.go，如下所示。 1234567891011121314func New(endpoints []string, options *store.Config) (store.Store, error) &#123; s := &amp;Consul&#123;&#125; config := api.DefaultConfig() s.config = config config.HttpClient = http.DefaultClient config.Address = endpoints[0] config.Scheme = "http" .... // Creates a new client client, err := api.NewClient(config) ... s.client = client return s, nil&#125; 在 Consul 的初始化函数中，新创建一个 Consul 客户端，并完成 Consul 客户端一些参数的初始化。 注册服务发现consul 完成服务发现的初始化，就会发送注册信息给 consul 服务器完成注册。key/value 的注册代码位于 github.com\docker\docker\pkg\discovery\kv\kv.go ，如下所示： 12345// Register is exportedfunc (s *Discovery) Register(addr string) error &#123; opts := &amp;store.WriteOptions&#123;TTL: s.ttl&#125; return s.store.Put(path.Join(s.path, addr), []byte(addr), opts)&#125; Consul 发送注册地址到 Consul 服务器，完成 Consul 的注册。 Consul 实现 Docker Swarm 服务注册例子 结合Swarm join 源码解析，下面介绍如何使用 Consul 实现 Docker Swarm 服务发现。 在 Swarm 的 Client 节点（IP 地址为 192.168.1.28）执行加入集群的指令，并指定 Consul 作为服务发现。 1$docker run -d --name swarm-slave-04 itaas-docker-registry:5000/public/swarm:1.2.3 join --addr 192.168.1.28:2375 consul://192.168.1.28:8500 8c7a6ec6d48ed526a81504879755e3772978790df4bf2476693b144 使用 Consul 的 Web UI 查看命令执行结果。在浏览器地址栏输入 http://192.168.1.28:8500，然后选择 key/value 选项卡，在该选项卡下选择 docker/swarm/nodes，可以看到 192.168.1.28 这个节点已经注册到 Docker Swarm 集群。 Consul 服务发现的结果如下图所示。 总结与展望 本文概述了 Docker Swarm 服务发现的四种策略并进行了简单的比较，简单介绍了 Consul，详述了 Swarm 使用 Consul 作为服务发现的代码流程，最后用一个例子说明了 Docker Swarm 使用 Consul 作为服务发现的过程，希望能够让大家对 Swarm 服务发现的过程有所了解。 通过对 Swarm 服务发现源码的解析，可以看到 Swarm 源码中使用第三方 key/value 作为服务发现的实现采用了简单工厂模式，我们也可以很容易地将其他的第三方 key/value 插件，以及自己设计的服务发现插件嵌入到 Swarm 的服务发现中。 参考资料学习 参考Consul、Etcd 和 ZooKeeper 的区别，了解第三方服务发现的区别 参考Consul 架构图，了解更多 Consul 的基本架构 参考热备份，查看热备份概念 参考Raft，查看 Raft 算法实现原理 参考Swarm 代码框架，了解 Swarm 代码的整体设计 参考Swarm 源码文件夹结构，了解 Swarm 源码的文件夹结构 参考Swarm manage 和 Store 流程解析，了解更多 Swarm 第三方服务发现执行流程 相关主题 访问 developerWorks 中国 IBM Bluemix 资源中心：本专题提供了丰富的文章、教程和演示等学习资源，带您由浅入深地了解 Bluemix。 访问 developerWorks 云计算专区，developerWorks 为开发人员和专业人员推出的云计算社区和技术资源。您可以了解关于云计算的更多信息，获取技术文档、how-to 文章、培训、下载、产品信息以及其他最新技术资源，并参与社区讨论。 IBM developerWorks Premium 是一项针对开发人员的会员计划，它提供了功能强大的工具、资源和支持，旨在帮助您快速设计原型、开发和部署成功的云项目。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[基于consul的Docker-overlay跨多宿主机容器网络]]></title>
      <url>%2F20170420%2Fdocker_consul_overlay%2F</url>
      <content type="text"><![CDATA[环境限制 必须安装key-value存储服务，如consul 宿主机已经安装docker engine 宿主机的hostname必须不同 内核大于3.16 环境准备及角色分配 两台ubuntu的server 主机名 ip 内核 启动docker容器名称 docker engine版本 consul服务 test26 192.168.2.26 4.10.4-1.el7.elrepo.x86_64 test26（centOS7） 17.03.0-ce server test139 192.168.2.139 4.10.4-1.el7.elrepo.x86_64 test139（centOS7） 17.03.0-ce client 实验目标： 两个CentOS7容器test26,test139网络互通, 注意本文中的zhaoshg@test26和zhaoshg@test139 防火墙开放端口分别在两台机器上运行：123$sudo firewall-cmd --permanent --add-port=&#123;8500/tcp,8300/tcp,8301/tcp,3375/tcp,2375/tcp&#125;$sudo firewall-cmd --reload$sudo firewall-cmd --list-all 运行分布式发现服务协调软件：consul 拉取consul镜像 1$docker pull consul 启动consul 12[zhaoshg@test ~]$docker run -d -it --net=host --name=consul_server -v /home/zhaoshg/consul_data:/data -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' -p 8300:8300 -p 8301:8301 -p 8301:8301/udp -p 8302:8302 -p 8302:8302/udp -p 8400:8400 -p 8500:8500 -p 53:53/udp consul agent -server -bootstrap -bind=192.168.2.26[nrj@test ~]$docker run -d -it --net=host --name=consul_client -v /home/zhaoshg/consul_data:/data -e 'CONSUL_LOCAL_CONFIG=&#123;"leave_on_terminate": true&#125;' -p 8300:8300 -p 8301:8301 -p 8301:8301/udp -p 8302:8302 -p 8302:8302/udp -p 8400:8400 -p 8500:8500 -p 53:53/udp consul agent -bind=192.168.2.139 -join=192.168.2.26 可以启动一个server和多个agent(此处是一个)，然后让agent，join到consul集群中 启动时可能会遇到55/udp被占用，多半是虚拟网卡的问题，卸载就好：1234$sudo virsh net-list$sudo virsh net-destroy default $sudo virsh net-undefine default$sudo service libvirtd restart 配置Docker并重启 在每一台docker宿主机上做如下配置，并重启docker 12345678910$sudo vim /etc/docker/daemon.json//添加&#123; "tls": false, "hosts": ["unix:///var/run/docker.sock","tcp://0.0.0.0:2375"], "cluster-store": "consul://localhost:8500", "cluster-advertise": "enp0s3:2375"&#125;$sudo systemctl daemon-reload$sudo systemctl restart docker enp0s3代表两台宿主机交互所对应的网卡地址 分别是 192.168.2.26和192.168.2.139 集群配置 –cluster-store= 参数指向docker daemon所使用key value service的地址（本例中即consul的服务地址）–cluster-advertise= 参数决定了所使用网卡以及docker daemon端口信息 宿主机配置 上面的-H 的参数分别指定了docker demon服务的地址和协议 跨主机网络创建创建overlay网络 创建 1[zhaoshg@test26 ~]: $sudo docker network create -d overlay mynet 验证在test26上创建的multihost网络，会通过consul服务同步到test139上面 1234567[zhaoshg@test139 ~]:$docker network lsNETWORK ID NAME DRIVER SCOPE490c2dbc35e0 bridge bridge local045f3acd3c28 docker_gwbridge bridge local023021bcc407 host host local5104bce70f86 mynet overlay global3bbb2a39fad8 none null local 创建容器 创建测试容器12$docker run -d -it --net=mynet --name=test1 centos$docker run -d -it --net=mynet --name=test2 centos 验证网络互通1234567891011121314151617181920212223242526272829303132333435363738394041424344zhaoshg@test139:~$ PID=$(docker inspect --format &#123;&#123;.State.Pid&#125;&#125; test2)zhaoshg@test139:~$ sudo nsenter --target $PID --mount --uts --ipc --net --pid[root@2516560c337f /]# yum install net-tools[root@2516560c337f /]# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 10.0.0.2 netmask 255.255.255.0 broadcast 0.0.0.0 inet6 fe80::42:aff:fe00:2 prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:0a:00:00:02 txqueuelen 0 (Ethernet) RX packets 31 bytes 2398 (2.3 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 18 bytes 1412 (1.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@2516560c337f /]# [root@2516560c337f /]# ping 192.168.2.26PING 192.168.2.26 (192.168.2.26) 56(84) bytes of data.64 bytes from 192.168.2.26: icmp_seq=1 ttl=63 time=0.657 ms64 bytes from 192.168.2.26: icmp_seq=2 ttl=63 time=0.853 ms64 bytes from 192.168.2.26: icmp_seq=8 ttl=63 time=0.463 ms64 bytes from 192.168.2.26: icmp_seq=9 ttl=63 time=0.681 ms^C--- 192.168.2.26 ping statistics ---32 packets transmitted, 32 received, 0% packet loss, time 31736msrtt min/avg/max/mdev = 0.363/0.671/1.486/0.183 ms[root@2516560c337f /]# [root@2516560c337f /]# ping 10.0.0.2PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.034 ms64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.068 ms64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.061 ms64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.068 ms^C--- 10.0.0.2 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3089msrtt min/avg/max/mdev = 0.034/0.057/0.068/0.016 ms[root@2516560c337f /]# 验证结论: test139容器host2的ip=10.0.0.3，可以ping通test26，可以ping通test26上的容器host1的ip=10.0.0.2 如何使用静态ip 以上的实验步骤。container的ip都是自动分配的，如果需要静态的固定ip，怎么办？ 在创建网络的过程中有区别 123$sudo docker network create -d overlay --ip-range=192.168.20.0/24 --gateway=192.168.20.1 --subnet=192.168.20.0/24 mynet$docker run -d -it --name test1 --net=mynet --ip=192.168.20.2 centos$docker run -d -it --name test2 --net=mynet --ip=192.168.20.3 centos 删除网络1$docker network rm mynet]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo的分类和标签设置]]></title>
      <url>%2F20170419%2Fhexo_tags_categories%2F</url>
      <content type="text"><![CDATA[设置分类列表修改根目录下_config.yml1234567891011# Directorysource_dir: sourcepublic_dir: public#这个是tags的目录tag_dir: tagsarchive_dir: archives#这个是category的目录category_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render: 修改themes下_config.yml12345678910menu: home: / #categories要打开 categories: /categories #about: /about archives: /archives #tags要打开 tags: /tags #sitemap: /sitemap.xml #commonweal: /404.html 生成tags和categories页面在根目录下执行12$hexo n page "tags"$hexo n page "categories" 然后去source目录下找到categories/index.md修改：123456---title: categoriesdate: 2017-04-19 16:19:25type: categoriescomments: false--- 去source目录下找到tags/index.md修改：123456---title: tagsdate: 2017-04-19 16:19:25type: tagscomments: false--- 这样就配置好了 在文章中添加tag、分类模板中添加编辑 /sacaffolds/post.md123456---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;categories: tags:--- 这样，new出来的文章默认就带上categories和tags了 多个tag的写法12345tages: - 标签1 - 标签2 ... - 标签n]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker Compose安装、使用和示例]]></title>
      <url>%2F20170419%2Fdocker_compose_install_use_exp%2F</url>
      <content type="text"><![CDATA[Compose是用于定义和运行复杂Docker应用的工具。你可以在一个文件中定义一个多容器的应用，然后使用一条命令来启动你的应用，然后所有相关的操作都会被自动完成。 1. 安装Docker和Compose Compose是用于定义和运行复杂Docker应用的工具。你可以在一个文件中定义一个多容器的应用，然后使用一条命令来启动你的应用，然后所有相关的操作都会被自动完成。 安装123$curl -L "https://github.com/docker/compose/releases/download/1.11.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose $chmod +x /usr/local/bin/docker-compose 测试安装结果12$docker-compose --versiondocker-compose version: 1.11.2 2. 使用Compose使用Compose只需要简单的三个步骤： 首先，使用Dockerfile来定义你的应用环境：1234FROM python:2.7ADD ./codeWORKDIR /codeRUN pip install -r requirements.txt 其中，requirements.txt中的内容包括：12flaskredis 再用Python写一个简单的app.py12345from flask importFlaskfrom redis importRedisimport osapp =Flask(__name__)redis =Redis(host='redis', port=6379)@app.route('/')def hello(): redis.incr('hits')return'Hello World! I have been seen %s times.'% redis.get('hits')if __name__ `"__main__": app.run(host="0.0.0.0", debug=True) 第二步，用一个compose.yaml来定义你的应用服务，他们可以把不同的服务生成不同的容器中组成你的应用。1234567891011web: build:. command: python app.py ports: - "5000:5000" volumes: - .:/code links: - redisredis: image: redis 第三步，执行docker-compose up来启动你的应用，它会根据compose.yaml的设置来pull/run这俩个容器，然后再启动。 12345678910111213141516171819Creating myapp_redis_1...Creating myapp_web_1...Building web...Step 0 : FROM python:2.72.7: Pulling from python...Status: Downloaded newer image for python:2.7 ---&gt; d833e0b23482Step 1 : ADD . /code ---&gt; 1c04b1b15808Removing intermediate container 9dab91b4410dStep 2 : WORKDIR /code ---&gt; Running in f495a62feac9 ---&gt; ffea89a7b090Attaching to myapp_redis_1, myapp_web_1......redis_1 | [1] 17 May 10:42:38.147 * The server is now ready to accept connections on port 6379web_1 | * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)web_1 | * Restarting with stat 3. Yaml文件参考在上面的yaml文件中，我们可以看到compose文件的基本结构。首先是定义一个服务名，下面是yaml服务中的一些选项条目： image:镜像的IDbuild:直接从pwd的Dockerfile来build，而非通过image选项来pulllinks：连接到那些容器。每个占一行，格式为SERVICE[:ALIAS],例如 – db[:database]external_links：连接到该compose.yaml文件之外的容器中，比如是提供共享或者通用服务的容器服务。格式同linkscommand：替换默认的command命令ports: 导出端口。格式可以是：1ports:-"3000"-"8000:8000"-"127.0.0.1:8001:8001" expose:导出端口，但不映射到宿主机的端口上。它仅对links的容器开放。格式直接指定端口号即可。volumes：加载路径作为卷，可以指定只读模式：123volumes:-/var/lib/mysql - cache/:/tmp/cache -~/configs:/etc/configs/:ro volumes_from：加载其他容器或者服务的所有卷12environment:- RACK_ENV=development - SESSION_SECRET env_file：从一个文件中导入环境变量，文件的格式为RACK_ENV=developmentextends:扩展另一个服务，可以覆盖其中的一些选项。一个sample如下：123456789101112webapp: build:./webapp environment:- DEBUG=false- SEND_EMAILS=falsedevelopment.ymlweb:extends: file: common.yml service: webapp ports:-"8000:8000" links:- db environment:- DEBUG=truedb: image: postgres net：容器的网络模式，可以为”bridge”, “none”, “container:[name or id]”, “host”中的一个。dns：可以设置一个或多个自定义的DNS地址。dns_search:可以设置一个或多个DNS的扫描域。其他的working_dir, entrypoint, user, hostname, domainname, mem_limit, privileged, restart, stdin_open, tty, cpu_shares，和docker run命令是一样的，这些命令都是单行的命令。例如：1234567891011cpu_shares:73working_dir:/codeentrypoint: /code/entrypoint.shuser: postgresqlhostname: foodomainname: foo.commem_limit:1000000000privileged:truerestart: alwaysstdin_open:truetty:true 4. docker-compose常用命令在第二节中的docker-compose up，这两个容器都是在前台运行的。我们可以指定-d命令以daemon的方式启动容器。除此之外，docker-compose还支持下面参数： --verbose：输出详细信息-f 制定一个非docker-compose.yml命名的yaml文件-p 设置一个项目名称（默认是directory名） docker-compose的动作包括： &emsp; build：构建服务&emsp; kill -s SIGINT：给服务发送特定的信号。&emsp; logs：输出日志&emsp; port：输出绑定的端口&emsp; ps：输出运行的容器&emsp; pull：pull服务的image&emsp; rm：删除停止的容器&emsp; run: 运行某个服务，例如docker-compose run web python manage.py ps&emsp; start：运行某个服务中存在的容器。&emsp; stop:停止某个服务中存在的容器。&emsp; up：create + run + attach容器到服务。&emsp; scale：设置服务运行的容器数量。例如：docker-compose scale web=2 worker=3 5. 个人示例示例一1$vim ~/workspace/docker-compose-env.yml 代码：1234567891011121314151617181920212223mysql: image: mysql:5.6.35 container_name: mysql_db expose: - "3306" volumes: - /var/lib/mysql/:/var/lib/mysql/ environment: - MYSQL_ROOT_PASSWORD=yourpassword net: mynetrbac: image: hub.c.163.com/zhaoshg/tomcat:7-jre8-alpine container_name: rbac expose: - "8080" volumes: - /home/zhaoshg/workspace/projects/rbac/:/usr/local/tomcat/webapps/rbac - /home/zhaoshg/logs/rbac/tomcat/:/usr/local/tomcat/logs/ - /home/zhaoshg/logs/rbac/:/home/logs/rbac/ net: mynet links: - mysql:mysql_db mynet是创建的overlay网络， 详见基于consul的Docker-overlay跨多宿主机容器网络?full=true) 运行1$docker-compose -f ~/workspace/docker-compose-env.yml up -d 查看启动情况12345$docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES936d6a048068 mysql:5.6.35 "docker-entrypoint..." 2 hours ago Up 2 hours 3306/tcp workspace_mysql_1f1827893e1b4 43b76557edc3 "catalina.sh run" 2 hours ago Up 2 hours 8080/tcp workspace_rbac_1 示例二1$vim ~/workspace/docker-compose-projects.yml 代码：1234567891011121314151617181920discenter: image: hub.c.163.com/zhaoshg/tomcat:7-jre8-alpine container_name: discenter ports: - "8888:8080" volumes: - /home/zhaoshg/workspace/projects/discenter/:/usr/local/tomcat/webapps/ROOT - /home/zhaoshg/logs/discenter/:/usr/local/tomcat/logs/ net: mynetcms: image: hub.c.163.com/zhaoshg/tomcat:7-jre8-alpine container_name: cms ports: - "8887:8080" volumes: - /home/zhaoshg/workspace/projects/cms/:/usr/local/tomcat/webapps/ROOT - /home/zhaoshg/logs/cms/tomcat/:/usr/local/tomcat/logs/ - /home/zhaoshg/logs/cms/:/home/logs/cms/ net: mynet 运行1$docker-compose -f ~/workspace/docker-compose-projects.yml up -d 查看启动情况1234567$docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES44c331824b2f 43b76557edc3 "catalina.sh run" 2 hours ago Up 2 hours 0.0.0.0:8888-&gt;8080/tcp workspace_discenter_1b3b5ec77f75a 43b76557edc3 "catalina.sh run" 2 hours ago Up 2 hours 0.0.0.0:8887-&gt;8080/tcp workspace_cms_1f1827893e1b4 43b76557edc3 "catalina.sh run" 2 hours ago Up 2 hours 8080/tcp workspace_rbac_1936d6a048068 mysql:5.6.35 "docker-entrypoint..." 2 hours ago Up 2 hours 3306/tcp workspace_mysql_1 示例三123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263version: '2.1'services: mysql: image: hub.c.163.com/zhaoshg/mysql:5.6.35 container_name: mysql volumes: - /home/zhaoshg/workspace/docker-data/mysql/:/var/lib/mysql/ expose: - "3306" environment: - MYSQL_ROOT_PASSWORD=yourpassword healthcheck: test: ["CMD", "curl", "-f", "http://localhost:3306 || exit 1"] interval: 10s timeout: 5s retries: 3# mem_limit: 256m memcached: image: memcached:1.4.36-alpine container_name: memcached ports: - "11211:11211" mem_limit: 56m fdfssingle: image: hub.c.163.com/zhaoshg/fastdfs container_name: fdfssingle ports: - "22122:22122" volumes: - /home/zhaoshg/fastdfs:/fastdfs mem_limit: 200m myweb: image: hub.c.163.com/zhaoshg/tomcat container_name: myweb environment: - JAVA_OPTS=-Djava.rmi.server.hostname=192.168.2.139 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.port=18900 -Dcom.sun.management.jmxremote.rmi.port=18901 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Xms512m -Xmx512m links: - mysql - memcached depends_on: mysql: condition: service_healthy memcached: condition: service_started ports: - "8100:8080" - "18900:18900" - "18901:18901" volumes: - /home/zhaoshg/workspace/projects/discenter/:/usr/local/tomcat/webapps/ROOT - /home/zhaoshg/logs/discenter/tomcat/:/usr/local/tomcat/logs/ - /home/zhaoshg/logs/discenter/web/:/home/logs/discenter/ healthcheck: test: curl -f http://localhost:8080/favicon.ico || exit 1 interval: 30s timeout: 5s retries: 3 参考:Compose Document]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker常见问题及解决方案]]></title>
      <url>%2F20170419%2Fdocker_q_and_a%2F</url>
      <content type="text"><![CDATA[Docker常见问题及解决方案1. container中启动tomcat8.5，访问/manager时直接报403错误，不提示输入用户名密码解决方案：在$CATALINA_BASE/conf/Catalina/localhost下新增manager.xml文件：123&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt;&lt;/Context&gt; 下面是tomcat8.5的问题,下面是官方文档的解释: A default Tomcat installation includes the Manager. To add an instance of the Manager web application Context to a new host install the manager.xml context configuration file in the $CATALINA_BASE/conf/[enginename]/[hostname] folder 2. 去除sudo解决方案： 如果还没有 docker group 就添加一个： 1$sudo groupadd docker 将用户加入该 group 内。然后退出并重新登录就生效啦。 1$sudo gpasswd -a $&#123;USER&#125; docker 重启 docker 服务 1$sudo service docker restart 切换当前会话到新 group 或者重启 X 会话 123$newgrp - dockerOR$pkill X 注意，最后一步是必须的，否则因为 groups 命令获取到的是缓存的组信息，刚添加的组信息未能生效，所以 docker images 执行时同样有错。 原因分析因为 /var/run/docker.sock 所属 docker 组具有 setuid 权限12$sudo ls -l /var/run/docker.socksrw-rw---- 1 root docker 0 May 1 21:35 /var/run/docker.sock 3. 镜像启动后自动退出解决方案： 加 -d -it 参数 4. centos7 中docker info报错docker bridge-nf-call-iptables is disabled解决方案：123456$sudo vim /etc/sysctl.conf#增加 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1$sudo reboot 5. docker 端口映射错误12docker: Error response from daemon: driver failed programming external connectivity on endpoint mysql (93720099240d3fed6a1316d6f1de7001331f8e4c587163653ffbf8b49375b8c1): (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 3306 -j DNAT --to-destination 172.17.0.2:3306 ! -i docker0: iptables: No chain/target/match by that name. (exit status 1)). 解决方案：12345$sudo pkill docker$sudo iptables -t nat -F$sudo ifconfig docker0 down$sudo brctl delbr docker0$sudo systemctl restart docker.service]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 启动顺序控制]]></title>
      <url>%2F20170419%2Fdocker_start_order%2F</url>
      <content type="text"><![CDATA[需求 有时候，你需要制定容器的启动顺序，比如你的web依赖你的sql，当sql没有启动时，你的web是无法正常启动的。 所以，你就会需要控制你容器的启动顺序。 如何实现 很遗憾，目前docker自己的命令都无法真正实现这个功能。 那怎么办 docker官方文档告诉我们，我们可以这样做： Use a tool such as wait-for-it or dockerize. These are small wrapper scripts which you can include in your application’s image and will poll a given host and port until it’s accepting TCP connections. wait-for-it它很简单，就是一段ps脚本（放到文章最下面的代码一） 怎么用更简单,看下面 123456789wait-for-it.sh host:port [-s] [-t timeout] [-- command args]-h HOST | --host=HOST 要测试的IP或者域名-p PORT | --port=PORT 要测试的TCP端口 一般情况下，你可以写成这种形式host:port-s | --strict 只有测试通过，才执行后面的命令-q | --quiet 静默模式，不输出任何状态信息-t TIMEOUT | --timeout=TIMEOUT 超时时间设置，超过就执行后面的命令, 0代表永不超时，如果不带这个参数，就是默认的15秒-- COMMAND ARGS 测试通过后要执行的命令和参数 例一：不带超时时间1234[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:81 -- echo "baidu is up" wait-for-it.sh: waiting 15 seconds for www.baidu.com:81wait-for-it.sh: timeout occurred after waiting 15 seconds for www.baidu.com:81baidu is up 例二：10秒超时1234[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:81 -t 10 -- echo "baidu is up" wait-for-it.sh: waiting 10 seconds for www.baidu.com:81wait-for-it.sh: timeout occurred after waiting 10 seconds for www.baidu.com:81baidu is up 例三：永不超时12[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:81 -t 0 -- echo "baidu is up" wait-for-it.sh: waiting for www.baidu.com:81 without a timeout 例四：只有测试通过，才执行后面命令12345678910[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:81 -t 10 -s -- echo "baidu is up" wait-for-it.sh: waiting 10 seconds for www.baidu.com:81wait-for-it.sh: timeout occurred after waiting 10 seconds for www.baidu.com:81wait-for-it.sh: strict mode, refusing to execute subprocess[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:80 -t 10 -s -- echo "baidu is up" wait-for-it.sh: waiting 10 seconds for www.baidu.com:80wait-for-it.sh: www.baidu.com:80 is available after 0 secondsbaidu is up 例五：静默123[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:81 -t 5 -s -q -- echo "baidu is up"[nrj@test139 workspace]$ ./wait-for-it.sh www.baidu.com:80 -t 5 -s -q -- echo "baidu is up" baidu is up Docker里面怎么用这个应该更简单吧。 把这个脚本build进你的镜像里面，比如放到tomcat镜像的/bin下面去。 比如你的tomcat镜像的名称是db，开放3306端口。 那么你tomcat镜像的启动脚本就要这么写：1$docker run [OPTIONS] IMAGE[:TAG] wait-for-it.sh db:3306 -t 0 -q -s /usr/local/tomcat/bin/catalina.sh run Docker-Compose的depends_on+（healthcheck）这个怎么用呢？前提条件是用docker-compose，还要使用v2.1的语法 例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: '2.1'services: mysql: image: registry.cn-hangzhou.aliyuncs.com/zhaoshg1984/env:mysql-5.6.35 container_name: mysql volumes: - /home/nrj/workspace/docker-data/mysql/:/var/lib/mysql/ expose: - "3306" environment: - MYSQL_ROOT_PASSWORD=5Yg6f4x1%bDiX%Q* healthcheck: test: ["CMD", "curl", "-f", "http://localhost:3306 || exit 1"] interval: 10s timeout: 5s retries: 3 memcached: image: memcached:1.4.36-alpine container_name: memcached ports: - "11211:11211" rbac: image: registry.cn-hangzhou.aliyuncs.com/zhaoshg1984/env:tomcat8-jre-8u121 container_name: rbac links: - mysql - memcached depends_on: mysql: condition: service_healthy memcached: condition: service_started expose: - "8080" volumes: - /home/nrj/workspace/projects/rbac/:/usr/local/tomcat/webapps/rbac - /home/nrj/logs/rbac/tomcat/:/usr/local/tomcat/logs/ - /home/nrj/logs/rbac/web/:/home/logs/rbac/ healthcheck: test: curl -f http://localhost:8080/rbac/resource/images/favicon.ico || exit 1 interval: 30s timeout: 5s retries: 3 上面的例子中，compose会等到redis启动之后、db服务“健康”之后再启动web。 代码一：wait-for-it 脚本内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154#!/usr/bin/env bash#Use this script to test if a given TCP host/port are availablecmdname=$(basename $0)echoerr() &#123; if [[ $QUIET -ne 1 ]]; then echo "$@" 1&gt;&amp;2; fi &#125;usage()&#123; cat &lt;&lt; USAGE &gt;&amp;2Usage: $cmdname host:port [-s] [-t timeout] [-- command args] -h HOST | --host=HOST Host or IP under test -p PORT | --port=PORT TCP port under test Alternatively, you specify the host and port as host:port -s | --strict Only execute subcommand if the test succeeds -q | --quiet Don't output any status messages -t TIMEOUT | --timeout=TIMEOUT Timeout in seconds, zero for no timeout -- COMMAND ARGS Execute command with args after the test finishesUSAGE exit 1&#125;wait_for()&#123; if [[ $TIMEOUT -gt 0 ]]; then echoerr "$cmdname: waiting $TIMEOUT seconds for $HOST:$PORT" else echoerr "$cmdname: waiting for $HOST:$PORT without a timeout" fi start_ts=$(date +%s) while : do (echo &gt; /dev/tcp/$HOST/$PORT) &gt;/dev/null 2&gt;&amp;1 result=$? if [[ $result -eq 0 ]]; then end_ts=$(date +%s) echoerr "$cmdname: $HOST:$PORT is available after $((end_ts - start_ts)) seconds" break fi sleep 1 done return $result&#125;wait_for_wrapper()&#123; # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692 if [[ $QUIET -eq 1 ]]; then timeout $TIMEOUT $0 --quiet --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp; else timeout $TIMEOUT $0 --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp; fi PID=$! trap "kill -INT -$PID" INT wait $PID RESULT=$? if [[ $RESULT -ne 0 ]]; then echoerr "$cmdname: timeout occurred after waiting $TIMEOUT seconds for $HOST:$PORT" fi return $RESULT&#125;#process argumentswhile [[ $# -gt 0 ]]do case "$1" in *:* ) hostport=($&#123;1//:/ &#125;) HOST=$&#123;hostport[0]&#125; PORT=$&#123;hostport[1]&#125; shift 1 ;; --child) CHILD=1 shift 1 ;; -q | --quiet) QUIET=1 shift 1 ;; -s | --strict) STRICT=1 shift 1 ;; -h) HOST="$2" if [[ $HOST == "" ]]; then break; fi shift 2 ;; --host=*) HOST="$&#123;1#*=&#125;" shift 1 ;; -p) PORT="$2" if [[ $PORT == "" ]]; then break; fi shift 2 ;; --port=*) PORT="$&#123;1#*=&#125;" shift 1 ;; -t) TIMEOUT="$2" if [[ $TIMEOUT == "" ]]; then break; fi shift 2 ;; --timeout=*) TIMEOUT="$&#123;1#*=&#125;" shift 1 ;; --) shift CLI="$@" break ;; --help) usage ;; *) echoerr "Unknown argument: $1" usage ;; esacdoneif [[ "$HOST" == "" || "$PORT" == "" ]]; then echoerr "Error: you need to provide a host and port to test." usagefiTIMEOUT=$&#123;TIMEOUT:-15&#125;STRICT=$&#123;STRICT:-0&#125;CHILD=$&#123;CHILD:-0&#125;QUIET=$&#123;QUIET:-0&#125;if [[ $CHILD -gt 0 ]]; then wait_for RESULT=$? exit $RESULTelse if [[ $TIMEOUT -gt 0 ]]; then wait_for_wrapper RESULT=$? else wait_for RESULT=$? fifiif [[ $CLI != "" ]]; then if [[ $RESULT -ne 0 &amp;&amp; $STRICT -eq 1 ]]; then echoerr "$cmdname: strict mode, refusing to execute subprocess" exit $RESULT fi exec $CLIelse exit $RESULTfi]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[为你的容器做一个健康检查]]></title>
      <url>%2F20170419%2Fdocker_healthycheck_for_con%2F</url>
      <content type="text"><![CDATA[你的容器是否觉得不顺畅？很难启动？看看如何建立一个健康检查确保你的容器健康运行。 Docker 1.12新功能之一就是检查一个容器健康与否，可以与镜像清晰度合并。并且这可以在命令行重写。 就像CMD指令，可以在Dockerfile中多重健康检查指令，但是只有最后一条有效。 这个增加很棒，因为一个容器报告状态可能返回错误可能要1小时。容器可能结束但是没有办法为了容器内部的应用去阻止一个状态。这个指令修复了这个问题。 Dockerfile创建arungupta/couchbase：1234FROM couchbase:latest COPY configure-node.sh /opt/couchbase HEALTHCHECK --interval=5s --timeout=3s CMD curl --fail http://localhost:8091/pools || exit 1 CMD ["/opt/couchbase/configure-node.sh"] 它使用configure-node.sh脚本来配置使用Couchbase REST API的服务器。 注意新的指令在这健康检查。 指令可以规定为：1HEALTHCHECK &lt;options&gt; CMD &lt;command&gt; 可以是：123–interval=DURATION (default 30s).–timeout=DURATION (default 30s).–retries=N (default 3). 是在容器内部运行来检查健康的命令。如果健康检查被启用，那么容器可以有以下三个状态： 开始：当容器开始时，初始状态。 健康：如果命令成功，容器则是健康的。 不健康：如果单个运行需要比指定超时还长，则容器被认为是不健康的。如果一个健康检查失败，那么将会多次重新尝试运，行并且如果还是失败将会声明不健康。 命令退出状态表明容器的健康状态。允许以下值： 0：容器健康。 1：容器不健康。 在我们的指令中，/pools RESTAPI是通过curl来调用的。如果命令失败，一个1的退出状态返回，这标志这次尝试容器是不健康的。每5秒命令被调用一次。如果命令没有在3秒内返回成功，容器则被标记不健康。 运行容器如下：1docker run -d --name db arungupta/couchbase:latest 检查状态：123docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 55b14302671e arungupta/couchbase:latest "/entrypoint.sh /opt/" 2 seconds ago Up 1 seconds (health: starting) 8091-8094/tcp, 11207/tcp, 11210-11211/tcp, 18091-18093/tcp db 注意怎样是健康：在状态栏报告初始状态。几秒后检查，显示状态：123docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 55b14302671e arungupta/couchbase:latest "/entrypoint.sh /opt/" About a minute ago Up About a minute (healthy) 8091-8094/tcp, 11207/tcp, 11210-11211/tcp, 18091-18093/tcp db 现在报告是健康的。 更多细节关于健康检查指令可以在docs.docker.com 找到。 现在，如果你正在运行一个没有健康检查指令的镜像，那么docker运行命令可以被用作制定相似的值。同等的运行时间命令如下：1docker run -d --name db --health-cmd "curl --fail http://localhost:8091/pools || exit 1" --health-interval=5s --timeout=3s arungupta/couchbase 过去5个容器的健康检查可以使用docker inspect命令获得：1docker inspect --format='&#123;&#123;json .State.Health&#125;&#125;' db 显示输出如下：123456789101112131415161718192021222324252627282930313233343536&#123; "Status": "healthy", "FailingStreak": 0, "Log": [ &#123; "Start": "2016-11-12T03:23:03.351561Z", "End": "2016-11-12T03:23:03.422176171Z", "ExitCode": 0, "Output": " % Total % Received % Xferd Average Speed Time Time Time Current\n Dload Upload Total Spent Left Speed\n\r 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0\r100 768 100 768 0 0 595k 0 --:--:-- --:--:-- --:--:-- 750k\n&#123;\"isAdminCreds\":true,\"isROAdminCreds\":false,\"isEnterprise\":true,\"pools\":[&#123;\"name\":\"default\",\"uri\":\"/pools/default?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"streamingUri\":\"/poolsStreaming/default?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;],\"settings\":&#123;\"maxParallelIndexers\":\"/settings/maxParallelIndexers?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"viewUpdateDaemon\":\"/settings/viewUpdateDaemon?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;,\"uuid\":\"1b84cdbd136e4e8466049dd062dd6969\",\"implementationVersion\":\"4.5.1-2844-enterprise\",\"componentsVersion\":&#123;\"lhttpc\":\"1.3.0\",\"os_mon\":\"2.2.14\",\"public_key\":\"0.21\",\"asn1\":\"2.0.4\",\"kernel\":\"2.16.4\",\"ale\":\"4.5.1-2844-enterprise\",\"inets\":\"5.9.8\",\"ns_server\":\"4.5.1-2844-enterprise\",\"crypto\":\"3.2\",\"ssl\":\"5.3.3\",\"sasl\":\"2.3.4\",\"stdlib\":\"1.19.4\"&#125;&#125;" &#125;, &#123; "Start": "2016-11-12T03:23:08.423558928Z", "End": "2016-11-12T03:23:08.510122392Z", "ExitCode": 0, "Output": " % Total % Received % Xferd Average Speed Time Time Time Current\n Dload Upload Total Spent Left Speed\n\r 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0\r100 768 100 768 0 0 309k 0 --:--:-- --:--:-- --:--:-- 375k\n&#123;\"isAdminCreds\":true,\"isROAdminCreds\":false,\"isEnterprise\":true,\"pools\":[&#123;\"name\":\"default\",\"uri\":\"/pools/default?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"streamingUri\":\"/poolsStreaming/default?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;],\"settings\":&#123;\"maxParallelIndexers\":\"/settings/maxParallelIndexers?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"viewUpdateDaemon\":\"/settings/viewUpdateDaemon?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;,\"uuid\":\"1b84cdbd136e4e8466049dd062dd6969\",\"implementationVersion\":\"4.5.1-2844-enterprise\",\"componentsVersion\":&#123;\"lhttpc\":\"1.3.0\",\"os_mon\":\"2.2.14\",\"public_key\":\"0.21\",\"asn1\":\"2.0.4\",\"kernel\":\"2.16.4\",\"ale\":\"4.5.1-2844-enterprise\",\"inets\":\"5.9.8\",\"ns_server\":\"4.5.1-2844-enterprise\",\"crypto\":\"3.2\",\"ssl\":\"5.3.3\",\"sasl\":\"2.3.4\",\"stdlib\":\"1.19.4\"&#125;&#125;" &#125;, &#123; "Start": "2016-11-12T03:23:13.511446818Z", "End": "2016-11-12T03:23:13.58141325Z", "ExitCode": 0, "Output": " &#123;\"isAdminCreds\":true,\"isROAdminCreds\":false,\"isEnterprise\":true,\"pools\":[&#123;\"name\":\"default\",\"uri\":\"/pools/default?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"streamingUri\":\"/poolsStreaming/default?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;],\"settings\":&#123;\"maxParallelIndexers\":\"/settings/maxParallelIndexers?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"viewUpdateDaemon\":\"/settings/viewUpdateDaemon?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;,\"uuid\":\"1b84cdbd136e4e8466049dd062dd6969\",\"implementationVersion\":\"4.5.1-2844-enterprise\",\"componentsVersion\":&#123;\"lhttpc\":\"1.3.0\",\"os_mon\":\"2.2.14\",\"public_key\":\"0.21\",\"asn1\":\"2.0.4\",\"kernel\":\"2.16.4\",\"ale\":\"4.5.1-2844-enterprise\",\"inets\":\"5.9.8\",\"ns_server\":\"4.5.1-2844-enterprise\",\"crypto\":\"3.2\",\"ssl\":\"5.3.3\",\"sasl\":\"2.3.4\",\"stdlib\":\"1.19.4\"&#125;&#125; % Total % Received % Xferd Average Speed Time Time Time Current\n Dload Upload Total Spent Left Speed\n\r 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0\r100 768 100 768 0 0 248k 0 --:--:-- --:--:-- --:--:-- 375k\n" &#125;, &#123; "Start": "2016-11-12T03:23:18.583512367Z", "End": "2016-11-12T03:23:18.677727356Z", "ExitCode": 0, "Output": " % Total % Received % Xferd Average Speed Time Time Time Current\n Dlo&#123;\"isAdminCreds\":true,\"isROAdminCreds\":false,\"isEnterprise\":true,\"pools\":[&#123;\"name\":\"default\",\"uri\":\"/pools/default?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"streamingUri\":\"/poolsStreaming/default?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;],\"settings\":&#123;\"maxParallelIndexers\":\"/settings/maxParallelIndexers?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"viewUpdateDaemon\":\"/settings/viewUpdateDaemon?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;,\"uuid\":\"1b84cdbd136e4e8466049dd062dd6969\",\"implementationVersion\":\"4.5.1-2844-enterprise\",\"componentsVersion\":&#123;\"lhttpc\":\"1.3.0\",\"os_mon\":\"2.2.14\",\"public_key\":\"0.21\",\"asn1\":\"2.0.4\",\"kernel\":\"2.16.4\",\"ale\":\"4.5.1-2844-enterprise\",\"inets\":\"5.9.8\",\"ns_server\":\"4.5.1-2844-enterprise\",\"crypto\":\"3.2\",\"ssl\":\"5.3.3\",\"sasl\":\"2.3.4\",\"stdlib\":\"1.19.4\"&#125;&#125;ad Upload Total Spent Left Speed\n\r 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0\r100 768 100 768 0 0 307k 0 --:--:-- --:--:-- --:--:-- 375k\n" &#125;, &#123; "Start": "2016-11-12T03:23:23.679661467Z", "End": "2016-11-12T03:23:23.782372291Z", "ExitCode": 0, "Output": " % Total % Received % Xferd Average Speed Time Time Time Current\n Dload Upload Total Spent Left&#123;\"isAdminCreds\":true,\"isROAdminCreds\":false,\"isEnterprise\":true,\"pools\":[&#123;\"name\":\"default\",\"uri\":\"/pools/default?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"streamingUri\":\"/poolsStreaming/default?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;],\"settings\":&#123;\"maxParallelIndexers\":\"/settings/maxParallelIndexers?uuid=1b84cdbd136e4e8466049dd062dd6969\",\"viewUpdateDaemon\":\"/settings/viewUpdateDaemon?uuid=1b84cdbd136e4e8466049dd062dd6969\"&#125;,\"uuid\":\"1b84cdbd136e4e8466049dd062dd6969\",\"implementationVersion\":\"4.5.1-2844-enterprise\",\"componentsVersion\":&#123;\"lhttpc\":\"1.3.0\",\"os_mon\":\"2.2.14\",\"public_key\":\"0.21\",\"asn1\":\"2.0.4\",\"kernel\":\"2.16.4\",\"ale\":\"4.5.1-2844-enterprise\",\"inets\":\"5.9.8\",\"ns_server\":\"4.5.1-2844-enterprise\",\"crypto\":\"3.2\",\"ssl\":\"5.3.3\",\"sasl\":\"2.3.4\",\"stdlib\":\"1.19.4\"&#125;&#125; Speed\n\r 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0\r100 768 100 768 0 0 439k 0 --:--:-- --:--:-- --:--:-- 750k\n" &#125; ] &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Swarm搭建Docker集群]]></title>
      <url>%2F20170419%2Fdocker_for_swarm%2F</url>
      <content type="text"><![CDATA[Swarm介绍Swarm是Docker公司在2014年12月初发布的一套较为简单的工具，用来管理Docker集群，它将一群Docker宿主机变成一个单一的，虚拟的主机。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，各种形式的Docker Client(docker client in Go, docker_py, docker等)均可以直接与Swarm通信。Swarm几乎全部用Go语言来完成开发，上周五，4月17号，Swarm0.2发布，相比0.1版本，0.2版本增加了一个新的策略来调度集群中的容器，使得在可用的节点上传播它们，以及支持更多的Docker命令以及集群驱动。Swarm deamon只是一个调度器（Scheduler）加路由器(router)，Swarm自己不运行容器，它只是接受docker客户端发送过来的请求，调度适合的节点来运行容器，这意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，当Swarm重新恢复运行之后，它会收集重建集群信息。下面是Swarm的结构图： 如何使用Swarm有3台机器： sclu083：10.13.181.83 sclu084：10.13.181.84 atsg124：10.32.105.124利用这三台机器创建一个Docker集群，其中sclu083同时充当swarm manager管理集群。Swarm安装最简单的安装Swarm的方式就是用Docker官方提供的Swarm镜像：1$ sudo docker pull swarm Docker集群管理需要服务发现(Discovery service backend)功能。Swarm支持以下几种discovery service backend：Docker Hub上面内置的服务发现功能，本地的静态文件描述集群(static file describing the cluster)，etcd(顺带说一句，etcd这玩意貌似很火很有前途，有时间研究下)，consul，zookeeper和一些静态的ip列表(a static list of ips)。本文会详细介绍前面两种方法backend的使用。在使用Swarm进行集群管理之前，需要先把准备加入集群的所有的节点的docker deamon的监听端口修改为0.0.0.0:2375，可以直接使用sudo docker –H tcp://0.0.0.0:2375 &amp;命令，也可以在配置文件中修改1$ sudo vim /etc/default/docker 在文件的最后面添加下面这句1D0OCKER_OPTS="-H 0.0.0.0:2375 –H unix:///var/run/docker.sock" 注意：一定是要在所有的节点上进行修改,修改之后要重启docker deamon1$ sudo service docker restart 服务发现功能第一种方法：使用Docker Hub上面内置的服务发现功能第一步在任何一个节点上面执行swarm create命令来创建一个集群标志。这条命令执行完毕之后，swarm会前往Docker Hub上内建的发现服务中获取一个全球唯一的token，用以唯一的标识swarm管理的Docker集群。1$ sudo docker run --rm swarm create 我们在sclu084 这台机器上执行上面的命令 返回的token是d947b55aa8fb9198b5d13ad81f61ac4d，这个token一定要记住，因为接下来的操作都会用到这一个token。 第二步在所有的要加入集群的机器上面执行swarm join命令，把机器加入集群。本次试验就是要在所有的三台机器上执行命令。1$ sudo docker run –-rm swarm join –addr=ip_address:2375 token://d947b55aa8fb9198b5d13ad81f61ac4d 在IP地址为10.13.181.84机器上面执行 执行这条命令后不会立即返回 ，我们手动通过Ctrl+C返回。 第三步启动swarm manager。因为我们要让sclu083充当Swarm管理节点，所以我们要在这台机器上面执行swarm manage命令1$ sudo docker run –d –p 2376:2375 swarm manage token:// d947b55aa8fb9198b5d13ad81f61ac4d 重点内容需要注意的是：在这条命令中，第一：要以daemon的形式运行swarm；第二：端口映射：2376可以更换成任何一个本机没有占用的端口，一定不能是2375，否则就会出问题。执行结果如下如所示： 执行完这个命令之后，整个集群已经启动起来了。 现在可以在任何一个节点上查看集群上的所有节点了。 之后可以在任何一台安装了docker的机器上面通过命令(命令中要指明swarm maneger 机器的IP地址和端口)在这个集群上面运行Dcoker容器操作。现在在10.13.181.85这台机器上面查看集群的节点的信息。info命令可以换成任何一个Swarm支持的docker命令，这些命令可以查看官方文档1$ sudo docker –H 10.13.181.83:2376 info 由上图的结果，我们可以发现一个问题：明明这个小集群中是有3个节点的，但是info命令只显示了2个节点。还缺少节点10.32.105.124。为什么会出现这个情况呢？ 因为10.32.105.124这台机器没有设置上面的docker daemon监听0.0.0.0:2375这个端口，所以Swarm没办法吧这个节点加入集群中来。 在使用Docker Hub内置的发现服务时，会出现一个问题，就是使用swarm create时会出现time=&quot;2015-04-21T08:56:25Z&quot; level=fatal msg=&quot;Get https://discovery-stage.hub.docker.com/v1/clusters/d947b55aa8fb9198b5d13ad81f61ac4d: dial tcp: i/o timeout&quot;类似于这样的错误，不知道是什么原因，有待解决。（可能是防火墙的问题） 当使用Docker Hub内置的服务发现功能出现问题时，可以使用下面的第二种方法。 第二种方法：使用文件第二种方法相对而言比第一种方法要简单，也更不容易出现timeout的问题。 第一步在sclu083这台机器上新建一个文件，把要加入集群的机器的IP地址写进去 第二步在sclu083这台机器上面执行swarm manage命令：1$ sudo docker run –d –p 2376:2375 –v $(pwd)/cluster:/tmp/cluster swarm manage file:///tmp/cluster 注意：这里一定要使用-v命令，因为cluster文件是在本机上面，启动的容器默认是访问不到的，所以要通过-v命令共享。还有，file:///千万不能忘记了。 可以看到，swarm已经运行起来了。现在可以查看下集群节点信息了，使用命令：1$ sudo docker run –rm –v $(pwd)/cluster:/tmp/cluster swarm list file:///tmp/cluster (在使用文件作为服务发现的时候，貌似manage list命令只能在swarm manage节点上使用，在其他节点上好像是用不了)好了，现在集群也已经运行起来了，可以跟第一种方法一样在其他机器上使用集群了。同样在sclu085 机器上做测试: 可以看到，成功访问并且节点信息是正确的。接下来可以把上面的info命令替换成其他docker可执行命令来使用这个晓得Docker集群了。 Swarm调度策略Swarm在schedule节点运行容器的时候，会根据指定的策略来计算最适合运行容器的节点，目前支持的策略有：spread, binpack, random. Random顾名思义，就是随机选择一个Node来运行容器，一般用作调试用， spread和binpack策略会根据各个节点的可用的CPU, RAM以及正在运行的容器的数量来计算应该运行容器的节点。 在同等条件下，Spread策略会选择运行容器最少的那台节点来运行新的容器，binpack策略会选择运行容器最集中的那台机器来运行新的节点(The binpack strategy causes Swarm to optimize for the Container which is most packed.)。 使用Spread策略会使得容器会均衡的分布在集群中的各个节点上运行，一旦一个节点挂掉了只会损失少部分的容器。 Binpack策略最大化的避免容器碎片化，就是说binpack策略尽可能的把还未使用的节点留给需要更大空间的容器运行，尽可能的把容器运行在一个节点上面。 过滤器Constraint Filter通过label来在指定的节点上面运行容器。这些label是在启动docker daemon时指定的，也可以写在/etc/default/docker这个配置文件里面。1$ sudo docker run –H 10.13.181.83:2376 –name redis_083 –d –e constraint:label==083 redis Affinity Filter使用-e affinity:container==container_name / container_id –-name container_1可以让容器container_1紧挨着容器container_name / container_id执行，也就是说两个容器在一个node上面执行(You can schedule 2 containers and make the container #2 next to the container #1.) 先在一台机器上启动一个容器1$ sudo docker -H 10.13.181.83:2376 run --name redis_085 -d -e constraint:label==085 redis 接下来启动容器redis_085_1，让redis_085_1紧挨着redis_085容器运行，也就是在一个节点上运行1$ sudo docker –H 10.13.181.83:2376 run –d –name redis_085_1 –e affinity:container==redis_085 redis 通过-e affinity:image=image_name命令可以指定只有已经下载了image_name的机器才运行容器(You can schedule a container only on nodes where the images are already pulled) 下面命令在只有Redis镜像的节点上面启动redis容器:1$ sudo docker –H 100.13.181.83:2376 run –name redis1 –d –e affinity:image==redis redis 下面这条命令达到的效果是：在有redis镜像的节点上面启动一个名字叫做redis的容器，如果每个节点上面都没有redis容器，就按照默认的策略启动redis容器。1$ sudo docker -H 10.13.181.83:2376 run -d --name redis -e affinity:image==~redis redis Port filterPort也会被认为是一个唯一的资源1$ sudo docker -H 10.13.181.83:2376 run -d -p 80:80 nginx 执行完这条命令，任何使用80端口的容器都是启动失败。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何使用 hexo＋github 搭建个人博客]]></title>
      <url>%2F20170419%2Fhexo_github_to_blog%2F</url>
      <content type="text"><![CDATA[GitHub Pages 有以下几个优点： 轻量级的博客系统，没有麻烦的配置 免费空间，享受 Git 版本管理功能 使用标记语言，比如 Markdown 无需自己搭建服务器 可以绑定自己的域名 当然他也有缺点： 搭配模板系统，相当于静态页发布，每运行生成一次都必须遍历全部的文本文件，网站越大，生成时间越长 动态程序的部分相当局限，比如没有评论，不过有解决方案 基于 Git，很多东西需要定制，不像 Wordpress 有强大的后台 要想搭建漂亮的 blog，还需要模板系统，官方推荐的是 jekyll，但是配置稍复杂，今天推荐另一个选择 —— hexo，一个简单地、轻量地、基于 Node 的一个静态博客框架。 下面介绍下如何使用 hexo 和 github pages 搭建个人博客。 准备工作注意: 本文针对 Windows 平台和 Hexo 3.1.1 安装 github windows主要使用 git bash，如果对 git 命令不熟悉的也可以使用 git 客户端进行某些操作github windows 安装 node.js因为要使用 npm，比较简单的方法就是安装 node.jsnode.js安装完成后添加 Path 环境变量，使 npm 命令生效;C:\Program Files\nodejs\node_modules\npm 创建 Github Pages没有 github 账号的话，需要注册一个，不赘述 然后创建一个仓库，名字是[yourGithubAccount].github.io 配置 ssh key使用 git bash 生成 public ssh key，以下是最简单的方法1$ssh-keygen -t rsa C/Documents and Settings/username/.ssh 目录下会生成 id_rsa.pub 将 id_rsa.pub 的内容完全复制到 github Account Setting 里的 ssh key 里即可 测试1$ssh -T git@github.com 然后会看到1Hi [yourGithubAccount]! You've successfully authenticated, but GitHub does not provide ps access. 设置用户信息12$git config --global user.name "[yourName]"//用户名$git config --global user.email "[yourEmail]"//填写自己的邮箱 经过以上步骤，本机已成功连接到 github，为部署打下基础。 配置 hexo本地 clone创建本地目录，然后使用 git bash 或者客户端 clone 之前创建的仓库（[yourGithubAccount].github.io） 安装、配置 hexo 进入仓库目录，使用 git bash 安装配置 hexo 123$npm install -g hexo-cli$npm install hexo --save$hexo init 安装 hexo 插件 12345678910111213$npm install hexo-generator-index --save$npm install hexo-generator-archive --save$npm install hexo-generator-category --save$npm install hexo-generator-tag --save$npm install hexo-server --save$npm install hexo-deployer-git --save$npm install hexo-deployer-heroku --save$npm install hexo-deployer-rsync --save$npm install hexo-deployer-openshift --save$npm install hexo-renderer-marked@0.2 --save$npm install hexo-renderer-stylus@0.2 --save$npm install hexo-generator-feed@1 --save$npm install hexo-generator-sitemap@1 --save 安装 ejs，否则无法解析模板 1$npm install 生成 public 文件夹 1$hexo g 浏览器输入 localhost:4000 本地查看效果 1$hexo s 主题hexo 有很多主题可选，我选了 Jacman，默认支持多说评论、网站统计、分享等功能，只要稍微配置即可使用。可以根据自己需求进行选择。 使用 hexo部署配置 _config.yml1234deploy: type: git repository: git@github.com:[yourGithubAccount]/[yourGithubAccount].github.io.git branch: master 1$hexo d 即可将 hexo 部署到 github 上 提示找不到 git 时需执行（虽然之前已经执行过）1$npm install hexo-deployer-git --save 然后1$hexo d 即可通过 http://[yourGithubAccount].github.io/ 查看了 发表新文章1$hexo new "title" 然后在 source/_post 下会生成该md文件，即可使用编辑器编写了 编写过程中，可以在本地实时查看效果，很是方便 支持 markdown，不了解的自行 google 吧 编写完成后，部署还是一样的12$hexo g$hexo d 如果部署过程中报错，可执行以下命令重新部署123$hexo clean$hexo generate$hexo deploy 添加自定义页面1$hexo new page "about" 该命令会生成 source/about/index.md，编辑即可 插件的升级与卸载12$npm update$npm uninstall &lt;plugin-name&gt; 更新 hexo1$npm update -g hexo 绑定自定义域名在/source/ 目录下新建内容为自定义域名的 CNAME 文件，部署即可（域名设置略） 备注：Hexo简写命令1234$hexo n #new$hexo g #generate$hexo s #server$hexo d #deploy 以上是基本操作，质量高的 blog 所带来的好处是不言而喻的，感兴趣的可以行动起来了。 参考资料http://alfred-sun.github.io/blog/2014/12/05/github-pages/http://beiyuu.com/github-pages/http://cnfeat.com/2014/05/10/2014-05-11-how-to-build-a-blog/http://wsgzao.github.io/post/hexo-guide/http://fy98.com/2014/03/03/build-blog-with-hexo/]]></content>
    </entry>

    
  
  
</search>
